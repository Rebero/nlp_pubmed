titletext,PMID
"Biologically Informed Neural Networks Predict Drug Responses.. Deep neural networks often achieve high predictive accuracy on biological problems, but it can be hard to contextualize how and explain why predictions are made. In this issue, Kuenzi et al. model the sensitivity of cancers to drugs using deep neural networks with a hierarchical structure derived from the Gene Ontology.",33096022
"Letter to the Editor. Reply to Ahn JC, Connell A, Simonetto DA, Hughes C, Shah VH. The application of artificial intelligence for the diagnosis and treatment of liver diseases.. among the forthcoming articles to be published in Hepatology, I noticed the extensive review by Ahn, Connell, Simonetto, Hughes & Shah concerning ""The application of artificial intelligence for the diagnosis and treatment of liver diseases"" [1]. As a bioethicist, I need to raise some concern about the perspective given by this review, which disregards some important issues concerning ethical aspects and patient-physician relationship.",33185298
"Reporting guidelines for clinical trial reports for interventions involving artificial intelligence: the CONSORT-AI extension.. The CONSORT 2010 statement provides minimum guidelines for reporting randomized trials. Its widespread use has been instrumental in ensuring transparency in the evaluation of new interventions. More recently, there has been a growing recognition that interventions involving artificial intelligence (AI) need to undergo rigorous, prospective evaluation to demonstrate impact on health outcomes. The CONSORT-AI (Consolidated Standards of Reporting Trials-Artificial Intelligence) extension is a new reporting guideline for clinical trials evaluating interventions with an AI component. It was developed in parallel with its companion statement for clinical trial protocols: SPIRIT-AI (Standard Protocol Items: Recommendations for Interventional Trials-Artificial Intelligence). Both guidelines were developed through a staged consensus process involving literature review and expert consultation to generate 29 candidate items, which were assessed by an international multi-stakeholder group in a two-stage Delphi survey (103 stakeholders), agreed upon in a two-day consensus meeting (31 stakeholders) and refined through a checklist pilot (34 participants). The CONSORT-AI extension includes 14 new items that were considered sufficiently important for AI interventions that they should be routinely reported in addition to the core CONSORT 2010 items. CONSORT-AI recommends that investigators provide clear descriptions of the AI intervention, including instructions and skills required for use, the setting in which the AI intervention is integrated, the handling of inputs and outputs of the AI intervention, the human-AI interaction and provision of an analysis of error cases. CONSORT-AI will help promote transparency and completeness in reporting clinical trials for AI interventions. It will assist editors and peer reviewers, as well as the general readership, to understand, interpret and critically appraise the quality of clinical trial design and risk of bias in the reported outcomes.",32908283
"Integration of novel monitoring devices with machine learning technology for scalable cardiovascular management.. Ambulatory monitoring is increasingly important for cardiovascular care but is often limited by the unpredictability of cardiovascular events, the intermittent nature of ambulatory monitors and the variable clinical significance of recorded data in patients. Technological advances in computing have led to the introduction of novel physiological biosignals that can increase the frequency at which abnormalities in cardiovascular parameters can be detected, making expert-level, automated diagnosis a reality. However, use of these biosignals for diagnosis also raises numerous concerns related to accuracy and actionability within clinical guidelines, in addition to medico-legal and ethical issues. Analytical methods such as machine learning can potentially increase the accuracy and improve the actionability of device-based diagnoses. Coupled with interoperability of data to widen access to all stakeholders, seamless connectivity (an internet of things) and maintenance of anonymity, this approach could ultimately facilitate near-real-time diagnosis and therapy. These tools are increasingly recognized by regulatory agencies and professional medical societies, but several technical and ethical issues remain. In this Review, we describe the current state of cardiovascular monitoring along the continuum from biosignal acquisition to the identification of novel biosensors and the development of analytical techniques and ultimately to regulatory and ethical issues. Furthermore, we outline new paradigms for cardiovascular monitoring.",33037325
"Artificial Intelligence for Surgical Safety: Automatic Assessment of the Critical View of Safety in Laparoscopic Cholecystectomy Using Deep Learning.. Objective: To develop a deep learning model to automatically segment hepatocystic anatomy and assess the criteria defining the critical view of safety (CVS) in laparoscopic cholecystectomy (LC).  Background: Poor implementation and subjective interpretation of CVS contributes to the stable rates of bile duct injuries in LC. As CVS is assessed visually, this task can be automated by using computer vision, an area of artificial intelligence aimed at interpreting images.  Methods: Still images from LC videos were annotated with CVS criteria and hepatocystic anatomy segmentation. A deep neural network comprising a segmentation model to highlight hepatocystic anatomy and a classification model to predict CVS criteria achievement was trained and tested using 5-fold cross validation. Intersection over union, average precision, and balanced accuracy were computed to evaluate the model performance versus the annotated ground truth.  Results: A total of 2854 images from 201 LC videos were annotated and 402 images were further segmented. Mean intersection over union for segmentation was 66.6%. The model assessed the achievement of CVS criteria with a mean average precision and balanced accuracy of 71.9% and 71.4%, respectively.  Conclusions: Deep learning algorithms can be trained to reliably segment hepatocystic anatomy and assess CVS criteria in still laparoscopic images. Surgical-technical partnerships should be encouraged to develop and evaluate deep learning models to improve surgical safety.",33201104
"Detecting Large Vessel Occlusion at Multiphase CT Angiography by Using a Deep Convolutional Neural Network.. Background Large vessel occlusion (LVO) stroke is one of the most time-sensitive diagnoses in medicine and requires emergent endovascular therapy to reduce morbidity and mortality. Leveraging recent advances in deep learning may facilitate rapid detection and reduce time to treatment. Purpose To develop a convolutional neural network to detect LVOs at multiphase CT angiography. Materials and Methods This multicenter retrospective study evaluated 540 adults with CT angiography examinations for suspected acute ischemic stroke from February 2017 to June 2018. Examinations positive for LVO (n = 270) were confirmed by catheter angiography and LVO-negative examinations (n = 270) were confirmed through review of clinical and radiology reports. Preprocessing of the CT angiography examinations included vasculature segmentation and the creation of maximum intensity projection images to emphasize the contrast agent-enhanced vasculature. Seven experiments were performed by using combinations of the three phases (arterial, phase 1; peak venous, phase 2; and late venous, phase 3) of the CT angiography. Model performance was evaluated on the held-out test set. Metrics included area under the receiver operating characteristic curve (AUC), sensitivity, and specificity. Results The test set included 62 patients (mean age, 69.5 years; 48% women). Single-phase CT angiography achieved an AUC of 0.74 (95% confidence interval [CI]: 0.63, 0.85) with sensitivity of 77% (24 of 31; 95% CI: 59%, 89%) and specificity of 71% (22 of 31; 95% CI: 53%, 84%). Phases 1, 2, and 3 together achieved an AUC of 0.89 (95% CI: 0.81, 0.96), sensitivity of 100% (31 of 31; 95% CI: 99%, 100%), and specificity of 77% (24 of 31; 95% CI: 59%, 89%), a statistically significant improvement relative to single-phase CT angiography (P = .01). Likewise, phases 1 and 3 and phases 2 and 3 also demonstrated improved fit relative to single phase (P = .03). Conclusion This deep learning model was able to detect the presence of large vessel occlusion and its diagnostic performance was enhanced by using delayed phases at multiphase CT angiography examinations. © RSNA, 2020 Online supplemental material is available for this article. See also the editorial by Ospel and Goyal in this issue.",32990513
"Geographic Distribution of US Cohorts Used to Train Deep Learning Algorithms.. This study describes the US geographic distribution of patient cohorts used to train deep learning algorithms in published radiology, ophthalmology, dermatology, pathology, gastroenterology, and cardiology machine learning articles published in 2015-2019.",32960230
"Diagnosis of COVID-19 Pneumonia Using Chest Radiography: Value of Artificial Intelligence.. Background Radiologists are proficient in differentiating between chest x-ray radiographs (CXRs) with and without symptoms of pneumonia, but have found it more challenging to differentiate CXRs with COVID-19 pneumonia symptoms from those without. Purpose To develop an artificial intelligence algorithm to differentiate COVID-19 pneumonia from other causes of CXR abnormalities. Materials and Methods In this retrospective study, a deep neural network, CV19-Net, was trained, validated, and tested on CXRs from patients with and without COVID-19 pneumonia. For the COVID-19 positive CXRs, patients with reverse transcriptase polymerase chain reaction positive results for severe acute respiratory syndrome coronavirus 2 with positive pneumonia findings between February 1, 2020 and May 30, 2020 were included. For the non-COVID-19 CXRs, patients with pneumonia who underwent CXR between October 1, 2019 and December 31, 2019 were included. Area under the receiver operating characteristic curve (AUC), sensitivity, and specificity were calculated to characterize diagnostic performance. To benchmark the performance of CV19-Net, a randomly sampled test dataset containing 500 CXRs from 500 patients was evaluated by both the CV19-Net and three experienced thoracic radiologists. Results A total of 2060 patients (5806 CXRs; mean age 62 ± 16, 1059 men) with COVID-19 pneumonia and 3148 patients (5300 CXRs; mean age 64 ± 18, 1578 men) with non-COVID-19 pneumonia were included and split into training + validation and test datasets. For the test set, CV19-Net achieved an AUC of 0.92 (95% confidence interval [CI]: 0.91, 0.93) corresponding to a sensitivity of 88% (95% CI: 87%, 89%) and a specificity of 79% (95% CI: 77%, 80%) using a high sensitivity operating threshold, or a sensitivity of 78% (95% CI: 77%, 79%) and a specificity of 89% (95% CI: 88%, 90%) using a high specificity operating threshold. For the 500 sampled CXRs, CV19-Net achieved an AUC of 0.94 (95% CI: 0.93, 0.96) compared to a 0.85 AUC (95% CI: 0.81, 0.88) of radiologists. Conclusion CV19-Net was able to differentiate COVID-19 related pneumonia from other types of pneumonia with performance exceeding that of experienced thoracic radiologists.",32969761
"The toll of noninfected CRS patients to the COVID-19 pandemic.. Social distancing with the aim of avoiding infections and pre-serve critical care capacities during the COVID-19 pandemic has been implemented in Germany according to World Health Organization (WHO) recommendations from early March onwards. Limitations of physical contacts to reduce exposure to SARS-CoV-2 infected individuals were handled strictly, particularly in medical centers dealing with airway diseases, like rhinology and pneumology clinics. Such measures and reluctance to visit out- and inpatient services resulted in a 82% decrease in consultations to the 12 German oto-rhino-laryngological (ORL) centres forming our database during the 50 days following March 09 in 2020 if compared to the same period in 2019. Our data on CRS care underline reports on undertreatment of non-COVID-19 individuals with several different diseases during the current pandemic. We should try to reduce the toll these patients have to pay as much as possible. We established telemedicine, e-Health and artificial intelligence-supported triage for selecting the right patients for onsite-consultations and to advise patients in several demands.",33130830
"Eigenrank by committee: Von-Neumann entropy based data subset selection and failure prediction for deep learning based medical image segmentation.. Manual delineation of anatomy on existing images is the basis of developing deep learning algorithms for medical image segmentation. However, manual segmentation is tedious. It is also expensive because clinician effort is necessary to ensure correctness of delineation. Consequently most algorithm development is based on a tiny fraction of the vast amount of imaging data collected at a medical center. Thus, selection of a subset of images from hospital databases for manual delineation - so that algorithms trained on such data are accurate and tolerant to variation, becomes an important challenge. We address this challenge using a novel algorithm. The proposed algorithm named 'Eigenrank by Committee' (EBC) first computes the degree of disagreement between segmentations generated by each DL model in a committee. Then, it iteratively adds to the committee, a DL model trained on cases where the disagreement is maximal. The disagreement between segmentations is quantified by the maximum eigenvalue of a Dice coefficient disagreement matrix a measure closely related to the Von Neumann entropy. We use EBC for selecting data subsets for manual labeling from a larger database of spinal canal segmentations as well as intervertebral disk segmentations. U-Nets trained on these subsets are used to generate segmentations on the remaining data. Similar sized data subsets are also randomly sampled from the respective databases, and U-Nets are trained on these random subsets as well. We found that U-Nets trained using data subsets selected by EBC, generate segmentations with higher average Dice coefficients on the rest of the database than U-Nets trained using random sampling (p < 0.05 using t-tests comparing averages). Furthermore, U-Nets trained using data subsets selected by EBC generate segmentations with a distribution of Dice coefficients that demonstrate significantly (p < 0.05 using Bartlett's test) lower variance in comparison to U-Nets trained using random sampling for all datasets. We believe that this lower variance indicates that U-Nets trained with EBC are more robust than U-Nets trained with random sampling.",33080506
"A machine learning analysis of a ""normal-like"" IDH-WT diffuse glioma transcriptomic subgroup associated with prolonged survival reveals novel immune and neurotransmitter-related actionable targets.. Background: Classification of primary central nervous system tumors according to the World Health Organization guidelines follows the integration of histologic interpretation with molecular information and aims at providing the most precise prognosis and optimal patient management. According to the cIMPACT-NOW update 3, diffuse isocitrate dehydrogenase-wild type (IDH-WT) gliomas should be graded as grade IV glioblastomas (GBM) if they possess one or more of the following molecular markers that predict aggressive clinical course: EGFR amplification, TERT promoter mutation, and whole-chromosome 7 gain combined with chromosome 10 loss. Methods: The Cancer Genome Atlas (TCGA) glioma expression datasets were reanalyzed in order to identify novel tumor subcategories which would be considered as GBM-equivalents with the current diagnostic algorithm. Unsupervised clustering allowed the identification of previously unrecognized transcriptomic subcategories. A supervised machine learning algorithm (k-nearest neighbor model) was also used to identify gene signatures specific to some of these subcategories. Results: We identified 14 IDH-WT infiltrating gliomas displaying a ""normal-like"" (NL) transcriptomic profile associated with a longer survival. Genes such as C5AR1 (complement receptor), SLC32A1 (vesicular gamma-aminobutyric acid transporter), MSR1 (or CD204, scavenger receptor A), and SYT5 (synaptotagmin 5) were differentially expressed and comprised in gene signatures specific to NL IDH-WT gliomas which were validated further using the Chinese Glioma Genome Atlas datasets. These gene signatures showed high discriminative power and correlation with survival. Conclusion: NL IDH-WT gliomas represent an infiltrating glioma subcategory with a superior prognosis which can only be detected using genome-wide analysis. Differential expression of genes potentially involved in immune checkpoint and amino acid signaling pathways is providing insight into mechanisms of gliomagenesis and could pave the way to novel treatment targets for infiltrating gliomas. Keywords: Amino acid neurotransmission; Biomarkers; C5AR1; Glioma; IDH-WT; MSR1; SLC32A1; SYT5; Transcriptomic; Tumor immune checkpoints.",33059718
"Apo AI Nanoparticles Delivered Post Myocardial Infarction Moderate Inflammation.. Rationale: Decades of research have examined immune-modulatory strategies to protect the heart after an acute myocardial infarction and prevent progression to heart failure but have failed to translate to clinical benefit. Objective: To determine anti-inflammatory actions of n-apo AI (Apo AI nanoparticles) that contribute to cardiac tissue recovery after myocardial infarction. Methods and results: Using a preclinical mouse model of myocardial infarction, we demonstrate that a single intravenous bolus of n-apo AI (CSL111, 80 mg/kg) delivered immediately after reperfusion reduced the systemic and cardiac inflammatory response. N-apo AI treatment lowered the number of circulating leukocytes by 30±7% and their recruitment into the ischemic heart by 25±10% (all P<5.0×10-2). This was associated with a reduction in plasma levels of the clinical biomarker of cardiac injury, cardiac troponin-I, by 52±17% (P=1.01×10-2). N-apo AI reduced the cardiac expression of chemokines that attract neutrophils and monocytes by 60% to 80% and lowered surface expression of integrin CD11b on monocytes by 20±5% (all P<5.0×10-2). Fluorescently labeled n-apo AI entered the infarct and peri-infarct regions and colocalized with cardiomyocytes undergoing apoptosis and with leukocytes. We further demonstrate that n-apo AI binds to neutrophils and monocytes, with preferential binding to the proinflammatory monocyte subtype and partially via SR-BI (scavenger receptor BI). In patients with type 2 diabetes, we also observed that intravenous infusion of the same n-apo AI (CSL111, 80 mg/kg) similarly reduced the level of circulating leukocytes by 12±5% (all P<5.0×10-2). Conclusions: A single intravenous bolus of n-apo AI delivered immediately post-myocardial infarction reduced the systemic and cardiac inflammatory response through direct actions on both the ischemic myocardium and leukocytes. These data highlight the anti-inflammatory effects of n-apo AI and provide preclinical support for investigation of its use for management of acute coronary syndromes in the setting of primary percutaneous coronary interventions. Keywords: apolipoprotein; inflammation; monocyte; myocardial infarction; percutaneous coronary interventions.",32951519
"A decision algorithm to promote outpatient antimicrobial stewardship for uncomplicated urinary tract infection.. Antibiotic resistance is a major cause of treatment failure and leads to increased use of broad-spectrum agents, which begets further resistance. This vicious cycle is epitomized by uncomplicated urinary tract infection (UTI), which affects one in two women during their life and is associated with increasing antibiotic resistance and high rates of prescription for broad-spectrum second-line agents. To address this, we developed machine learning models to predict antibiotic susceptibility using electronic health record data and built a decision algorithm for recommending the narrowest possible antibiotic to which a specimen is susceptible. When applied to a test cohort of 3629 patients presenting between 2014 and 2016, the algorithm achieved a 67% reduction in the use of second-line antibiotics relative to clinicians. At the same time, it reduced inappropriate antibiotic therapy, defined as the choice of a treatment to which a specimen is resistant, by 18% relative to clinicians. For specimens where clinicians chose a second-line drug but the algorithm chose a first-line drug, 92% (1066 of 1157) of decisions ended up being susceptible to the first-line drug. When clinicians chose an inappropriate first-line drug, the algorithm chose an appropriate first-line drug 47% (183 of 392) of the time. Our machine learning decision algorithm provides antibiotic stewardship for a common infectious syndrome by maximizing reductions in broad-spectrum antibiotic use while maintaining optimal treatment outcomes. Further work is necessary to improve generalizability by training models in more diverse populations.",33148625
"Predicting the progression of mild cognitive impairment using machinelearning: A systematic, quantitative and critical review.. We performed a systematic review of studies focusing on the automatic prediction of the progression of mild cognitive impairment to Alzheimer's disease (AD) dementia, and a quantitative analysis of the methodological choices impacting performance. This review included 172 articles, from which 234 experiments were extracted. For each of them, we reported the used data set, the feature types, the algorithm type, performance and potential methodological issues. The impact of these characteristics on the performance was evaluated using a multivariate mixed effect linear regressions. We found that using cognitive, fluorodeoxyglucose-positron emission tomography or potentially electroencephalography and magnetoencephalography variables significantly improved predictive performance compared to not including them, whereas including other modalities, in particular T1 magnetic resonance imaging, did not show a significant effect. The good performance of cognitive assessments questions the wide use of imaging for predicting the progression to AD and advocates for exploring further fine domain-specific cognitive assessments. We also identified several methodological issues, including the absence of a test set, or its use for feature selection or parameter tuning in nearly a fourth of the papers. Other issues, found in 15% of the studies, cast doubts on the relevance of the method to clinical practice. We also highlight that short-term predictions are likely not to be better than predicting that subjects stay stable over time. These issues highlight the importance of adhering to good practices for the use of machine learning as a decision support system for the clinical practice.",33091740
"CS(2)-Net: Deep learning segmentation of curvilinear structures in medical imaging.. Automated detection of curvilinear structures, e.g., blood vessels or nerve fibres, from medical and biomedical images is a crucial early step in automatic image interpretation associated to the management of many diseases. Precise measurement of the morphological changes of these curvilinear organ structures informs clinicians for understanding the mechanism, diagnosis, and treatment of e.g. cardiovascular, kidney, eye, lung, and neurological conditions. In this work, we propose a generic and unified convolution neural network for the segmentation of curvilinear structures and illustrate in several 2D/3D medical imaging modalities. We introduce a new curvilinear structure segmentation network (CS2-Net), which includes a self-attention mechanism in the encoder and decoder to learn rich hierarchical representations of curvilinear structures. Two types of attention modules - spatial attention and channel attention - are utilized to enhance the inter-class discrimination and intra-class responsiveness, to further integrate local features with their global dependencies and normalization, adaptively. Furthermore, to facilitate the segmentation of curvilinear structures in medical images, we employ a 1×3 and a 3×1 convolutional kernel to capture boundary features. Besides, we extend the 2D attention mechanism to 3D to enhance the network's ability to aggregate depth information across different layers/slices. The proposed curvilinear structure segmentation network is thoroughly validated using both 2D and 3D images across six different imaging modalities. Experimental results across nine datasets show the proposed method generally outperforms other state-of-the-art algorithms in various metrics.",33166771
"Composite type-2 biomarker strategy versus a symptom-risk-based algorithm to adjust corticosteroid dose in patients with severe asthma: a multicentre, single-blind, parallel group, randomised controlled trial.. Background: Asthma treatment guidelines recommend increasing corticosteroid dose to control symptoms and reduce exacerbations. This approach is potentially flawed because symptomatic asthma can occur without corticosteroid responsive type-2 (T2)-driven eosinophilic inflammation, and inappropriately high-dose corticosteroid treatment might have little therapeutic benefit with increased risk of side-effects. We compared a biomarker strategy to adjust corticosteroid dose using a composite score of T2 biomarkers (fractional exhaled nitric oxide [FENO], blood eosinophils, and serum periostin) with a standardised symptom-risk-based algorithm (control). Methods: We did a single-blind, parallel group, randomised controlled trial in adults (18-80 years of age) with severe asthma (at treatment steps 4 and 5 of the Global Initiative for Asthma) and FENO of less than 45 parts per billion at 12 specialist severe asthma centres across England, Scotland, and Northern Ireland. Patients were randomly assigned (4:1) to either the biomarker strategy group or the control group by an online electronic case-report form, in blocks of ten, stratified by asthma control and use of rescue systemic steroids in the previous year. Patients were masked to study group allocation throughout the entirety of the study. Patients attended clinic every 8 weeks, with treatment adjustment following automated treatment-group-specific algorithms: those in the biomarker strategy group received a default advisory to maintain treatment and those in the control group had their treatment adjusted according to the steps indicated by the trial algorithm. The primary outcome was the proportion of patients with corticosteroid dose reduction at week 48, in the intention-to-treat (ITT) population. Secondary outcomes were inhaled corticosteroid (ICS) dose at the end of the study; cumulative dose of ICS during the study; proportion of patients on maintenance oral corticosteroids (OCS) at study end; rate of protocol-defined severe exacerbations per patient year; time to first severe exacerbation; number of hospital admissions for asthma; changes in lung function, Asthma Control Questionnaire-7 score, Asthma Quality of Life Questionnaire score, and T2 biomarkers from baseline to week 48; and whether patients declined to progress to OCS. A secondary aim of our study was to establish the proportion of patients with severe asthma in whom T2 biomarkers remained low when corticosteroid therapy was decreased to a minimum ICS dose. This study is registered with ClinicalTrials.gov, NCT02717689 and has been completed. Findings: Patients were recruited from Jan 8, 2016, to July 12, 2018. Of 549 patients assessed, 301 patients were included in the ITT population and were randomly assigned to the biomarker strategy group (n=240) or to the control group (n=61). 28·4% of patients in the biomarker strategy group were on a lower corticosteroid dose at week 48 compared with 18·5% of patients in the control group (adjusted odds ratio [aOR] 1·71 [95% CI 0·80-3·63]; p=0·17). In the per-protocol (PP) population (n=121), a significantly greater proportion of patients were on a lower corticosteroid dose at week 48 in the biomarker strategy group (30·7% of patients) compared with the control group (5·0% of patients; aOR 11·48 [95% CI 1·35-97·83]; p=0·026). Patient choice to not follow treatment advice was the principle reason for loss to PP analysis. There was no difference in secondary outcomes between study groups and no loss of asthma control among patients in the biomarker strategy group who reduced their corticosteroid dose. Interpretation: Biomarker-based corticosteroid adjustment did not result in a greater proportion of patients reducing corticosteroid dose versus control. Understanding the reasons for patients not following treatment advice in both treatment strategies is an important area for future research. The prevalence of T2 biomarker-low severe asthma was low. Funding: This study was funded, in part, by the Medical Research Council UK.",32916135
"Deep neural network models for computational histopathology: A survey.. Histopathological images contain rich phenotypic information that can be used to monitor underlying mechanisms contributing to disease progression and patient survival outcomes. Recently, deep learning has become the mainstream methodological choice for analyzing and interpreting histology images. In this paper, we present a comprehensive review of state-of-the-art deep learning approaches that have been used in the context of histopathological image analysis. From the survey of over 130 papers, we review the field's progress based on the methodological aspect of different machine learning strategies such as supervised, weakly supervised, unsupervised, transfer learning and various other sub-variants of these methods. We also provide an overview of deep learning based survival models that are applicable for disease-specific prognosis tasks. Finally, we summarize several existing open datasets and highlight critical challenges and limitations with current deep learning approaches, along with possible avenues for future research.",33049577
"Central reading of ulcerative colitis clinical trial videos using neural networks.. Background and aims: Endoscopic disease activity scoring in ulcerative colitis (UC) is useful in clinical practice but infrequently done. It is required in clinical trials, where it is expensive and slow because human central readers (CR) are needed. A machine learning algorithm (MLA) automating the process could elevate clinical care and facilitate clinical research. Prior work using single-institution databases and endoscopic still images has been promising.  Methods: 795 full-length endoscopy videos (FLEV) were prospectively collected from a phase 2 trial of mirikizumab with 249 patients from 14 countries, totaling 19.5 million image frames. Expert CRs assigned each FLEV one endoscopic Mayo score (eMS) and one UC endoscopic index of severity (UCEIS) score. Initially, video data were cleaned, and abnormality features extracted using convolutional neural networks. Subsequently, a recurrent neural network (RNN) was trained on the features to predict eMS and UCEIS from individual full-length endoscopy videos.  Results: The primary metric to assess the performance of the RNN model was quadratic weighted kappa (QWK) comparing the agreement of the machine-read endoscopy score with the human central reader score. QWK progressively penalizes disagreements that exceed one level. The model's agreement metric was excellent with QWK of 0.844 (95% CI, 0.787-0.901) for eMS and 0.855 (95% CI, 0.80-0.91) for UCEIS.  Conclusion: We found that a deep learning algorithm can be trained to predict levels of ulcerative colitis severity from full-length endoscopy videos. Our data set was prospectively collected in a multinational clinical trial, videos rather than still images were used, UCEIS and eMS were reported, and MLA performance metrics met or exceeded those previously published for UC severity scores.",33098883
"Detection of Pathogenic Variants With Germline Genetic Testing Using DeepLearning vs Standard Methods in Patients With Prostate Cancer and Melanoma.. Importance: Less than 10% of patients with cancer have detectable pathogenic germline alterations, which may be partially due to incomplete pathogenic variant detection.  Objective: To evaluate if deep learning approaches identify more germline pathogenic variants in patients with cancer.  Design, setting, and participants: A cross-sectional study of a standard germline detection method and a deep learning method in 2 convenience cohorts with prostate cancer and melanoma enrolled in the US and Europe between 2010 and 2017. The final date of clinical data collection was December 2017.  Exposures: Germline variant detection using standard or deep learning methods.  Main outcomes and measures: The primary outcomes included pathogenic variant detection performance in 118 cancer-predisposition genes estimated as sensitivity, specificity, positive predictive value (PPV), and negative predictive value (NPV). The secondary outcomes were pathogenic variant detection performance in 59 genes deemed actionable by the American College of Medical Genetics and Genomics (ACMG) and 5197 clinically relevant mendelian genes. True sensitivity and true specificity could not be calculated due to lack of a criterion reference standard, but were estimated as the proportion of true-positive variants and true-negative variants, respectively, identified by each method in a reference variant set that consisted of all variants judged to be valid from either approach.  Results: The prostate cancer cohort included 1072 men (mean [SD] age at diagnosis, 63.7 [7.9] years; 857 [79.9%] with European ancestry) and the melanoma cohort included 1295 patients (mean [SD] age at diagnosis, 59.8 [15.6] years; 488 [37.7%] women; 1060 [81.9%] with European ancestry). The deep learning method identified more patients with pathogenic variants in cancer-predisposition genes than the standard method (prostate cancer: 198 vs 182; melanoma: 93 vs 74); sensitivity (prostate cancer: 94.7% vs 87.1% [difference, 7.6%; 95% CI, 2.2% to 13.1%]; melanoma: 74.4% vs 59.2% [difference, 15.2%; 95% CI, 3.7% to 26.7%]), specificity (prostate cancer: 64.0% vs 36.0% [difference, 28.0%; 95% CI, 1.4% to 54.6%]; melanoma: 63.4% vs 36.6% [difference, 26.8%; 95% CI, 17.6% to 35.9%]), PPV (prostate cancer: 95.7% vs 91.9% [difference, 3.8%; 95% CI, -1.0% to 8.4%]; melanoma: 54.4% vs 35.4% [difference, 19.0%; 95% CI, 9.1% to 28.9%]), and NPV (prostate cancer: 59.3% vs 25.0% [difference, 34.3%; 95% CI, 10.9% to 57.6%]; melanoma: 80.8% vs 60.5% [difference, 20.3%; 95% CI, 10.0% to 30.7%]). For the ACMG genes, the sensitivity of the 2 methods was not significantly different in the prostate cancer cohort (94.9% vs 90.6% [difference, 4.3%; 95% CI, -2.3% to 10.9%]), but the deep learning method had a higher sensitivity in the melanoma cohort (71.6% vs 53.7% [difference, 17.9%; 95% CI, 1.82% to 34.0%]). The deep learning method had higher sensitivity in the mendelian genes (prostate cancer: 99.7% vs 95.1% [difference, 4.6%; 95% CI, 3.0% to 6.3%]; melanoma: 91.7% vs 86.2% [difference, 5.5%; 95% CI, 2.2% to 8.8%]).  Conclusions and relevance: Among a convenience sample of 2 independent cohorts of patients with prostate cancer and melanoma, germline genetic testing using deep learning, compared with the current standard genetic testing method, was associated with higher sensitivity and specificity for detection of pathogenic variants. Further research is needed to understand the relevance of these findings with regard to clinical outcomes.",33201204
"Artificial Intelligence for Intraoperative Guidance: Using Semantic Segmentation to Identify Surgical Anatomy During Laparoscopic Cholecystectomy.. Objective: To develop and evaluate the performance of artificial intelligence (AI) models that can identify safe and dangerous zones of dissection, and anatomical landmarks during laparoscopic cholecystectomy (LC).  Summary background data: Many adverse events during surgery occur due to errors in visual perception and judgment leading to misinterpretation of anatomy. Deep learning, a subfield of AI, can potentially be used to provide real-time guidance intraoperatively.  Methods: Deep learning models were developed and trained to identify safe (Go) and dangerous (No-Go) zones of dissection, liver, gallbladder, and hepatocystic triangle during LC. Annotations were performed by four high-volume surgeons. AI predictions were evaluated using 10-fold cross-validation against annotations by expert surgeons. Primary outcomes were intersection-over-union (IOU) and F1 score (validated spatial correlation indices), and secondary outcomes were pixel-wise accuracy, sensitivity, specificity, ± standard deviation.  Results: AI models were trained on 2627 random frames from 290 LC videos, procured from 37 countries, 136 institutions and 153 surgeons. Mean IOU, F1 score, accuracy, sensitivity, and specificity for the AI to identify Go zones were 0.53 (±0.24), 0.70 (±0.28), 0.94 (±0.05), 0.69 (±0.20) and 0.94 (±0.03) respectively. For No-Go zones, these metrics were 0.71 (±0.29), 0.83 (±0.31), 0.95 (±0.06), 0.80 (±0.21) and 0.98 (±0.05), respectively. Mean IOU for identification of the liver, gallbladder and hepatocystic triangle were: 0.86 (±0.12), 0.72 (±0.19) and 0.65 (±0.22), respectively.  Conclusions: AI can be used to identify anatomy within the surgical field. This technology may eventually be used to provide real-time guidance and minimize the risk of adverse events.",33196488
"Deep Learning for Detecting Cerebral Aneurysms with CT Angiography.. Background Cerebral aneurysm detection is a challenging task. Deep learning may become a supportive tool for more accurate interpretation. Purpose To develop a highly sensitive deep learning-based algorithm that assists in the detection of cerebral aneurysms on CT angiography images. Materials and Methods Head CT angiography images were retrospectively retrieved from two hospital databases acquired across four different scanners between January 2015 and June 2019. The data were divided into training and validation sets; 400 additional independent CT angiograms acquired between July and December 2019 were used for external validation. A deep learning-based algorithm was constructed and assessed. Both internal and external validation were performed. Jackknife alternative free-response receiver operating characteristic analysis was performed. Results A total of 1068 patients (mean age, 57 years ± 11 [standard deviation]; 660 women) were evaluated for a total of 1068 CT angiograms encompassing 1337 cerebral aneurysms. Of these, 534 CT angiograms (688 aneurysms) were assigned to the training set, and the remaining 534 CT angiograms (649 aneurysms) constituted the validation set. The sensitivity of the proposed algorithm for detecting cerebral aneurysms was 97.5% (633 of 649; 95% CI: 96.0, 98.6). Moreover, eight new aneurysms that had been overlooked in the initial reports were detected (1.2%, eight of 649). With the aid of the algorithm, the overall performance of radiologists in terms of area under the weighted alternative free-response receiver operating characteristic curve was higher by 0.01 (95% CI: 0.00, 0.03). Conclusion The proposed deep learning algorithm assisted radiologists in detecting cerebral aneurysms on CT angiography images, resulting in a higher detection rate. ",33141003
"Deep pyramid local attention neural network for cardiac structure segmentation in two-dimensional echocardiography.. Automatic semantic segmentation in 2D echocardiography is vital in clinical practice for assessing various cardiac functions and improving the diagnosis of cardiac diseases. However, two distinct problems have persisted in automatic segmentation in 2D echocardiography, namely the lack of an effective feature enhancement approach for contextual feature capture and lack of label coherence in category prediction for individual pixels. Therefore, in this study, we propose a deep learning model, called deep pyramid local attention neural network (PLANet), to improve the segmentation performance of automatic methods in 2D echocardiography. Specifically, we propose a pyramid local attention module to enhance features by capturing supporting information within compact and sparse neighboring contexts. We also propose a label coherence learning mechanism to promote prediction consistency for pixels and their neighbors by guiding the learning with explicit supervision signals. The proposed PLANet was extensively evaluated on the dataset of cardiac acquisitions for multi-structure ultrasound segmentation (CAMUS) and sub-EchoNet-Dynamic, which are two large-scale and public 2D echocardiography datasets. The experimental results show that PLANet performs better than traditional and deep learning-based segmentation methods on geometrical and clinical metrics. Moreover, PLANet can complete the segmentation of heart structures in 2D echocardiography in real time, indicating a potential to assist cardiologists accurately and efficiently.",33129143
"Validation of a Machine Learning Algorithm to Predict 180-Day Mortality for Outpatients With Cancer.. Importance: Machine learning (ML) algorithms can identify patients with cancer at risk of short-term mortality to inform treatment and advance care planning. However, no ML mortality risk prediction algorithm has been prospectively validated in oncology or compared with routinely used prognostic indices. Objective: To validate an electronic health record-embedded ML algorithm that generated real-time predictions of 180-day mortality risk in a general oncology cohort. Design, setting, and participants: This prognostic study comprised a prospective cohort of patients with outpatient oncology encounters between March 1, 2019, and April 30, 2019. An ML algorithm, trained on retrospective data from a subset of practices, predicted 180-day mortality risk between 4 and 8 days before a patient's encounter. Patient encounters took place in 18 medical or gynecologic oncology practices, including 1 tertiary practice and 17 general oncology practices, within a large US academic health care system. Patients aged 18 years or older with outpatient oncology or hematology and oncology encounters were included in the analysis. Patients were excluded if their appointment was scheduled after weekly predictions were generated and if they were only evaluated in benign hematology, palliative care, or rehabilitation practices. Exposures: Gradient-boosting ML binary classifier. Main outcomes and measures: The primary outcome was the patients' 180-day mortality from the index encounter. The primary performance metric was the area under the receiver operating characteristic curve (AUC). Results: Among 24 582 patients, 1022 (4.2%) died within 180 days of their index encounter. Their median (interquartile range) age was 64.6 (53.6-73.2) years, 15 319 (62.3%) were women, 18 015 (76.0%) were White, and 10 658 (43.4%) were seen in the tertiary practice. The AUC was 0.89 (95% CI, 0.88-0.90) for the full cohort. The AUC varied across disease-specific groups within the tertiary practice (AUC ranging from 0.74 to 0.96) but was similar between the tertiary and general oncology practices. At a prespecified 40% mortality risk threshold used to differentiate high- vs low-risk patients, observed 180-day mortality was 45.2% (95% CI, 41.3%-49.1%) in the high-risk group vs 3.1% (95% CI, 2.9%-3.3%) in the low-risk group. Integrating the algorithm into the Eastern Cooperative Oncology Group and Elixhauser comorbidity index-based classifiers resulted in favorable reclassification (net reclassification index, 0.09 [95% CI, 0.04-0.14] and 0.23 [95% CI, 0.20-0.27], respectively). Conclusions and relevance: In this prognostic study, an ML algorithm was feasibly integrated into the electronic health record to generate real-time, accurate predictions of short-term mortality for patients with cancer and outperformed routinely used prognostic indices. This algorithm may be used to inform behavioral interventions and prompt earlier conversations about goals of care and end-of-life preferences among patients with cancer.",32970131
"Deep-Learning Resources for Studying Glycan-Mediated Host-Microbe Interactions.. Glycans, the most diverse biopolymer, are shaped by evolutionary pressures stemming from host-microbe interactions. Here, we present machine learning and bioinformatics methods to leverage the evolutionary information present in glycans to gain insights into how pathogens and commensals interact with hosts. By using techniques from natural language processing, we develop deep-learning models for glycans that are trained on a curated dataset of 19,299 unique glycans and can be used to study and predict glycan functions. We show that these models can be utilized to predict glycan immunogenicity and the pathogenicity of bacterial strains, as well as investigate glycan-mediated immune evasion via molecular mimicry. We also develop glycan-alignment methods and use these to analyze virulence-determining glycan motifs in the capsular polysaccharides of bacterial pathogens. These resources enable one to identify and study glycan motifs involved in immunogenicity, pathogenicity, molecular mimicry, and immune evasion, expanding our understanding of host-microbe interactions.",33120114
"Artificial Intelligence Applied to Breast MRI for Improved Diagnosis.. Background Recognition of salient MRI morphologic and kinetic features of various malignant tumor subtypes and benign diseases, either visually or with artificial intelligence (AI), allows radiologists to improve diagnoses that may improve patient treatment. Purpose To evaluate whether the diagnostic performance of radiologists in the differentiation of cancer from noncancer at dynamic contrast material-enhanced (DCE) breast MRI is improved when using an AI system compared with conventionally available software. Materials and Methods In a retrospective clinical reader study, images from breast DCE MRI examinations were interpreted by 19 breast imaging radiologists from eight academic and 11 private practices. Readers interpreted each examination twice. In the ""first read,"" they were provided with conventionally available computer-aided evaluation software, including kinetic maps. In the ""second read,"" they were also provided with AI analytics through computer-aided diagnosis software. Reader diagnostic performance was evaluated with receiver operating characteristic (ROC) analysis, with the area under the ROC curve (AUC) as a figure of merit in the task of distinguishing between malignant and benign lesions. The primary study end point was the difference in AUC between the first-read and the second-read conditions. Results One hundred eleven women (mean age, 52 years ± 13 [standard deviation]) were evaluated with a total of 111 breast DCE MRI examinations (54 malignant and 57 nonmalignant lesions). The average AUC of all readers improved from 0.71 to 0.76 (P = .04) when using the AI system. The average sensitivity improved when Breast Imaging Reporting and Data System (BI-RADS) category 3 was used as the cut point (from 90% to 94%; 95% confidence interval [CI] for the change: 0.8%, 7.4%) but not when using BI-RADS category 4a (from 80% to 85%; 95% CI: -0.9%, 11%). The average specificity showed no difference when using either BI-RADS category 4a or category 3 as the cut point (52% and 52% [95% CI: -7.3%, 6.0%], and from 29% to 28% [95% CI: -6.4%, 4.3%], respectively). Conclusion Use of an artificial intelligence system improves radiologists' performance in the task of differentiating benign and malignant MRI breast lesions.",33078996
"Pain management in hidradenitis suppurativa and a proposed treatment algorithm.. Pain contributes substantially to reduced quality of life in individuals living with hidradenitis suppurativa (HS). Although improved understanding of HS pathogenesis and treatment has resulted in improved evidence-based HS management guidelines, comprehensive pain management guidelines have yet to be developed. Little HS-specific data exist to guide pharmacologic analgesia, however, recognizing HS pain as either acute or chronic and predominantly nociceptive (aching and gnawing pain due to tissue damage) versus neuropathic (burning type pain due to somatosensory nervous system dysfunction) provides a conceptual framework for applying outside pain management practices to HS management. This manuscript incorporates the best available evidence from the HS and pain literature to propose an HS pain algorithm that integrates psychological, pharmacological, and complementary and alternative treatment modalities. Keywords: Hidradenitis suppurativa; acute pain; chronic pain; neuropathic; nociceptive; pain management; treatment.",32950543
"If deep learning is the answer, what is the question?. Neuroscience research is undergoing a minor revolution. Recent advances in machine learning and artificial intelligence research have opened up new ways of thinking about neural computation. Many researchers are excited by the possibility that deep neural networks may offer theories of perception, cognition and action for biological brains. This approach has the potential to radically reshape our approach to understanding neural systems, because the computations performed by deep networks are learned from experience, and not endowed by the researcher. If so, how can neuroscientists use deep networks to model and understand biological brains? What is the outlook for neuroscientists who seek to characterize computations or neural codes, or who wish to understand perception, attention, memory and executive functions? In this Perspective, our goal is to offer a road map for systems neuroscience research in the age of deep learning. We discuss the conceptual and methodological challenges of comparing behaviour, learning dynamics and neural representations in artificial and biological systems, and we highlight new research questions that have emerged for neuroscience as a direct consequence of recent advances in machine learning.",33199854
The Emerging Role of Artificial Intelligence in the Fight Against COVID-19.. The coronavirus disease 2019 (COVID-19) pandemic has generated large volumes of clinical data that can be an invaluable resource towards answering a number of important questions for this and future pandemics. Artificial intelligence can have an important role in analysing such data to identify populations at higher risk of COVID-19-related urological pathologies and to suggest treatments that block viral entry into cells by interrupting the angiotensin-converting enzyme 2-transmembrane serine protease 2 (ACE2-TMPRSS2) pathway.,32994064
"Diagnostic Algorithm to Differentiate Benign Atypical Leiomyomas from Malignant Uterine Sarcomas with Diffusion-weighted MRI.. Background Improving the differentiation of uterine sarcomas from atypical leiomyomas remains a clinical challenge and is needed to avoid inappropriate surgery. Purpose To develop a diagnostic algorithm including diffusion-weighted MRI criteria to differentiate malignant uterine sarcomas from benign atypical leiomyomas. Materials and Methods This case-control retrospective study identified women with an atypical uterine mass at MRI between January 2000 and April 2017, with surgery or MRI follow-up after 1 year or longer. A diagnostic algorithm including T2-weighted MRI and diffusion-weighted imaging (DWI) signal and apparent diffusion coefficient (ADC) values was developed to predict for sarcoma. The training set consisted of 51 sarcomas and 105 leiomyomas. Two external validation sets were used to evaluate interreader reproducibility (16 sarcomas; 26 leiomyomas) and impact of reader experience (29 sarcomas; 30 leiomyomas). Wilson confidence intervals (CIs) were calculated for sensitivity and specificity. Results Evaluated were 156 women (median age, 50 years; interquartile range, 44–63 years). Predictive MRI criteria for malignancy were enlarged lymph nodes or peritoneal implants, high DWI signal greater than that in endometrium, and ADC less than or equal to 0.905 × 10−3 mm2/sec. Conversely, a global or focal area of low T2 signal intensity and a low or an intermediate DWI signal less than that in endometrium or lymph nodes allowed readers to confidently diagnose as benign a uterine mass demonstrating one or more of these signs (P < .001) in 100% cases in all three data sets. The sensitivities and specificities of the algorithm for diagnosis of malignancy were 98% (50 of 51 masses; 95% CI: 90%, 100%) and 94% (99 of 105 masses; 95% CI: 88%, 98%) in the training set; 88% (14 of 16 masses; 95% CI: 64%, 97%) and 100% (26 of 26 masses; 95% CI: 87%, 100%) in the validation set; and 83% (24 of 29 masses; 95% CI: 65%, 92%) and 97% (29 of 30 masses; 95% CI: 83%, 99%) for the less experienced reader, respectively. Conclusion A diagnostic algorithm with predictive features including lymphadenopathy, high diffusion-weighted imaging signal with reference to endometrium, and low apparent diffusion coefficient enabled differentiation of malignant sarcomas from atypical leiomyomas, and it may assist inexperienced readers",32930650
"ELNet:Automatic classification and segmentation for esophageal lesions using convolutional neural network.. Automatic and accurate esophageal lesion classification and segmentation is of great significance to clinically estimate the lesion statuses of the esophageal diseases and make suitable diagnostic schemes. Due to individual variations and visual similarities of lesions in shapes, colors, and textures, current clinical methods remain subject to potential high-risk and time-consumption issues. In this paper, we propose an Esophageal Lesion Network (ELNet) for automatic esophageal lesion classification and segmentation using deep convolutional neural networks (DCNNs). The underlying method automatically integrates dual-view contextual lesion information to extract global features and local features for esophageal lesion classification and lesion-specific segmentation network is proposed for automatic esophageal lesion annotation at pixel level. For the established clinical large-scale database of 1051 white-light endoscopic images, ten-fold cross-validation is used in method validation. Experiment results show that the proposed framework achieves classification with sensitivity of 0.9034, specificity of 0.9718, and accuracy of 0.9628, and the segmentation with sensitivity of 0.8018, specificity of 0.9655, and accuracy of 0.9462. All of these indicate that our method enables an efficient, accurate, and reliable esophageal lesion diagnosis in clinics.",33129148
"Insulin dose optimization using an automated artificial intelligence-based decision support system in youths with type 1 diabetes.. Despite the increasing adoption of insulin pumps and continuous glucose monitoring devices, most people with type 1 diabetes do not achieve their glycemic goals1. This could be related to a lack of expertise or inadequate time for clinicians to analyze complex sensor-augmented pump data. We tested whether frequent insulin dose adjustments guided by an automated artificial intelligence-based decision support system (AI-DSS) is as effective and safe as those guided by physicians in controlling glucose levels. ADVICE4U was a six-month, multicenter, multinational, parallel, randomized controlled, non-inferiority trial in 108 participants with type 1 diabetes, aged 10-21 years and using insulin pump therapy (ClinicalTrials.gov no. NCT03003806). Participants were randomized 1:1 to receive remote insulin dose adjustment every three weeks guided by either an AI-DSS, (AI-DSS arm, n = 54) or by physicians (physician arm, n = 54). The results for the primary efficacy measure-the percentage of time spent within the target glucose range (70-180 mg dl-1 (3.9-10.0 mmol l-1))-in the AI-DSS arm were statistically non-inferior to those in the physician arm (50.2 ± 11.1% versus 51.6 ± 11.3%, respectively, P < 1 × 10-7). The percentage of readings below 54 mg dl-1 (<3.0 mmol l-1) within the AI-DSS arm was statistically non-inferior to that in the physician arm (1.3 ± 1.4% versus 1.0 ± 0.9%, respectively, P < 0.0001). Three severe adverse events related to diabetes (two severe hypoglycemia, one diabetic ketoacidosis) were reported in the physician arm and none in the AI-DSS arm. In conclusion, use of an automated decision support tool for optimizing insulin pump settings was non-inferior to intensive insulin titration provided by physicians from specialized academic diabetes centers.",32908282
"Artificial Intelligence in Low- and Middle-Income Countries: Innovating Global Health Radiology.. Scarce or absent radiology resources impede adoption of artificial intelligence (AI) for medical imaging by resource-poor health institutions. They face limitations in local equipment, personnel expertise, infrastructure, data-rights frameworks, and public policies. The trustworthiness of AI for medical decision making in global health and low-resource settings is hampered by insufficient data diversity, nontransparent AI algorithms, and resource-poor health institutions' limited participation in AI production and validation. RAD-AID's three-pronged integrated strategy for AI adoption in resource-poor health institutions is presented, which includes clinical radiology education, infrastructure implementation, and phased AI introduction. This strategy derives from RAD-AID's more-than-a-decade experience as a nonprofit organization developing radiology in resource-poor health institutions, both in the United States and in low- and middle-income countries. The three components synergistically provide the foundation to address health care disparities. Local radiology personnel expertise is augmented through comprehensive education. Software, hardware, and radiologic and networking infrastructure enables radiology workflows incorporating AI. These educational and infrastructure developments occur while RAD-AID delivers phased introduction, testing, and scaling of AI via global health collaborations.",33021895
"Guidelines for clinical trial protocols for interventions involving artificial intelligence: the SPIRIT-AI extension.. The SPIRIT 2013 statement aims to improve the completeness of clinical trial protocol reporting by providing evidence-based recommendations for the minimum set of items to be addressed. This guidance has been instrumental in promoting transparent evaluation of new interventions. More recently, there has been a growing recognition that interventions involving artificial intelligence (AI) need to undergo rigorous, prospective evaluation to demonstrate their impact on health outcomes. The SPIRIT-AI (Standard Protocol Items: Recommendations for Interventional Trials-Artificial Intelligence) extension is a new reporting guideline for clinical trial protocols evaluating interventions with an AI component. It was developed in parallel with its companion statement for trial reports: CONSORT-AI (Consolidated Standards of Reporting Trials-Artificial Intelligence). Both guidelines were developed through a staged consensus process involving literature review and expert consultation to generate 26 candidate items, which were consulted upon by an international multi-stakeholder group in a two-stage Delphi survey (103 stakeholders), agreed upon in a consensus meeting (31 stakeholders) and refined through a checklist pilot (34 participants). The SPIRIT-AI extension includes 15 new items that were considered sufficiently important for clinical trial protocols of AI interventions. These new items should be routinely reported in addition to the core SPIRIT 2013 items. SPIRIT-AI recommends that investigators provide clear descriptions of the AI intervention, including instructions and skills required for use, the setting in which the AI intervention will be integrated, considerations for the handling of input and output data, the human-AI interaction and analysis of error cases. SPIRIT-AI will help promote transparency and completeness for clinical trial protocols for AI interventions. Its use will assist editors and peer reviewers, as well as the general readership, to understand, interpret and critically appraise the design and risk of bias for a planned clinical trial.",32908284
"Image-level detection of arterial occlusions in 4D-CTA of acute stroke patients using deep learning.. The triage of acute stroke patients is increasingly dependent on four-dimensional CTA (4D-CTA) imaging. In this work, we present a convolutional neural network (CNN) for image-level detection of intracranial anterior circulation artery occlusions in 4D-CTA. The method uses a normalized 3D time-to-signal (TTS) representation of the input image, which is sensitive to differences in the global arrival times caused by the potential presence of vascular pathologies. The TTS map presents the time within the cranial cavity at which the signal reaches a percentage of the maximum signal intensity, corrected for the baseline intensity. The method was trained and validated on (n=214) patient images and tested on an independent set of (n=279) patient images. This test set included all consecutive suspected-stroke patients admitted to our hospital in 2018. The accuracy, sensitivity, and specificity were 92%, 95%, and 92%. The area under the receiver operating characteristics curve was 0.98 (95% CI: 0.95- 0.99). These results show the feasibility of automated stroke triage in 4D-CTA.",32920477
"The application of artificial intelligence for the diagnosis and treatment of liver diseases.. Modern medical care produces large volumes of multi-modal patient data, which many clinicians struggle to process and synthesize into actionable knowledge. In recent years, artificial intelligence (AI) has emerged as an effective tool in this regard. The field of hepatology is no exception, with a growing number of studies published that apply artificial intelligence techniques to the diagnosis and treatment of liver diseases. These have included Machine Learning algorithms (such as regression models, Bayesian networks, and support vector machines) to predict disease progression, the presence of complications, and mortality; Deep Learning algorithms to enable rapid, automated interpretation of radiologic and pathologic images; and Natural Language Processing to extract clinically meaningful concepts from vast quantities of unstructured data in Electronic Health Records. This review article will provide a comprehensive overview of hepatology-focused AI research, discuss some of the barriers to clinical implementation and adoption, and suggest future directions for the field.  ",33098140
"Thin-slice Pituitary MRI with Deep Learning-based Reconstruction: Diagnostic Performance in a Postoperative Setting.. Background Achieving high-spatial-resolution pituitary MRI is challenging because of the trade-off between image noise and spatial resolution. Deep learning-based MRI reconstruction enables image denoising with sharp edges and reduced artifacts, which improves the image quality of thin-slice MRI. Purpose To assess the diagnostic performance of 1-mm slice thickness MRI with deep learning-based reconstruction (DLR) (hereafter, 1-mm MRI+DLR) compared with 3-mm slice thickness MRI (hereafter, 3-mm MRI) for identifying residual tumor and cavernous sinus invasion in the evaluation of postoperative pituitary adenoma. Materials and Methods This single-institution retrospective study included 65 patients (mean age ± standard deviation, 54 years ± 10; 26 women) who underwent a combined imaging protocol including 3-mm MRI and 1-mm MRI+DLR for postoperative evaluation of pituitary adenoma between August and October 2019. Reference standards for correct diagnosis were established by using all available imaging resources, clinical histories, laboratory findings, surgical records, and pathology reports. The diagnostic performances of 3-mm MRI, 1-mm slice thickness MRI without DLR (hereafter, 1-mm MRI), and 1-mm MRI+DLR for identifying residual tumor and cavernous sinus invasion were evaluated by two readers and compared between the protocols. Results The performance of 1-mm MRI+DLR in the identification of residual tumor was comparable to that of 3-mm MRI (area under the receiver operating characteristic curve [AUC], 0.89-0.92 vs 0.85-0.89, respectively; P ≥ .09). In the identification of cavernous sinus invasion, the diagnostic performance of 1-mm MRI+DLR was higher than that of 3-mm MRI (AUC, 0.95-0.98 vs 0.83-0.87, respectively; P ≤ .02). Conventional 1-mm MRI (AUC, 0.82-0.83) showed comparable diagnostic performance to 3-mm MRI (AUC, 0.83-0.87) (P ≥ .38). With 1-mm MRI+DLR, residual tumor was diagnosed in 20 patients and cavernous sinus invasion was diagnosed in 14 patients, in whom these diagnoses were not made with 3-mm MRI. Conclusion In the postoperative evaluation of pituitary adenoma, 1-mm slice thickness MRI with deep learning-based reconstruction showed higher diagnostic performance than 3-mm slice thickness MRI in the identification of cavernous sinus invasion and comparable diagnostic performance to 3-mm slice thickness MRI in the identification of residual tumor. ",33141001
"Elastic Registration-driven Deep Learning for Longitudinal Assessment of Systemic Sclerosis Interstitial Lung Disease at CT.. Background Longitudinal follow-up of interstitial lung diseases (ILDs) at CT mainly relies on the evaluation of the extent of ILD, without accounting for lung shrinkage. Purpose To develop a deep learning-based method to depict worsening of ILD based on lung shrinkage detection from elastic registration of chest CT scans in patients with systemic sclerosis (SSc). Materials and Methods Patients with SSc evaluated between January 2009 and October 2017 who had undergone at least two unenhanced supine CT scans of the chest and pulmonary function tests (PFTs) performed within 3 months were retrospectively included. Morphologic changes on CT scans were visually assessed by two observers and categorized as showing improvement, stability, or worsening of ILD. Elastic registration between baseline and follow-up CT images was performed to obtain deformation maps of the whole lung. Jacobian determinants calculated from the deformation maps were given as input to a deep learning-based classifier to depict morphologic and functional worsening. For this purpose, the set was randomly split into training, validation, and test sets. Correlations between mean Jacobian values and changes in PFT measurements were evaluated with the Spearman correlation. Results A total of 212 patients (median age, 53 years; interquartile range, 45-62 years; 177 women) were included as follows: 138 for the training set (65%), 34 for the validation set (16%), and 40 for the test set (21%). Jacobian maps demonstrated lung parenchyma shrinkage of the posterior lung bases in patients found to have worsened ILD at visual assessment. The classifier detected morphologic and functional worsening with an accuracy of 80% (32 of 40 patients; 95% confidence interval [CI]: 64%, 91%) and 83% (33 of 40 patients; 95% CI: 67%, 93%), respectively. Jacobian values correlated with changes in forced vital capacity (R = -0.38; 95% CI: -0.25, -0.49; P < .001) and diffusing capacity for carbon monoxide (R = -0.42; 95% CI: -0.27, -0.54; P < .001). Conclusion Elastic registration of CT scans combined with a deep learning classifier aided in the diagnosis of morphologic and functional worsening of interstitial lung disease in patients with systemic sclerosis.",33078999
"Re-Identification and growth detection of pulmonary nodules without image registration using 3D siamese neural networks.. Lung cancer follow-up is a complex, error prone, and time consuming task for clinical radiologists. Several lung CT scan images taken at different time points of a given patient need to be individually inspected, looking for possible cancerogenous nodules. Radiologists mainly focus their attention in nodule size, density, and growth to assess the existence of malignancy. In this study, we present a novel method based on a 3D siamese neural network, for the re-identification of nodules in a pair of CT scans of the same patient without the need for image registration. The network was integrated into a two-stage automatic pipeline to detect, match, and predict nodule growth given pairs of CT scans. Results on an independent test set reported a nodule detection sensitivity of 94.7%, an accuracy for temporal nodule matching of 88.8%, and a sensitivity of 92.0% with a precision of 88.4% for nodule growth detection.",33075637
Outcomes of Adversarial Attacks on Deep Learning Models for Ophthalmology Imaging Domains.. This study investigates whether adversarial attacks can confuse deep learning systems based on imaging domains.,33001161
"Quantitative Analysis of OCT for Neovascular Age-Related Macular Degeneration Using Deep Learning.. Purpose: To apply a deep learning algorithm for automated, objective, and comprehensive quantification of OCT scans to a large real-world dataset of eyes with neovascular age-related macular degeneration (AMD) and make the raw segmentation output data openly available for further research. Design: Retrospective analysis of OCT images from the Moorfields Eye Hospital AMD Database. Participants: A total of 2473 first-treated eyes and 493 second-treated eyes that commenced therapy for neovascular AMD between June 2012 and June 2017. Methods: A deep learning algorithm was used to segment all baseline OCT scans. Volumes were calculated for segmented features such as neurosensory retina (NSR), drusen, intraretinal fluid (IRF), subretinal fluid (SRF), subretinal hyperreflective material (SHRM), retinal pigment epithelium (RPE), hyperreflective foci (HRF), fibrovascular pigment epithelium detachment (fvPED), and serous PED (sPED). Analyses included comparisons between first- and second-treated eyes by visual acuity (VA) and race/ethnicity and correlations between volumes. Main outcome measures: Volumes of segmented features (mm3) and central subfield thickness (CST) (μm). Results: In first-treated eyes, the majority had both IRF and SRF (54.7%). First-treated eyes had greater volumes for all segmented tissues, with the exception of drusen, which was greater in second-treated eyes. In first-treated eyes, older age was associated with lower volumes for RPE, SRF, NSR, and sPED; in second-treated eyes, older age was associated with lower volumes of NSR, RPE, sPED, fvPED, and SRF. Eyes from Black individuals had higher SRF, RPE, and serous PED volumes compared with other ethnic groups. Greater volumes of the majority of features were associated with worse VA. Conclusions: We report the results of large-scale automated quantification of a novel range of baseline features in neovascular AMD. Major differences between first- and second-treated eyes, with increasing age, and between ethnicities are highlighted. In the coming years, enhanced, automated OCT segmentation may assist personalization of real-world care and the detection of novel structure-function correlations. These data will be made publicly available for replication and future investigation by the AMD research community.",32980396
"The reliability of a deep learning model in clinical out-of-distribution MRI data: A multicohort study.. Deep learning (DL) methods have in recent years yielded impressive results in medical imaging, with the potential to function as clinical aid to radiologists. However, DL models in medical imaging are often trained on public research cohorts with images acquired with a single scanner or with strict protocol harmonization, which is not representative of a clinical setting. The aim of this study was to investigate how well a DL model performs in unseen clinical datasets-collected with different scanners, protocols and disease populations-and whether more heterogeneous training data improves generalization. In total, 3117 MRI scans of brains from multiple dementia research cohorts and memory clinics, that had been visually rated by a neuroradiologist according to Scheltens' scale of medial temporal atrophy (MTA), were included in this study. By training multiple versions of a convolutional neural network on different subsets of this data to predict MTA ratings, we assessed the impact of including images from a wider distribution during training had on performance in external memory clinic data. Our results showed that our model generalized well to datasets acquired with similar protocols as the training data, but substantially worse in clinical cohorts with visibly different tissue contrasts in the images. This implies that future DL studies investigating performance in out-of-distribution (OOD) MRI data need to assess multiple external cohorts for reliable results. Further, by including data from a wider range of scanners and protocols the performance improved in OOD data, which suggests that more heterogeneous training data makes the model generalize better. To conclude, this is the most comprehensive study to date investigating the domain shift in deep learning on MRI data, and we advocate rigorous evaluation of DL models on clinical data prior to being certified for deployment.",33007638
"Convolutional neural networks for the automatic diagnosis of melanoma: An extensive experimental study.. Melanoma is the type of skin cancer with the highest levels of mortality, and it is more dangerous because it can spread to other parts of the body if not caught and treated early. Melanoma diagnosis is a complex task, even for expert dermatologists, mainly due to the great variety of morphologies in moles of patients. Accordingly, the automatic diagnosis of melanoma is a task that poses the challenge of developing efficient computational methods that ease the diagnostic and, therefore, aid dermatologists in decision-making. In this work, an extensive analysis was conducted, aiming at assessing and illustrating the effectiveness of convolutional neural networks in coping with this complex task. To achieve this objective, twelve well-known convolutional network models were evaluated on eleven public image datasets. The experimental study comprised five phases, where first it was analyzed the sensitivity of the models regarding the optimization algorithm used for their training, and then it was analyzed the impact in performance when using different techniques such as cost-sensitive learning, data augmentation and transfer learning. The conducted study confirmed the usefulness, effectiveness and robustness of different convolutional architectures in solving melanoma diagnosis problem. Also, important guidelines to researchers working on this area were provided, easing the selection of both the proper convolutional model and technique according the characteristics of data.",33129155
"Performance of a Deep Learning Algorithm Compared with Radiologic Interpretation for Lung Cancer Detection on Chest Radiographs in a Health Screening Population.. Background The performance of a deep learning algorithm for lung cancer detection on chest radiographs in a health screening population is unknown. Purpose To validate a commercially available deep learning algorithm for lung cancer detection on chest radiographs in a health screening population. Materials and Methods Out-of-sample testing of a deep learning algorithm was retrospectively performed using chest radiographs from individuals undergoing a comprehensive medical check-up between July 2008 and December 2008 (validation test). To evaluate the algorithm performance for visible lung cancer detection, the area under the receiver operating characteristic curve (AUC) and diagnostic measures, including sensitivity and false-positive rate (FPR), were calculated. The algorithm performance was compared with that of radiologists using the McNemar test and the Moskowitz method. Additionally, the deep learning algorithm was applied to a screening cohort undergoing chest radiography between January 2008 and December 2012, and its performances were calculated. Results In a validation test comprising 10 285 radiographs from 10 202 individuals (mean age, 54 years ± 11 [standard deviation]; 5857 men) with 10 radiographs of visible lung cancers, the algorithm's AUC was 0.99 (95% confidence interval: 0.97, 1), and it showed comparable sensitivity (90% [nine of 10 radiographs]) to that of the radiologists (60% [six of 10 radiographs]; P = .25) with a higher FPR (3.1% [319 of 10 275 radiographs] vs 0.3% [26 of 10 275 radiographs]; P < .001). In the screening cohort of 100 525 chest radiographs from 50 070 individuals (mean age, 53 years ± 11; 28 090 men) with 47 radiographs of visible lung cancers, the algorithm's AUC was 0.97 (95% confidence interval: 0.95, 0.99), and its sensitivity and FPR were 83% (39 of 47 radiographs) and 3% (2999 of 100 478 radiographs), respectively. Conclusion A deep learning algorithm detected lung cancers on chest radiographs with a performance comparable to that of radiologists, which will be helpful for radiologists in healthy populations with a low prevalence of lung cancer. © RSNA, 2020 Online supplemental material is available for this article. See also the editorial by Armato in this issue.",32960729
"Accurate brain age prediction with lightweight deep neural networks.. Deep learning has huge potential for accurate disease prediction with neuroimaging data, but the prediction performance is often limited by training-dataset size and computing memory requirements. To address this, we propose a deep convolutional neural network model, Simple Fully Convolutional Network (SFCN), for accurate prediction of brain age using T1-weighted structural MRI data. Compared with other popular deep network architectures, SFCN has fewer parameters, so is more compatible with small dataset size and 3D volume data. The network architecture was combined with several techniques for boosting performance, including data augmentation, pre-training, model regularization, model ensemble and prediction bias correction. We compared our overall SFCN approach with several widely-used machine learning models. It achieved state-of-the-art performance in UK Biobank data (N = 14,503), with mean absolute error (MAE) = 2.14y in brain age prediction and 99.5% in sex classification. SFCN also won (both parts of) the 2019 Predictive Analysis Challenge for brain age prediction, involving 79 competing teams (N = 2,638, MAE = 2.90y). We describe here the details of our approach, and its optimisation and validation. Our approach can easily be generalised to other tasks using different image modalities, and is released on GitHub.",33197716
"Difficulty-aware hierarchical convolutional neural networks for deformable registration of brain MR images.. The aim of deformable brain image registration is to align anatomical structures, which can potentially vary with large and complex deformations. Anatomical structures vary in size and shape, requiring the registration algorithm to estimate deformation fields at various degrees of complexity. Here, we present a difficulty-aware model based on an attention mechanism to automatically identify hard-to-register regions, allowing better estimation of large complex deformations. The difficulty-aware model is incorporated into a cascaded neural network consisting of three sub-networks to fully leverage both global and local contextual information for effective registration. The first sub-network is trained at the image level to predict a coarse-scale deformation field, which is then used for initializing the subsequent sub-network. The next two sub-networks progressively optimize at the patch level with different resolutions to predict a fine-scale deformation field. Embedding difficulty-aware learning into the hierarchical neural network allows harder patches to be identified in the deeper sub-networks at higher resolutions for refining the deformation field. Experiments conducted on four public datasets validate that our method achieves promising registration accuracy with better preservation of topology, compared with state-of-the-art registration methods.",33129152
"Incorporating historical sub-optimal deep neural networks for dose prediction in radiotherapy.. As the main treatment for cancer patients, radiotherapy has achieved enormous advancement over recent decades. However, these achievements have come at the cost of increased treatment plan complexity, necessitating high levels of expertise experience and effort. The accurate prediction of dose distribution would alleviate the above issues. Deep convolutional neural networks are known to be effective models for such prediction tasks. Most studies on dose prediction have attempted to modify the network architecture to accommodate the requirement of different diseases. In this paper, we focus on the input and output of dose prediction model, rather than the network architecture. Regarding the input, the non-modulated dose distribution, which is the initial quantity in the inverse optimization of the treatment plan, is used to provide auxiliary information for the prediction task. Regarding the output, a historical sub-optimal ensemble (HSE) method is proposed, which leverages the sub-optimal models during the training phase to improve the prediction results. The proposed HSE is a general method that does not require any modification of the learning algorithm and does not incur additional computational cost during the training phase. Multiple experiments, including the dose prediction, segmentation, and classification tasks, demonstrate the effectiveness of the strategies applied to the input and output parts.",33166773
"Automated Recognition of Regional Wall Motion Abnormalities Through Deep Neural Network Interpretation of Transthoracic Echocardiography.. Background: Automated interpretation of echocardiography by deep neural networks could support clinical reporting and improve efficiency. Whereas previous studies have evaluated spatial relationships using still frame images, we aimed to train and test a deep neural network for video analysis by combining spatial and temporal information, to automate the recognition of left ventricular regional wall motion abnormalities. Methods: We collected a series of transthoracic echocardiography examinations performed between July 2017 and April 2018 in 2 tertiary care hospitals. Regional wall abnormalities were defined by experienced physiologists and confirmed by trained cardiologists. First, we developed a 3-dimensional convolutional neural network model for view selection ensuring stringent image quality control. Second, a U-net model segmented images to annotate the location of each left ventricular wall. Third, a final 3-dimensional convolutional neural network model evaluated echocardiographic videos from 4 standard views, before and after segmentation, and calculated a wall motion abnormality confidence level (0-1) for each segment. To evaluate model stability, we performed 5-fold cross-validation and external validation. Results: In a series of 10 638 echocardiograms, our view selection model identified 6454 (61%) examinations with sufficient image quality in all standard views. In this training set, 2740 frames were annotated to develop the segmentation model, which achieved a Dice similarity coefficient of 0.756. External validation was performed in 1756 examinations from an independent hospital. A regional wall motion abnormality was observed in 8.9% and 4.9% in the training and external validation datasets, respectively. The final model recognized regional wall motion abnormalities in the cross-validation and external validation datasets with an area under the receiver operating characteristic curve of 0.912 (95% CI, 0.896-0.928) and 0.891 (95% CI, 0.834-0.948), respectively. In the external validation dataset, the sensitivity was 81.8% (95% CI, 73.8%-88.2%), and specificity was 81.6% (95% CI, 80.4%-82.8%). Conclusions: In echocardiographic examinations of sufficient image quality, it is feasible for deep neural networks to automate the recognition of regional wall motion abnormalities using temporal and spatial information from moving images. Further investigation is required to optimize model performance and evaluate clinical applications.",32964749
"Subvoxel vessel wall thickness measurements of the intracranial arteries using a convolutional neural network.. Vessel wall thickening of the intracranial arteries has been associated with cerebrovascular disease and atherosclerotic plaque development. Visualization of the vessel wall has been enabled by recent advancements in vessel wall MRI. However, quantifying early wall thickening from these MR images is difficult and prone to severe overestimation, because the voxel size of clinically used acquisitions exceeds the wall thickness of the intracranial arteries. In this study, we aimed for accurate and precise subvoxel vessel wall thickness measurements. A convolutional neural network was trained on MR images of 34 ex vivo circle of Willis specimens, acquired with a clinically used protocol (isotropic acquired voxel size: 0.8 mm). Ground truth measurements were performed on images acquired with an ultra-high-resolution protocol (isotropic acquired voxel size: 0.11 mm) and were used for evaluation. Additionally, we determined the robustness of our method by applying Monte Carlo dropout and test time augmentation. Lastly, we applied our method on in vivo images of three intracranial aneurysms to measure their wall thickness. Our method shows resolvability of different vessel wall thicknesses, well below the acquired voxel size. The method described may facilitate quantitative measurements on MRI data for a wider range of clinical applications.",33049576
"New algorithm to quantify cardiopulmonary interaction in patients with atrial fibrillation: a proof-of-concept study.. Background: Traditional formulas to calculate pulse pressure variation (PPV) cannot be used in patients with atrial fibrillation (AF). We have developed a new algorithm that accounts for arrhythmia-induced pulse pressure changes, allowing us to isolate and quantify ventilation-induced pulse pressure variation (VPPV). The robustness of the algorithm was tested in patients subjected to altered loading conditions. We investigated whether changes in VPPV imposed by passive leg raising (PLR) were proportional to the pre-PLR values.  Methods: Consenting patients with active AF scheduled for an ablation of the pulmonary vein under general anaesthesia and mechanical ventilation were included. Loading conditions were altered by PLR. ECG and invasive pressure data were acquired during 60 s periods before and after PLR. A generalised additive model was constructed for each patient on each observation period. The impact of AF was modelled on the two preceding RR intervals of each beat (RR0 and RR-1). The impact of ventilation and the long-term pulse pressure trends were modelled as separate splines. Ventilation-induced pulse pressure variation was defined as the percentage of the maximal change in pulse pressure during the ventilation cycle.  Results: Nine patients were studied. The predictive abilities of the models had a median r2 of 0.92 (inter-quartile range: 89.2-94.2). Pre-PLR VPPV ranged from 0.1% to 27.9%. After PLR, VPPV decreased to 0-11.3% (P<0.014). The relation between the Pre-PLR values and the magnitude of the changes imposed by the PLR was statistically significant (P<0.001).  Conclusions: Our algorithm enables quantification of VPPV in patients with AF with the ability to detect changing loading conditions.",33138963
"Biomechanically constrained non-rigid MR-TRUS prostate registration using deep learning based 3D point cloud matching.. A non-rigid MR-TRUS image registration framework is proposed for prostate interventions. The registration framework consists of a convolutional neural networks (CNN) for MR prostate segmentation, a CNN for TRUS prostate segmentation and a point-cloud based network for rapid 3D point cloud matching. Volumetric prostate point clouds were generated from the segmented prostate masks using tetrahedron meshing. The point cloud matching network was trained using deformation field that was generated by finite element analysis. Therefore, the network implicitly models the underlying biomechanical constraint when performing point cloud matching. A total of 50 patients' datasets were used for the network training and testing. Alignment of prostate shapes after registration was evaluated using three metrics including Dice similarity coefficient (DSC), mean surface distance (MSD) and Hausdorff distance (HD). Internal point-to-point registration accuracy was assessed using target registration error (TRE). Jacobian determinant and strain tensors of the predicted deformation field were calculated to analyze the physical fidelity of the deformation field. On average, the mean and standard deviation were 0.94±0.02, 0.90±0.23 mm, 2.96±1.00 mm and 1.57±0.77 mm for DSC, MSD, HD and TRE, respectively. Robustness of our method to point cloud noise was evaluated by adding different levels of noise to the query point clouds. Our results demonstrated that the proposed method could rapidly perform MR-TRUS image registration with good registration accuracy and robustness.",33129147
"Predicting suicide attempt or suicide death following a visit to psychiatric specialty care: A machine learning study using Swedish national registry data.. Background: Suicide is a major public health concern globally. Accurately predicting suicidal behavior remains challenging. This study aimed to use machine learning approaches to examine the potential of the Swedish national registry data for prediction of suicidal behavior.  Methods and findings: The study sample consisted of 541,300 inpatient and outpatient visits by 126,205 Sweden-born patients (54% female and 46% male) aged 18 to 39 (mean age at the visit: 27.3) years to psychiatric specialty care in Sweden between January 1, 2011 and December 31, 2012. The most common psychiatric diagnoses at the visit were anxiety disorders (20.0%), major depressive disorder (16.9%), and substance use disorders (13.6%). A total of 425 candidate predictors covering demographic characteristics, socioeconomic status (SES), electronic medical records, criminality, as well as family history of disease and crime were extracted from the Swedish registry data. The sample was randomly split into an 80% training set containing 433,024 visits and a 20% test set containing 108,276 visits. Models were trained separately for suicide attempt/death within 90 and 30 days following a visit using multiple machine learning algorithms. Model discrimination and calibration were both evaluated. Among all eligible visits, 3.5% (18,682) were followed by a suicide attempt/death within 90 days and 1.7% (9,099) within 30 days. The final models were based on ensemble learning that combined predictions from elastic net penalized logistic regression, random forest, gradient boosting, and a neural network. The area under the receiver operating characteristic (ROC) curves (AUCs) on the test set were 0.88 (95% confidence interval [CI] = 0.87-0.89) and 0.89 (95% CI = 0.88-0.90) for the outcome within 90 days and 30 days, respectively, both being significantly better than chance (i.e., AUC = 0.50) (p < 0.01). Sensitivity, specificity, and predictive values were reported at different risk thresholds. A limitation of our study is that our models have not yet been externally validated, and thus, the generalizability of the models to other populations remains unknown.  Conclusions: By combining the ensemble method of multiple machine learning algorithms and high-quality data solely from the Swedish registers, we developed prognostic models to predict short-term suicide attempt/death with good discrimination and calibration. Whether novel predictors can improve predictive performance requires further investigation.",33156863
"Association of Ticagrelor vs Clopidogrel With Net Adverse Clinical Events in Patients With Acute Coronary Syndrome Undergoing Percutaneous Coronary Intervention.. Importance: Current guidelines recommend ticagrelor as the preferred P2Y12 platelet inhibitor for patients with acute coronary syndrome (ACS), primarily based on a single large randomized clinical trial. The benefits and risks associated with ticagrelor vs clopidogrel in routine practice merits attention.  Objective: To determine the association of ticagrelor vs clopidogrel with ischemic and hemorrhagic events in patients undergoing percutaneous coronary intervention (PCI) for ACS in clinical practice.  Design, setting, and participants: A retrospective cohort study of patients with ACS who underwent PCI and received ticagrelor or clopidogrel was conducted using 2 United States electronic health record-based databases and 1 nationwide South Korean database from November 2011 to March 2019. Patients were matched using a large-scale propensity score algorithm, and the date of final follow-up was March 2019.  Exposures: Ticagrelor vs clopidogrel.  Main outcomes and measures: The primary end point was net adverse clinical events (NACE) at 12 months, composed of ischemic events (recurrent myocardial infarction, revascularization, or ischemic stroke) and hemorrhagic events (hemorrhagic stroke or gastrointestinal bleeding). Secondary outcomes included NACE or mortality, all-cause mortality, ischemic events, hemorrhagic events, individual components of the primary outcome, and dyspnea at 12 months. The database-level hazard ratios (HRs) were pooled to calculate summary HRs by random-effects meta-analysis.  Results: After propensity score matching among 31 290 propensity-matched pairs (median age group, 60-64 years; 29.3% women), 95.5% of patients took aspirin together with ticagrelor or clopidogrel. The 1-year risk of NACE was not significantly different between ticagrelor and clopidogrel (15.1% [3484/23 116 person-years] vs 14.6% [3290/22 587 person-years]; summary HR, 1.05 [95% CI, 1.00-1.10]; P = .06). There was also no significant difference in the risk of all-cause mortality (2.0% for ticagrelor vs 2.1% for clopidogrel; summary HR, 0.97 [95% CI, 0.81-1.16]; P = .74) or ischemic events (13.5% for ticagrelor vs 13.4% for clopidogrel; summary HR, 1.03 [95% CI, 0.98-1.08]; P = .32). The risks of hemorrhagic events (2.1% for ticagrelor vs 1.6% for clopidogrel; summary HR, 1.35 [95% CI, 1.13-1.61]; P = .001) and dyspnea (27.3% for ticagrelor vs 22.6% for clopidogrel; summary HR, 1.21 [95% CI, 1.17-1.26]; P < .001) were significantly higher in the ticagrelor group.  Conclusions and relevance: Among patients with ACS who underwent PCI in routine clinical practice, ticagrelor, compared with clopidogrel, was not associated with significant difference in the risk of NACE at 12 months. Because the possibility of unmeasured confounders cannot be excluded, further research is needed to determine whether ticagrelor is more effective than clopidogrel in this setting.",33107944
"Discriminative and generative models for anatomical shape analysis on point clouds with deep neural networks.. We introduce deep neural networks for the analysis of anatomical shapes that learn a low-dimensional shape representation from the given task, instead of relying on hand-engineered representations. Our framework is modular and consists of several computing blocks that perform fundamental shape processing tasks. The networks operate on unordered point clouds and provide invariance to similarity transformations, avoiding the need to identify point correspondences between shapes. Based on the framework, we assemble a discriminative model for disease classification and age regression, as well as a generative model for the accruate reconstruction of shapes. In particular, we propose a conditional generative model, where the condition vector provides a mechanism to control the generative process. For instance, it enables to assess shape variations specific to a particular diagnosis, when passing it as side information. Next to working on single shapes, we introduce an extension for the joint analysis of multiple anatomical structures, where the simultaneous modeling of multiple structures can lead to a more compact encoding and a better understanding of disorders. We demonstrate the advantages of our framework in comprehensive experiments on real and synthetic data. The key insights are that (i) learning a shape representation specific to the given task yields higher performance than alternative shape descriptors, (ii) multi-structure analysis is both more efficient and more accurate than single-structure analysis, and (iii) point clouds generated by our model capture morphological differences associated to Alzheimer's disease, to the point that they can be used to train a discriminative model for disease classification. Our framework naturally scales to the analysis of large datasets, giving it the potential to learn characteristic variations in large populations.",33129154
"A global benchmark of algorithms for segmenting the left atrium from late gadolinium-enhanced cardiac magnetic resonance imaging.. Segmentation of medical images, particularly late gadolinium-enhanced magnetic resonance imaging (LGE-MRI) used for visualizing diseased atrial structures, is a crucial first step for ablation treatment of atrial fibrillation. However, direct segmentation of LGE-MRIs is challenging due to the varying intensities caused by contrast agents. Since most clinical studies have relied on manual, labor-intensive approaches, automatic methods are of high interest, particularly optimized machine learning approaches. To address this, we organized the 2018 Left Atrium Segmentation Challenge using 154 3D LGE-MRIs, currently the world's largest atrial LGE-MRI dataset, and associated labels of the left atrium segmented by three medical experts, ultimately attracting the participation of 27 international teams. In this paper, extensive analysis of the submitted algorithms using technical and biological metrics was performed by undergoing subgroup analysis and conducting hyper-parameter analysis, offering an overall picture of the major design choices of convolutional neural networks (CNNs) and practical considerations for achieving state-of-the-art left atrium segmentation. Results show that the top method achieved a Dice score of 93.2% and a mean surface to surface distance of 0.7 mm, significantly outperforming prior state-of-the-art. Particularly, our analysis demonstrated that double sequentially used CNNs, in which a first CNN is used for automatic region-of-interest localization and a subsequent CNN is used for refined regional segmentation, achieved superior results than traditional methods and machine learning approaches containing single CNNs. This large-scale benchmarking study makes a significant step towards much-improved segmentation methods for atrial LGE-MRIs, and will serve as an important benchmark for evaluating and comparing the future works in the field. Furthermore, the findings from this study can potentially be extended to other imaging datasets and modalities, having an impact on the wider medical imaging community.",33166776
"Machine Learning for Surgical Phase Recognition: A Systematic Review.. Objective: To provide an overview of ML models and data streams utilized for automated surgical phase recognition.  Background: Phase recognition identifies different steps and phases of an operation. ML is an evolving technology that allows analysis and interpretation of huge data sets. Automation of phase recognition based on data inputs is essential for optimization of workflow, surgical training, intraoperative assistance, patient safety, and efficiency.  Methods: A systematic review was performed according to the Cochrane recommendations and the Preferred Reporting Items for Systematic Reviews and Meta-Analyses statement. PubMed, Web of Science, IEEExplore, GoogleScholar, and CiteSeerX were searched. Literature describing phase recognition based on ML models and the capture of intraoperative signals during general surgery procedures was included.  Results: A total of 2254 titles/abstracts were screened, and 35 full-texts were included. Most commonly used ML models were Hidden Markov Models and Artificial Neural Networks with a trend towards higher complexity over time. Most frequently used data types were feature learning from surgical videos and manual annotation of instrument use. Laparoscopic cholecystectomy was used most commonly, often achieving accuracy rates over 90%, though there was no consistent standardization of defined phases.  Conclusions: ML for surgical phase recognition can be performed with high accuracy, depending on the model, data type, and complexity of surgery. Different intraoperative data inputs such as video and instrument type can successfully be used. Most ML models still require significant amounts of manual expert annotations for training. The ML models may drive surgical workflow towards standardization, efficiency, and objectiveness to improve patient outcome in the future.",33201088
"Application of Artificial Intelligence in Dentistry.. Artificial intelligence (AI) is a technology that utilizes machines to mimic intelligent human behavior. To appreciate human-technology interaction in the clinical setting, augmented intelligence has been proposed as a cognitive extension of AI in health care, emphasizing its assistive and supplementary role to medical professionals. While truly autonomous medical robotic systems are still beyond reach, the virtual component of AI, known as software-type algorithms, is the main component used in dentistry. Because of their powerful capabilities in data analysis, these virtual algorithms are expected to improve the accuracy and efficacy of dental diagnosis, provide visualized anatomic guidance for treatment, simulate and evaluate prospective results, and project the occurrence and prognosis of oral diseases. Potential obstacles in contemporary algorithms that prevent routine implementation of AI include the lack of data curation, sharing, and readability; the inability to illustrate the inner decision-making process; the insufficient power of classical computing; and the neglect of ethical principles in the design of AI frameworks. It is necessary to maintain a proactive attitude toward AI to ensure its affirmative development and promote human-technology rapport to revolutionize dental practice. The present review outlines the progress and potential dental applications of AI in medical-aided diagnosis, treatment, and disease prediction and discusses their data limitations, interpretability, computing power, and ethical considerations, as well as their impact on dentists, with the objective of creating a backdrop for future research in this rapidly expanding arena.",33118431
"Evaluation of a novel retinopathy of prematurity severity scale applied by clinicians and deep learning.. Objective: To evaluate the clinical utility of a quantitative deep-learning derived vascular severity score for retinopathy of prematurity (ROP) by assessing its correlation with clinical ROP diagnosis and by measuring clinician agreement in applying a novel scale.  Design: Analysis of existing database of posterior pole fundus images and corresponding ophthalmoscopic examinations using two methods of assigning a quantitative scale to vascular severity.  Subjects: AND PARTICIPANTS: Images were from clinical exams of patients in the Imaging & Informatics in ROP consortium. 4 ophthalmologists and 1 study coordinator evaluated vascular severity on a 1-9 scale.  Methods: A quantitative vascular severity score (1-9) was applied to each image using a deep learning algorithm. A database of 499 images was developed for assessment of inter-observer agreement.  Main outcome measures: Distribution of deep learning derived vascular severity scores with the clinical assessment of zone (I,II,III), stage (0,1,2,3) and extent (<3, 3-6, >6 clock hours) of stage 3 evaluated using multivariable linear regression. Weighted kappa and Pearson correlation coefficients for inter-observer agreement on 1-9 vascular severity scale.  Results: For deep learning analysis, a total of 6344 clinical examinations were analyzed. A higher deep learning derived vascular severity score was associated with more posterior disease, higher disease stage, and higher extent of stage 3 disease (P<.001 for all). For a given ROP stage, the vascular severity score was higher in zone I than zone II or III (P<.001). For a given number of clock hours of stage 3, the severity score was higher in zone I than zone II (P=.03 in zone I and P<.001 in zone II). Multivariable regression found zone, stage, and extent were all independently associated with the severity score (P<.001 for all). For inter-observer agreement, mean (±Standard Deviation [SD]) weighted kappa was 0.67 (±0.06) and Pearson Correlation coefficient (±SD) was 0.88 (±.04) on the use of a 1-9 vascular severity scale.  Conclusions: A vascular severity scale for ROP appears feasible for clinical adoption, corresponds with zone, stage, extent of stage 3, and plus disease, and facilitates the use of objective technology such as deep learning to improve consistency of ROP diagnosis.",33121959
"EUFOREA treatment algorithm for allergic rhinitis.. Allergic rhinitis (AR) is the most common chronic inflammatory disease, affecting an estimated 100 million Europeans (1). Despite a substantial burden on individuals, society and health economies (2), AR remains under-diagnosed, under-estimated (in terms of severity), and under-treated (3). Although effective and safe treatments exist, patients wait too long to seek medical advice, often preferring to self-manage at drug stores and at the pharmacy (4).",32991658
"Natural Language Processing in Surgery: A Systematic Review and Meta-Analysis.. Objective: The aim of this study was to systematically assess the application and potential benefits of natural language processing (NLP) in surgical outcomes research. Summary background data: Widespread implementation of electronic health records (EHRs) has generated a massive patient data source. Traditional methods of data capture, such as billing codes and/or manual review of free-text narratives in EHRs, are highly labor-intensive, costly, subjective, and potentially prone to bias. Methods: A literature search of PubMed, MEDLINE, Web of Science, and Embase identified all articles published starting in 2000 that used NLP models to assess perioperative surgical outcomes. Evaluation metrics of NLP systems were assessed by means of pooled analysis and meta-analysis. Qualitative synthesis was carried out to assess the results and risk of bias on outcomes. Results: The present study included 29 articles, with over half (n = 15) published after 2018. The most common outcome identified using NLP was postoperative complications (n = 14). Compared to traditional non-NLP models, NLP models identified postoperative complications with higher sensitivity [0.92 (0.87-0.95) vs 0.58 (0.33-0.79), P < 0.001]. The specificities were comparable at 0.99 (0.96-1.00) and 0.98 (0.95-0.99), respectively. Using summary of likelihood ratio matrices, traditional non-NLP models have clinical utility for confirming documentation of outcomes/diagnoses, whereas NLP models may be reliably utilized for both confirming and ruling out documentation of outcomes/diagnoses. Conclusions: NLP usage to extract a range of surgical outcomes, particularly postoperative complications, is accelerating across disciplines and areas of clinical outcomes research. NLP and traditional non-NLP approaches demonstrate similar performance measures, but NLP is superior in ruling out documentation of surgical outcomes.",33074901
"AI-driven quantification, staging and outcome prediction of COVID-19 pneumonia.. Coronavirus disease 2019 (COVID-19) emerged in 2019 and disseminated around the world rapidly. Computed tomography (CT) imaging has been proven to be an important tool for screening, disease quantification and staging. The latter is of extreme importance for organizational anticipation (availability of intensive care unit beds, patient management planning) as well as to accelerate drug development through rapid, reproducible and quantified assessment of treatment response. Even if currently there are no specific guidelines for the staging of the patients, CT together with some clinical and biological biomarkers are used. In this study, we collected a multi-center cohort and we investigated the use of medical imaging and artificial intelligence for disease quantification, staging and outcome prediction. Our approach relies on automatic deep learning-based disease quantification using an ensemble of architectures, and a data-driven consensus for the staging and outcome prediction of the patients fusing imaging biomarkers with clinical and biological attributes. Highly promising results on multiple external/independent evaluation cohorts as well as comparisons with expert human readers demonstrate the potentials of our approach.",33171345
"Accelerating Surgical Site Infection Abstraction With a Semi-automated Machine-learning Approach.. Objective: To demonstrate that a semi-automated approach to health data abstraction provides significant efficiencies and high accuracy. Background: Surgical outcome abstraction remains laborious and a barrier to the sustainment of quality improvement registries like ACS-NSQIP. A supervised machine learning algorithm developed for detecting SSI using structured and unstructured electronic health record data was tested to perform semi-automated SSI abstraction. Methods: A Lasso-penalized logistic regression model with 2011-3 data was trained (baseline performance measured with 10-fold cross-validation). A cutoff probability score from the training data was established, dividing the subsequent evaluation dataset into ""negative"" and ""possible"" SSI groups, with manual data abstraction only performed on the ""possible"" group. We evaluated performance on data from 2014, 2015, and both years. Results: Overall, 6188 patients were in the 2011-3 training dataset and 5132 patients in the 2014-5 evaluation dataset. With use of the semi-automated approach, applying the cut-off score decreased the amount of manual abstraction by ≥90%, resulting in <1% false negatives in the ""negative"" group and a sensitivity of 82%. A blinded review of 10% of the ""possible"" group, considering only the features selected by the algorithm, resulted in high agreement with the gold standard based on full chart abstraction, pointing towards additional efficiency in the abstraction process by making it possible for abstractors to review limited, salient portions of the chart. Conclusion: Semi-automated machine learning-aided SSI abstraction greatly accelerates the abstraction process and achieves very good performance. This could be translated to other post-operative outcomes and reduce cost barriers for wider ACS-NSQIP adoption.",33074897
"Treatment after progression in the era of immunotherapy.. Immunotherapy represents a paradigm shift in oncology treatment. The goal of immunotherapy is to overcome immunosuppression induced by a tumour and its microenvironment, thereby allowing the immune system to target and kill cancer cells. The immunotherapy era began when the first immune checkpoint inhibitor, ipilimumab, was approved for use almost a decade ago. This therapeutic approach is associated with distinct types of response, including processes such as pseudoprogression (ie, increased tumour burden via radiology, which is not accompanied by clinical deterioration) and hyperprogression (ie, rapid progression of the disease as a result of immunotherapy). In this Review, we focus on therapeutic approaches for patients who progress on immunotherapy. We review the different types of clinical responses associated with immunotherapy and describe treatment options for this population.",33002442
"Effect of Integrating Machine Learning Mortality Estimates With Behavioral Nudges to Clinicians on Serious Illness Conversations Among Patients With Cancer: A Stepped-Wedge Cluster Randomized Clinical Trial.. Importance: Serious illness conversations (SICs) are structured conversations between clinicians and patients about prognosis, treatment goals, and end-of-life preferences. Interventions that increase the rate of SICs between oncology clinicians and patients may improve goal-concordant care and patient outcomes. Objective: To determine the effect of a clinician-directed intervention integrating machine learning mortality predictions with behavioral nudges on motivating clinician-patient SICs. Design, setting, and participants: This stepped-wedge cluster randomized clinical trial was conducted across 20 weeks (from June 17 to November 1, 2019) at 9 medical oncology clinics (8 subspecialty oncology and 1 general oncology clinics) within a large academic health system in Pennsylvania. Clinicians at the 2 smallest subspecialty clinics were grouped together, resulting in 8 clinic groups randomly assigned to the 4 intervention wedge periods. Included participants in the intention-to-treat analyses were 78 oncology clinicians who received SIC training and their patients (N = 14 607) who had an outpatient oncology encounter during the study period. Interventions: (1) Weekly emails to oncology clinicians with SIC performance feedback and peer comparisons; (2) a list of up to 6 high-risk patients (≥10% predicted risk of 180-day mortality) scheduled for the next week, estimated using a validated machine learning algorithm; and (3) opt-out text message prompts to clinicians on the patient's appointment day to consider an SIC. Clinicians in the control group received usual care consisting of weekly emails with cumulative SIC performance. Main outcomes and measures: Percentage of patient encounters with an SIC in the intervention group vs the usual care (control) group. Results: The sample consisted of 78 clinicians and 14 607 patients. The mean (SD) age of patients was 61.9 (14.2) years, 53.7% were female, and 70.4% were White. For all encounters, SICs were conducted among 1.3% in the control group and 4.6% in the intervention group, a significant difference (adjusted difference in percentage points, 3.3; 95% CI, 2.3-4.5; P < .001). Among 4124 high-risk patient encounters, SICs were conducted among 3.6% in the control group and 15.2% in the intervention group, a significant difference (adjusted difference in percentage points, 11.6; 95% CI, 8.2-12.5; P < .001). Conclusions and relevance: In this stepped-wedge cluster randomized clinical trial, an intervention that delivered machine learning mortality predictions with behavioral nudges to oncology clinicians significantly increased the rate of SICs among all patients and among patients with high mortality risk who were targeted by the intervention. Behavioral nudges combined with machine learning mortality predictions can positively influence clinician behavior and may be applied more broadly to improve care near the end of life.",33057696
"Improving Image Quality and Reducing Radiation Dose for Pediatric CT by Using Deep Learning Reconstruction.. Background CT deep learning reconstruction (DLR) algorithms have been developed to remove image noise. How the DLR affects image quality and radiation dose reduction has yet to be fully investigated. Purpose To investigate a DLR algorithm's dose reduction and image quality improvement for pediatric CT. Materials and Methods DLR was compared with filtered back projection (FBP), statistical-based iterative reconstruction (SBIR), and model-based iterative reconstruction (MBIR) in a retrospective study by using data from CT examinations of pediatric patients (February to December 2018). A comparison of object detectability for 15 objects (diameter, 0.5-10 mm) at four contrast difference levels (50, 150, 250, and 350 HU) was performed by using a non-prewhitening-matched mathematical observer model with eye filter (d'NPWE), task transfer function, and noise power spectrum analysis. Object detectability was assessed by using area under the curve analysis. Three pediatric radiologists performed an observer study to assess anatomic structures with low object-to-background signal and contrast to noise in the azygos vein, right hepatic vein, common bile duct, and superior mesenteric artery. Observers rated from 1 to 10 (worst to best) for edge definition, quantum noise level, and object conspicuity. Analysis of variance and Tukey honest significant difference post hoc tests were used to analyze differences between reconstruction algorithms. Results Images from 19 patients (mean age, 11 years ± 5 [standard deviation]; 10 female patients) were evaluated. Compared with FBP, SBIR, and MBIR, DLR demonstrated improved object detectability by 51% (16.5 of 10.9), 18% (16.5 of 13.9), and 11% (16.5 of 14.8), respectively. DLR reduced image noise without noise texture effects seen with MBIR. Radiologist ratings were 7 ± 1 (DLR), 6.2 ± 1 (MBIR), 6.2 ± 1 (SBIR), and 4.6 ± 1 (FBP); two-way analysis of variance showed a difference on the basis of reconstruction type (P < .001). Radiologists consistently preferred DLR images (intraclass correlation coefficient, 0.89; 95% CI: 0.83, 0.93). DLR demonstrated 52% (1 of 2.1) greater dose reduction than SBIR. Conclusion The DLR algorithm improved image quality and dose reduction without sacrificing noise texture and spatial resolution",33201790
"Artificial Intelligence System to Determine Risk of T1 Colorectal Cancer Metastasis to Lymph Node.. Background aims: In accordance with guidelines, most patients with T1 colorectal cancers (CRC) undergo surgical resection with lymph node dissection, despite the low incidence (∼10%) of metastasis to lymph node. To reduce unnecessary surgical resections, we used artificial intelligence to build a model to identify T1 colorectal tumors at risk for metastasis to lymph node and validated the model in a separate set of patients. Methods: We collected data from 3134 patients with T1 CRC treated at 6 hospitals in Japan from April 1997 through September 2017 (training cohort). We developed a machine-learning artificial neural network (ANN) using data on patients' age and sex, as well as tumor size, location, morphology, lymphatic and vascular invasion, and histologic grade. We then conducted the external validation on the ANN model using independent 939 patients at another hospital during the same period (validation cohort). We calculated areas under the receiver operator characteristics curves (AUROCs) for the ability of the model and United States guidelines to identify patients with lymph node metastases. Results: Lymph node metastases were found in 319/3134 patients (10.2%) in the training cohort and 79/939 patients (8.4%) in the validation cohort. In the validation cohort, the ANN model identified patients with lymph node metastases with an AUC of 0.83, whereas the guidelines identified patients with lymph node metastases with an AUC of 0.73 (P<.001). When the analysis was limited to patients with initial endoscopic resection (n=517), the ANN model identified patients with lymph node metastases with an AUC of 0.84 and the guidelines identified these patients with an AUC of 0.77 (P=.005). Conclusions: The ANN model outperformed guidelines in identifying patients with T1 CRCs who had lymph node metastases. This model might be used to determine which patients require additional surgery after endoscopic resection of T1 CRCs. UMIN Clinical Trials Registry no: UMIN000038609.",32979355
"Predicting Drug Response and Synergy Using a Deep Learning Model of Human Cancer Cells.. Most drugs entering clinical trials fail, often related to an incomplete understanding of the mechanisms governing drug response. Machine learning techniques hold immense promise for better drug response predictions, but most have not reached clinical practice due to their lack of interpretability and their focus on monotherapies. We address these challenges by developing DrugCell, an interpretable deep learning model of human cancer cells trained on the responses of 1,235 tumor cell lines to 684 drugs. Tumor genotypes induce states in cellular subsystems that are integrated with drug structure to predict response to therapy and, simultaneously, learn biological mechanisms underlying the drug response. DrugCell predictions are accurate in cell lines and also stratify clinical outcomes. Analysis of DrugCell mechanisms leads directly to the design of synergistic drug combinations, which we validate systematically by combinatorial CRISPR, drug-drug screening in vitro, and patient-derived xenografts. DrugCell provides a blueprint for constructing interpretable models for predictive medicine.",33096023
"Enrichment Benefits of Risk Algorithms for Pulmonary Arterial Hypertension Clinical Trials.. Rationale: Event-driven primary endpoints are increasingly used in pulmonary arterial hypertension clinical trials, substantially increasing required sample sizes and trial lengths. The U.S. Food and Drug Administration advocates the use of prognostic enrichment of clinical trials by preselecting a patient population with increased likelihood of experiencing the trial's primary endpoint. Objective: This study compares validated clinical scales of risk (COMPERA, the French score, and REVEAL 2.0) to identify patients that are likely to experience a clinical worsening event for trial enrichment. Methods: Baseline data from three pulmonary arterial hypertension clinical trials (AMBITION, SERAPHIN, and GRIPHON) were pooled and standardized. Receiver-operating curves were used to measure each algorithm's performance in predicting clinical worsening within the pooled placebo cohort. Power simulations were conducted to determine sample size and treatment time reductions for multiple enrichment strategies. A cost analysis was performed to illustrate potential financial savings by applying enrichment to GRIPHON. Measurements and results: All risk algorithms were compared using area under the receiver-operating curve and substantially outperformed prediction per New York Heart Association Functional Class. REVEAL 2.0's risk grouping provided the greatest time and sample size savings in AMBITION and GRIPHON for all enrichment strategies but lacked appropriate inputs (i.e., N-terminal-proB-type natriuretic peptide) to perform as well in SERAPHIN. Cost analysis applied to GRIPHON demonstrated the greatest financial benefit by enrolling patients with a REVEAL score ≥8. Conclusion: This preliminary study demonstrates the feasibility of risk algorithms for pulmonary arterial hypertension trial enrichment and a need for further investigation. Keywords: clinical trial enrichment; pulmonary arterial hypertension; risk score calculator.",32937078
"Machine-learning-based multiple abnormality prediction with large-scale chest computed tomography volumes.. Machine learning models for radiology benefit from large-scale data sets with high quality labels for abnormalities. We curated and analyzed a chest computed tomography (CT) data set of 36,316 volumes from 19,993 unique patients. This is the largest multiply-annotated volumetric medical imaging data set reported. To annotate this data set, we developed a rule-based method for automatically extracting abnormality labels from free-text radiology reports with an average F-score of 0.976 (min 0.941, max 1.0). We also developed a model for multi-organ, multi-disease classification of chest CT volumes that uses a deep convolutional neural network (CNN). This model reached a classification performance of AUROC >0.90 for 18 abnormalities, with an average AUROC of 0.773 for all 83 abnormalities, demonstrating the feasibility of learning from unfiltered whole volume CT data. We show that training on more labels improves performance significantly: for a subset of 9 labels - nodule, opacity, atelectasis, pleural effusion, consolidation, mass, pericardial effusion, cardiomegaly, and pneumothorax - the model's average AUROC increased by 10% when the number of training labels was increased from 9 to all 83. All code for volume preprocessing, automated label extraction, and the volume abnormality prediction model is publicly available. The 36,316 CT volumes and labels will also be made publicly available pending institutional approval.",33129142
"Machine learning demonstrates that somatic mutations imprint invariant morphologic features in myelodysplastic syndromes.. Morphologic interpretation is the standard in diagnosing myelodysplastic syndrome (MDS), but it has limitations, such as varying reliability in pathologic evaluation and lack of integration with genetic data. Somatic events shape morphologic features, but the complexity of morphologic and genetic changes makes clear associations challenging. This article interrogates novel clinical subtypes of MDS using a machine-learning technique devised to identify patterns of cooccurrence among morphologic features and genomic events. We sequenced 1079 MDS patients and analyzed bone marrow morphologic alterations and other clinical features. A total of 1929 somatic mutations were identified. Five distinct morphologic profiles with unique clinical characteristics were defined. Seventy-seven percent of higher-risk patients clustered in profile 1. All lower-risk (LR) patients clustered into the remaining 4 profiles: profile 2 was characterized by pancytopenia, profile 3 by monocytosis, profile 4 by elevated megakaryocytes, and profile 5 by erythroid dysplasia. These profiles could also separate patients with different prognoses. LR MDS patients were classified into 8 genetic signatures (eg, signature A had TET2 mutations, signature B had both TET2 and SRSF2 mutations, and signature G had SF3B1 mutations), demonstrating association with specific morphologic profiles. Six morphologic profiles/genetic signature associations were confirmed in a separate analysis of an independent cohort. Our study demonstrates that nonrandom or even pathognomonic relationships between morphology and genotype to define clinical features can be identified. This is the first comprehensive implementation of machine-learning algorithms to elucidate potential intrinsic interdependencies among genetic lesions, morphologies, and clinical prognostic in attributes of MDS.",32961553
