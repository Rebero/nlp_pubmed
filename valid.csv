label,title,text,titletext
0,Hit identification of FGFR1 inhibitors using receptor-based virtual screening,Aim. To identify novel FGFR1 inhibitors using the virtual screening approach. Methods. Virtual screening of a small organic compounds library was performed by molecular docking using the Autodock 4.2.6 program package. The compounds activity was determined by in vitro biochemical tests using Î³-32P ATP. Results. In vitro experiments demonstrated that 18 compounds belonging to three chemical classes had an inhibitory activity against FGFR1 with IC50 values in the range from 1.8 to 71 Î¼M. Conclusions. Several FGFR1 inhibitors were found using molecular modeling and biochemical testing. These compounds are excellent candidates for further chemical optimization.,Hit identification of FGFR1 inhibitors using receptor-based virtual screening. Aim. To identify novel FGFR1 inhibitors using the virtual screening approach. Methods. Virtual screening of a small organic compounds library was performed by molecular docking using the Autodock 4.2.6 program package. The compounds activity was determined by in vitro biochemical tests using Î³-32P ATP. Results. In vitro experiments demonstrated that 18 compounds belonging to three chemical classes had an inhibitory activity against FGFR1 with IC50 values in the range from 1.8 to 71 Î¼M. Conclusions. Several FGFR1 inhibitors were found using molecular modeling and biochemical testing. These compounds are excellent candidates for further chemical optimization.
0,Osteoporosis,,
0,Assessment of Blood Tumor Mutational Burden as a Potential Biomarker for Immunotherapy in Patients With Non-Small Cell Lung Cancer With Use of a Next-Generation Sequencing Cancer Gene Panel,,
0,T1 bladder cancer: current considerations for diagnosis and management,"Stage T1 bladder cancers invade the lamina propria of the bladder and, despite sharing many of the genetic features of muscle-invasive bladder cancers, are classified as non-muscle-invasive or 'superficial' tumours. Yet, patients with T1 bladder cancer have an overall mortality of 33% and a cancer-specific mortality of 14% at three years after diagnosis, suggesting that these patients have a high risk of progression and, accordingly, require meticulous surgery, endoscopic surveillance and clinical decision-making. We hypothesize that the variability in the outcomes of patients with T1 bladder cancer is a result of both tumour heterogeneity and pathological staging, as well as inconsistencies in risk stratification, endoscopic resection and schedules of delivery of BCG. Owing to limitations in clinical staging, patients with T1 bladder cancer are at risk of both undertreatment with persistent use of BCG despite recurrence, and overtreatment with early cystectomy. Understanding the molecular features of T1 bladder cancers and how they respond to BCG therapy could improve biomarkers for risk stratification to align therapy with biological risk.","T1 bladder cancer: current considerations for diagnosis and management. Stage T1 bladder cancers invade the lamina propria of the bladder and, despite sharing many of the genetic features of muscle-invasive bladder cancers, are classified as non-muscle-invasive or 'superficial' tumours. Yet, patients with T1 bladder cancer have an overall mortality of 33% and a cancer-specific mortality of 14% at three years after diagnosis, suggesting that these patients have a high risk of progression and, accordingly, require meticulous surgery, endoscopic surveillance and clinical decision-making. We hypothesize that the variability in the outcomes of patients with T1 bladder cancer is a result of both tumour heterogeneity and pathological staging, as well as inconsistencies in risk stratification, endoscopic resection and schedules of delivery of BCG. Owing to limitations in clinical staging, patients with T1 bladder cancer are at risk of both undertreatment with persistent use of BCG despite recurrence, and overtreatment with early cystectomy. Understanding the molecular features of T1 bladder cancers and how they respond to BCG therapy could improve biomarkers for risk stratification to align therapy with biological risk."
0,"With a Little Help from Machine Learning, Precision Radiology Can Be Feasible",,
0,"Quality of Reporting on Guideline, Protocol, or Algorithm Implementation in Adult Trauma Centers: A Systematic Review","OBJECTIVE: To appraise the quality of reporting on guideline, protocol, and algorithm implementations in adult trauma settings according to the Revised Standards for Quality Improvement Reporting Excellence (SQUIRE 2.0). BACKGROUND: At present we do not know if published reports of guideline implementations in trauma settings are of sufficient quality to facilitate replication by other centers wishing to implement the same or similar guidelines. METHODS: A systematic review of the literature was conducted. Articles were identified through electronic databases and hand searching relevant trauma journals. Studies meeting inclusion criteria focused on a guideline, protocol, or algorithm that targeted adult trauma patients >/=18 years and/or trauma patient care providers, and evaluated the effectiveness of guideline, protocol, or algorithm implementation in terms of change in clinical practice or patient outcomes. Each included study was assessed in duplicate for adherence to the 18-item SQUIRE 2.0 criteria. The primary endpoint was the proportion of studies meeting at least 80% (score >/=15) of SQUIRE 2.0. RESULTS: Of 7368 screened studies, 74 met inclusion criteria. Thirty-nine percent of studies scored >/=80% on SQUIRE 2.0. Criteria that were met most frequently were abstract (93%), problem description (93%), and specific aims (89%). The lowest scores appeared in the funding (28%), context (47%), and results (54%) criteria. No study indicated using SQUIRE 2.0 as a guideline to writing the report. CONCLUSIONS: Significant opportunity exists to improve the utility of guideline implementation reports in adult trauma settings, particularly in the domains of study context and the implications of context for study outcomes.","Quality of Reporting on Guideline, Protocol, or Algorithm Implementation in Adult Trauma Centers: A Systematic Review. OBJECTIVE: To appraise the quality of reporting on guideline, protocol, and algorithm implementations in adult trauma settings according to the Revised Standards for Quality Improvement Reporting Excellence (SQUIRE 2.0). BACKGROUND: At present we do not know if published reports of guideline implementations in trauma settings are of sufficient quality to facilitate replication by other centers wishing to implement the same or similar guidelines. METHODS: A systematic review of the literature was conducted. Articles were identified through electronic databases and hand searching relevant trauma journals. Studies meeting inclusion criteria focused on a guideline, protocol, or algorithm that targeted adult trauma patients >/=18 years and/or trauma patient care providers, and evaluated the effectiveness of guideline, protocol, or algorithm implementation in terms of change in clinical practice or patient outcomes. Each included study was assessed in duplicate for adherence to the 18-item SQUIRE 2.0 criteria. The primary endpoint was the proportion of studies meeting at least 80% (score >/=15) of SQUIRE 2.0. RESULTS: Of 7368 screened studies, 74 met inclusion criteria. Thirty-nine percent of studies scored >/=80% on SQUIRE 2.0. Criteria that were met most frequently were abstract (93%), problem description (93%), and specific aims (89%). The lowest scores appeared in the funding (28%), context (47%), and results (54%) criteria. No study indicated using SQUIRE 2.0 as a guideline to writing the report. CONCLUSIONS: Significant opportunity exists to improve the utility of guideline implementation reports in adult trauma settings, particularly in the domains of study context and the implications of context for study outcomes."
0,A novel multidimensional signature predicts prognosis in hepatocellular carcinoma patients,"The abnormal expression of microRNAs (miRNAs) or protein-coding genes (PCGs) have been found to be associated with the prognosis of hepatocellular carcinoma (HCC) patients. Using bioinformatics analysis methods including Coxâ€™s proportional hazards regression analysis, the random survival forest algorithm, Kaplanâ€“Meier, and receiver operating characteristic (ROC) curve analysis, we mined the gene expression profiles of 469 HCC patients from The Cancer Genome Atlas (n = 379) and Gene Expression Omnibus (GSE14520; n = 90) public database. We selected a signature comprising one protein-coding gene (PCG; DNA polymerase Î¼) and three miRNAs (hsa-miR-149-5p, hsa-miR-424-5p, hsa-miR-579-5p) with highest accurate prediction (area under the ROC curve [AUC] = 0.72; n = 189) from the training data set. The signature stratified patients into high- and low-risk groups with significantly different survival (median 27.9 vs. 55.2 months, log-rank test, p < 0.001) in the training data set, and its risk stratification ability were validated in the test data set (median 47.4 vs. 84.4 months, log-rank test, p = 0.03) and an independent data set (median 31.0 vs. 46.0 months, log-rank test, p = 0.01). Multivariable Cox regression analysis showed that the signature was an independent prognostic factor. And the signature was proved to have a better survival prediction power than tumorâ€“nodeâ€“metastasis (TNM) stage (AUC signature = 0.72/0.64/0.62 vs. AUC TNM = 0.65/0.61/0.61; p < 0.05). Moreover, we validated the expression of these prognostic genes from the PCG-miRNA signature in Huh-7 cell by real-time polymerase chain reaction. In conclusion, we found a signature that can predict survival of HCC patients and serve as a prognostic marker for HCC.","A novel multidimensional signature predicts prognosis in hepatocellular carcinoma patients. The abnormal expression of microRNAs (miRNAs) or protein-coding genes (PCGs) have been found to be associated with the prognosis of hepatocellular carcinoma (HCC) patients. Using bioinformatics analysis methods including Coxâ€™s proportional hazards regression analysis, the random survival forest algorithm, Kaplanâ€“Meier, and receiver operating characteristic (ROC) curve analysis, we mined the gene expression profiles of 469 HCC patients from The Cancer Genome Atlas (n = 379) and Gene Expression Omnibus (GSE14520; n = 90) public database. We selected a signature comprising one protein-coding gene (PCG; DNA polymerase Î¼) and three miRNAs (hsa-miR-149-5p, hsa-miR-424-5p, hsa-miR-579-5p) with highest accurate prediction (area under the ROC curve [AUC] = 0.72; n = 189) from the training data set. The signature stratified patients into high- and low-risk groups with significantly different survival (median 27.9 vs. 55.2 months, log-rank test, p < 0.001) in the training data set, and its risk stratification ability were validated in the test data set (median 47.4 vs. 84.4 months, log-rank test, p = 0.03) and an independent data set (median 31.0 vs. 46.0 months, log-rank test, p = 0.01). Multivariable Cox regression analysis showed that the signature was an independent prognostic factor. And the signature was proved to have a better survival prediction power than tumorâ€“nodeâ€“metastasis (TNM) stage (AUC signature = 0.72/0.64/0.62 vs. AUC TNM = 0.65/0.61/0.61; p < 0.05). Moreover, we validated the expression of these prognostic genes from the PCG-miRNA signature in Huh-7 cell by real-time polymerase chain reaction. In conclusion, we found a signature that can predict survival of HCC patients and serve as a prognostic marker for HCC."
0,A Transcriptome-wide Translational Program Defined by LIN28B Expression Level,"Tan et al. show that changes in LIN28B expression can upregulate and downregulate gene expression. By suppressing let-7 family miRNA biogenesis, LIN28B liberates Argonaute to bind non-let-7 miRNA families with greater frequency, causing downstream changes because of redistributed miRNA activity. These effects affect a significant portion of the transcriptome.","A Transcriptome-wide Translational Program Defined by LIN28B Expression Level. Tan et al. show that changes in LIN28B expression can upregulate and downregulate gene expression. By suppressing let-7 family miRNA biogenesis, LIN28B liberates Argonaute to bind non-let-7 miRNA families with greater frequency, causing downstream changes because of redistributed miRNA activity. These effects affect a significant portion of the transcriptome."
0,CDC42 Deletion Elicits Cerebral Vascular Malformations via Increased MEKK3-Dependent KLF4 Expression,,
0,"Reply to Francesco Montorsi and Giorgio Gandaglia's Letter to the Editor re: Georg Jancke, Firas Aljabery, Sigurdur Gudjonsson, et al. Port-site Metastases After Robot-assisted Radical Cystectomy: Is There a Publication Bias? Eur Urol 2018;73:641-2",,
0,Towards early detection of adverse drug reactions: combining pre-clinical drug structures and post-market safety reports,"BACKGROUND: Adverse drug reaction (ADR) is a major burden for patients and healthcare industry. Early and accurate detection of potential ADRs can help to improve drug safety and reduce financial costs. Post-market spontaneous reports of ADRs remain a cornerstone of pharmacovigilance and a series of drug safety signal detection methods play an important role in providing drug safety insights. However, existing methods require sufficient case reports to generate signals, limiting their usages for newly approved drugs with few (or even no) reports. METHODS: In this study, we propose a label propagation framework to enhance drug safety signals by combining drug chemical structures with FDA Adverse Event Reporting System (FAERS). First, we compute original drug safety signals via common signal detection algorithms. Then, we construct a drug similarity network based on chemical structures. Finally, we generate enhanced drug safety signals by propagating original signals on the drug similarity network. Our proposed framework enriches post-market safety reports with pre-clinical drug similarity network, effectively alleviating issues of insufficient cases for newly approved drugs. RESULTS: We apply the label propagation framework to four popular signal detection algorithms (PRR, ROR, MGPS, BCPNN) and find that our proposed framework generates more accurate drug safety signals than the corresponding baselines. In addition, our framework identifies potential ADRs for newly approved drugs, thus paving the way for early detection of ADRs. CONCLUSIONS: The proposed label propagation framework combines pre-clinical drug structures with post-market safety reports, generates enhanced drug safety signals, and can potentially help to accurately detect ADRs ahead of time. AVAILABILITY: The source code for this paper is available at: https://github.com/ruoqi-liu/LP-SDA.","Towards early detection of adverse drug reactions: combining pre-clinical drug structures and post-market safety reports. BACKGROUND: Adverse drug reaction (ADR) is a major burden for patients and healthcare industry. Early and accurate detection of potential ADRs can help to improve drug safety and reduce financial costs. Post-market spontaneous reports of ADRs remain a cornerstone of pharmacovigilance and a series of drug safety signal detection methods play an important role in providing drug safety insights. However, existing methods require sufficient case reports to generate signals, limiting their usages for newly approved drugs with few (or even no) reports. METHODS: In this study, we propose a label propagation framework to enhance drug safety signals by combining drug chemical structures with FDA Adverse Event Reporting System (FAERS). First, we compute original drug safety signals via common signal detection algorithms. Then, we construct a drug similarity network based on chemical structures. Finally, we generate enhanced drug safety signals by propagating original signals on the drug similarity network. Our proposed framework enriches post-market safety reports with pre-clinical drug similarity network, effectively alleviating issues of insufficient cases for newly approved drugs. RESULTS: We apply the label propagation framework to four popular signal detection algorithms (PRR, ROR, MGPS, BCPNN) and find that our proposed framework generates more accurate drug safety signals than the corresponding baselines. In addition, our framework identifies potential ADRs for newly approved drugs, thus paving the way for early detection of ADRs. CONCLUSIONS: The proposed label propagation framework combines pre-clinical drug structures with post-market safety reports, generates enhanced drug safety signals, and can potentially help to accurately detect ADRs ahead of time. AVAILABILITY: The source code for this paper is available at: https://github.com/ruoqi-liu/LP-SDA."
0,"Do no harm: a roadmap for responsible machine learning for health care (vol 25, pg 1337, 2019)",,
0,Scrublet: Computational Identification of Cell Doublets in Single-Cell Transcriptomic Data,"Single-cell RNA-sequencing has become a widely used, powerful approach for studying cell populations. However, these methods often generate multiplet artifacts, where two or more cells receive the same barcode, resulting in a hybrid transcriptome. In most experiments, multiplets account for several percent of transcriptomes and can confound downstream data analysis. Here, we present Single-Cell Remover of Doublets (Scrublet), a framework for predicting the impact of multiplets in a given analysis and identifying problematic multiplets. Scrublet avoids the need for expert knowledge or cell clustering by simulating multiplets from the data and building a nearest neighbor classifier. To demonstrate the utility of this approach, we test Scrublet on several datasets that include independent knowledge of cell multiplets. Scrublet is freely available for download at github.com/AllonKleinLab/scrublet.","Scrublet: Computational Identification of Cell Doublets in Single-Cell Transcriptomic Data. Single-cell RNA-sequencing has become a widely used, powerful approach for studying cell populations. However, these methods often generate multiplet artifacts, where two or more cells receive the same barcode, resulting in a hybrid transcriptome. In most experiments, multiplets account for several percent of transcriptomes and can confound downstream data analysis. Here, we present Single-Cell Remover of Doublets (Scrublet), a framework for predicting the impact of multiplets in a given analysis and identifying problematic multiplets. Scrublet avoids the need for expert knowledge or cell clustering by simulating multiplets from the data and building a nearest neighbor classifier. To demonstrate the utility of this approach, we test Scrublet on several datasets that include independent knowledge of cell multiplets. Scrublet is freely available for download at github.com/AllonKleinLab/scrublet."
0,A Decision Analysis of Follow-up and Treatment Algorithms for Nonsolid Pulmonary Nodules,"Purpose To evaluate management strategies and treatment options for patients with ground-glass nodules (GGNs) by using decision-analysis models. Materials and Methods A simulation was developed for 1 000 000 hypothetical patients with GGNs undergoing follow-up per the Lung Imaging Reporting and Data System (Lung-RADS) recommendations. The initial age range was 55-75 years (mean, 64 years). Nodules could grow and develop solid components over time. Clinically significant malignancy rates were calibrated to data from the National Lung Screening Trial. Annual versus 3-year-interval follow-up of Lung-RADS category 2 nodules was compared, and different treatment strategies were tested (stereotactic body radiation therapy, surgery, and no therapy). Results Overall, 2.3% (22 584 of 1 000 000) of nodules were clinically significant malignancies; 6.3% (62 559 of 1 000 000) of nodules were treated. Only 30% (18 668 of 62 559) of Lung-RADS category 4B or 4X nodules were clinically significant malignancies. The risk of clinically significant malignancy for persistent nonsolid nodules after baseline was higher than Lung-RADS estimates for categories 2 and 3 (3% vs <1% and 1%-2%, respectively). Overall survival (OS) at 10 years was 72% (527 827 of 737 306; 95% confidence interval [CI]: 71%, 72%) with annual follow-up and 71% (526 507 of 737 306; 95% CI: 71%, 72%) with 3-year-interval follow-up (P < .01). At 10 years, OS among patients whose nodules progressed to Lung-RADS category 4B or 4X was 80% after radiation therapy (49 945 of 62 559; 95% CI: 80%, 80%), 79% after surgery (49 139 of 62 559; 95% CI: 78%, 79%), and 74% after no therapy (46 512 of 62 559; 95% CI: 74%, 75%) (P < .01). Conclusion Simulation modeling suggests that the follow-up interval for evaluating ground-glass nodules can be increased from 1 year to 3 years with minimal change in outcomes. Stereotactic body radiation therapy demonstrated the best outcomes compared with lobectomy and with no therapy for nonsolid nodules. (c) RSNA, 2018 Online supplemental material is available for this article.","A Decision Analysis of Follow-up and Treatment Algorithms for Nonsolid Pulmonary Nodules. Purpose To evaluate management strategies and treatment options for patients with ground-glass nodules (GGNs) by using decision-analysis models. Materials and Methods A simulation was developed for 1 000 000 hypothetical patients with GGNs undergoing follow-up per the Lung Imaging Reporting and Data System (Lung-RADS) recommendations. The initial age range was 55-75 years (mean, 64 years). Nodules could grow and develop solid components over time. Clinically significant malignancy rates were calibrated to data from the National Lung Screening Trial. Annual versus 3-year-interval follow-up of Lung-RADS category 2 nodules was compared, and different treatment strategies were tested (stereotactic body radiation therapy, surgery, and no therapy). Results Overall, 2.3% (22 584 of 1 000 000) of nodules were clinically significant malignancies; 6.3% (62 559 of 1 000 000) of nodules were treated. Only 30% (18 668 of 62 559) of Lung-RADS category 4B or 4X nodules were clinically significant malignancies. The risk of clinically significant malignancy for persistent nonsolid nodules after baseline was higher than Lung-RADS estimates for categories 2 and 3 (3% vs <1% and 1%-2%, respectively). Overall survival (OS) at 10 years was 72% (527 827 of 737 306; 95% confidence interval [CI]: 71%, 72%) with annual follow-up and 71% (526 507 of 737 306; 95% CI: 71%, 72%) with 3-year-interval follow-up (P < .01). At 10 years, OS among patients whose nodules progressed to Lung-RADS category 4B or 4X was 80% after radiation therapy (49 945 of 62 559; 95% CI: 80%, 80%), 79% after surgery (49 139 of 62 559; 95% CI: 78%, 79%), and 74% after no therapy (46 512 of 62 559; 95% CI: 74%, 75%) (P < .01). Conclusion Simulation modeling suggests that the follow-up interval for evaluating ground-glass nodules can be increased from 1 year to 3 years with minimal change in outcomes. Stereotactic body radiation therapy demonstrated the best outcomes compared with lobectomy and with no therapy for nonsolid nodules. (c) RSNA, 2018 Online supplemental material is available for this article."
0,Precision Medicine in Pulmonary Arterial Hypertension A First Step,,
0,Sex Disparities in Ophthalmic Research A Descriptive Bibliometric Study on Scientific Authorships,,
0,Predicting Patient Response to the Antiarrhythmic Mexiletine Based on Genetic Variation Personalized Medicine for Long QT Syndrome,,
0,The Proliferation of Reports on Clinical Scoring Systems: Issues About Uptake and Clinical Utility,,
0,Ethical concerns with the use of intelligent assistive technology: findings from a qualitative study with professional stakeholders,"BACKGROUND: Advances in artificial intelligence (AI), robotics and wearable computing are creating novel technological opportunities for mitigating the global burden of population ageing and improving the quality of care for older adults with dementia and/or age-related disability. Intelligent assistive technology (IAT) is the umbrella term defining this ever-evolving spectrum of intelligent applications for the older and disabled population. However, the implementation of IATs has been observed to be sub-optimal due to a number of barriers in the translation of novel applications from the designing labs to the bedside. Furthermore, since these technologies are designed to be used by vulnerable individuals with age- and multi-morbidity-related frailty and cognitive disability, they are perceived to raise important ethical challenges, especially when they involve machine intelligence, collect sensitive data or operate in close proximity to the human body. Thus, the goal of this paper is to explore and assess the ethical issues that professional stakeholders perceive in the development and use of IATs in elderly and dementia care. METHODS: We conducted a multi-site study involving semi-structured qualitative interviews with researchers and health professionals. We analyzed the interview data using a descriptive thematic analysis to inductively explore relevant ethical challenges. RESULTS: Our findings indicate that professional stakeholders find issues of patient autonomy and informed consent, quality of data management, distributive justice and human contact as ethical priorities. Divergences emerged in relation to how these ethical issues are interpreted, how conflicts between different ethical principles are resolved and what solutions should be implemented to overcome current challenges. CONCLUSIONS: Our findings indicate a general agreement among professional stakeholders on the ethical promises and challenges raised by the use of IATs among older and disabled users. Yet, notable divergences persist regarding how these ethical challenges can be overcome and what strategies should be implemented for the safe and effective implementation of IATs. These findings provide technology developers with useful information about unmet ethical needs. Study results may guide policy makers with firsthand information from relevant stakeholders about possible solutions for ethically-aligned technology governance.","Ethical concerns with the use of intelligent assistive technology: findings from a qualitative study with professional stakeholders. BACKGROUND: Advances in artificial intelligence (AI), robotics and wearable computing are creating novel technological opportunities for mitigating the global burden of population ageing and improving the quality of care for older adults with dementia and/or age-related disability. Intelligent assistive technology (IAT) is the umbrella term defining this ever-evolving spectrum of intelligent applications for the older and disabled population. However, the implementation of IATs has been observed to be sub-optimal due to a number of barriers in the translation of novel applications from the designing labs to the bedside. Furthermore, since these technologies are designed to be used by vulnerable individuals with age- and multi-morbidity-related frailty and cognitive disability, they are perceived to raise important ethical challenges, especially when they involve machine intelligence, collect sensitive data or operate in close proximity to the human body. Thus, the goal of this paper is to explore and assess the ethical issues that professional stakeholders perceive in the development and use of IATs in elderly and dementia care. METHODS: We conducted a multi-site study involving semi-structured qualitative interviews with researchers and health professionals. We analyzed the interview data using a descriptive thematic analysis to inductively explore relevant ethical challenges. RESULTS: Our findings indicate that professional stakeholders find issues of patient autonomy and informed consent, quality of data management, distributive justice and human contact as ethical priorities. Divergences emerged in relation to how these ethical issues are interpreted, how conflicts between different ethical principles are resolved and what solutions should be implemented to overcome current challenges. CONCLUSIONS: Our findings indicate a general agreement among professional stakeholders on the ethical promises and challenges raised by the use of IATs among older and disabled users. Yet, notable divergences persist regarding how these ethical challenges can be overcome and what strategies should be implemented for the safe and effective implementation of IATs. These findings provide technology developers with useful information about unmet ethical needs. Study results may guide policy makers with firsthand information from relevant stakeholders about possible solutions for ethically-aligned technology governance."
0,Filtering out the noise in axon guidance,,
0,Reply to Parker: Implications of Tuberculosis Sputum Culture Test Sensitivity on Accuracy of Other Diagnostic Modalities,,
0,Wearable Biosensors in Pediatric Cardiovascular Disease Promises and Pitfalls Toward Generating Actionable Insights,,
0,Interaction and molecular dynamics simulation study of Osimertinib (AstraZeneca 9291) anticancer drug with the EGFR kinase domain in native protein and mutated L844V and C797S,"Background: Targeted therapy is a novel, promising approach to anticancer treatment that endeavors to overcome drug resistance to traditional chemotherapies. Patients with the L858R mutation in epidermal growth factor receptor (EGFR) respond to the first generation tyrosine kinase inhibitors (TKIs); however, after one year of treatment, they may become resistant. The T790M mutation is the most probable cause for drug resistance. Third generation drugs, including Osimertinib (AZD9291), are more effective against T790M and other sensitive mutations. Osimertinib is effective against the L844V mutation, has conditional effectiveness for the L718Q mutation, and is ineffective for the Cys797Ser (C797S) mutation. Cells that have both the T790M and C797 mutations are more resistant to third generation drugs. Although research has shown that Osimertinib is an effective treatment for EGFR L844V cells, this has not been shown for cells that have the C797S mutation. This molecular mechanism has not been well-studied. Methods: In the present study, we used the GROMACS software for molecular dynamics simulation to identify interactions between Osimertinib and the kinase part of EGFR in L844V and C797S mutants. Results: We evaluated native EGFR protein and the L844V and C797S mutationsâ€™ docking and binding energy, kI, intermolecular, internal, and torsional energy parameters. Osimertinib was effective for the EGFR L844V mutation, but not for EGFR C797S. All simulations were validated by root-mean-square deviation (RMSD), root-mean square fluctuation (RMSF), and radius of gyration (ROG). Conclusion: According to our computational simulation, the results supported the experimental models and, therefore, could confirm and predict the molecular mechanism of drug efficacy.","Interaction and molecular dynamics simulation study of Osimertinib (AstraZeneca 9291) anticancer drug with the EGFR kinase domain in native protein and mutated L844V and C797S. Background: Targeted therapy is a novel, promising approach to anticancer treatment that endeavors to overcome drug resistance to traditional chemotherapies. Patients with the L858R mutation in epidermal growth factor receptor (EGFR) respond to the first generation tyrosine kinase inhibitors (TKIs); however, after one year of treatment, they may become resistant. The T790M mutation is the most probable cause for drug resistance. Third generation drugs, including Osimertinib (AZD9291), are more effective against T790M and other sensitive mutations. Osimertinib is effective against the L844V mutation, has conditional effectiveness for the L718Q mutation, and is ineffective for the Cys797Ser (C797S) mutation. Cells that have both the T790M and C797 mutations are more resistant to third generation drugs. Although research has shown that Osimertinib is an effective treatment for EGFR L844V cells, this has not been shown for cells that have the C797S mutation. This molecular mechanism has not been well-studied. Methods: In the present study, we used the GROMACS software for molecular dynamics simulation to identify interactions between Osimertinib and the kinase part of EGFR in L844V and C797S mutants. Results: We evaluated native EGFR protein and the L844V and C797S mutationsâ€™ docking and binding energy, kI, intermolecular, internal, and torsional energy parameters. Osimertinib was effective for the EGFR L844V mutation, but not for EGFR C797S. All simulations were validated by root-mean-square deviation (RMSD), root-mean square fluctuation (RMSF), and radius of gyration (ROG). Conclusion: According to our computational simulation, the results supported the experimental models and, therefore, could confirm and predict the molecular mechanism of drug efficacy."
0,Artificial Intelligence in Health Care: Will the Value Match the Hype?,,
0,Getting to the Cores of Autism,,
0,Advances in technology for management of type 1 diabetes,,
0,HF-SENSE: an improved partially parallel imaging using a high-pass filter,"BACKGROUND: One of the major limitations of MRI is its slow acquisition speed. To accelerate data acquisition, partially parallel imaging (PPI) methods have been widely used in clinical applications such as sensitivity encoding (SENSE) and generalized autocalibrating partially parallel acquisitions (GRAPPA). SENSE is a popular image-domain partially parallel imaging method, which suffers from residual aliasing artifacts when the reduction factor goes higher. Undersampling the k-space data and then reconstruct images with artificial sparsity is an efficient way to accelerate data acquisition. By exploiting artificial sparsity with a high-pass filter, an improved SENSE method is proposed in this work, termed high-pass filtered SENSE (HF-SENSE). METHODS: First, a high-pass filter was applied to the raw k-space data, the result of which was used as the inputs of sensitivity estimation and undersampling process. Second, the adaptive array coil combination method was adopted to calculate sensitivity maps on a block-by-block basis. Third, Tikhonov regularized SENSE was then used to reconstruct magnetic resonance images. Fourth, the reconstructed images were transformed into k-space data, which was filtered with the corresponding inverse filter. RESULTS: Both simulation and in vivo experiments demonstrate that HF-SENSE method significantly reduces noise level of the reconstructed images compared with SENSE. Furthermore, it is found that HF-SENSE can achieve lower normalized root-mean-square error value than SENSE. CONCLUSIONS: The proposed method explores artificial sparsity with a high-pass filter. Experiments demonstrate that the proposed HF-SENSE method can improve the image quality of SENSE reconstruction. The high-pass filter parameters can be predefined. With this image reconstruction method, high acceleration factors can be achieved, which will improve the clinical applicability of SENSE. This retrospective study (HF-SENSE: an improved partially parallel imaging using a high-pass filter) was approved by Institute Review Board of 2nd Affiliated Hospital of Zhejiang University (ethical approval number 2018-314). Participant for all images have informed consent that he knew the risks and agreed to participate in the research.","HF-SENSE: an improved partially parallel imaging using a high-pass filter. BACKGROUND: One of the major limitations of MRI is its slow acquisition speed. To accelerate data acquisition, partially parallel imaging (PPI) methods have been widely used in clinical applications such as sensitivity encoding (SENSE) and generalized autocalibrating partially parallel acquisitions (GRAPPA). SENSE is a popular image-domain partially parallel imaging method, which suffers from residual aliasing artifacts when the reduction factor goes higher. Undersampling the k-space data and then reconstruct images with artificial sparsity is an efficient way to accelerate data acquisition. By exploiting artificial sparsity with a high-pass filter, an improved SENSE method is proposed in this work, termed high-pass filtered SENSE (HF-SENSE). METHODS: First, a high-pass filter was applied to the raw k-space data, the result of which was used as the inputs of sensitivity estimation and undersampling process. Second, the adaptive array coil combination method was adopted to calculate sensitivity maps on a block-by-block basis. Third, Tikhonov regularized SENSE was then used to reconstruct magnetic resonance images. Fourth, the reconstructed images were transformed into k-space data, which was filtered with the corresponding inverse filter. RESULTS: Both simulation and in vivo experiments demonstrate that HF-SENSE method significantly reduces noise level of the reconstructed images compared with SENSE. Furthermore, it is found that HF-SENSE can achieve lower normalized root-mean-square error value than SENSE. CONCLUSIONS: The proposed method explores artificial sparsity with a high-pass filter. Experiments demonstrate that the proposed HF-SENSE method can improve the image quality of SENSE reconstruction. The high-pass filter parameters can be predefined. With this image reconstruction method, high acceleration factors can be achieved, which will improve the clinical applicability of SENSE. This retrospective study (HF-SENSE: an improved partially parallel imaging using a high-pass filter) was approved by Institute Review Board of 2nd Affiliated Hospital of Zhejiang University (ethical approval number 2018-314). Participant for all images have informed consent that he knew the risks and agreed to participate in the research."
0,Reading Acquisition in Children: Developmental Processes and Dyslexia-Specific Effects,,
0,A new method for excavating feature lncRNA in lung adenocarcinoma based on pathway crosstalk analysis,"Recent theoretical and experimental studies indicate that long-chain noncoding RNAs (lncRNAs) are essential for the growth and differentiation of cells and the occurrence and development of tumors in epigenetics, but the regulation of lncRNA on gene expression, transcriptional activation, and transcriptional interference in diseases is still unclear. There is an urgent need for effective methods to discover significant lncRNAs with their functions on gene regulatory mechanisms. For this purpose, a new method of extracting significant lncRNA based on pathway crosstalk and dysfunction caused by the differentially expressed genes in lung adenocarcinoma (LUAD) was proposed. The pathway analysis method based on global influence (PAGI) was first applied to find the feature genes that play an important role in the crosstalks of disease-related pathways. Then to explore the hub lncRNAs, the weighted gene coexpression network analysis (WGCNA) was used to construct coexpression models of the feature genes and lncRNAs. The experiment results showed that 64 out of the 322 hub lncRNAs were closely related to the clinical features of patients with LUAD. Among them, nine lncRNAs (UCA1, LINC00857, PVT1, PCAT6, LINC00460, LINC00319, AP000553.1, AP000439.2, and AP005233.2) were identified to be tightly correlated with non-smallâ€“cell lung cancer (NSCLC) pathways. In summary, we offer an effective way to extract significant lncRNA by dysfunctional pathway crosstalk in LUAD which allows the selected lncRNAs with more biologically interpreted and reproducible results. This method can be applied to other diseases and provide useful information for understanding the pathogenesis of human cancer.","A new method for excavating feature lncRNA in lung adenocarcinoma based on pathway crosstalk analysis. Recent theoretical and experimental studies indicate that long-chain noncoding RNAs (lncRNAs) are essential for the growth and differentiation of cells and the occurrence and development of tumors in epigenetics, but the regulation of lncRNA on gene expression, transcriptional activation, and transcriptional interference in diseases is still unclear. There is an urgent need for effective methods to discover significant lncRNAs with their functions on gene regulatory mechanisms. For this purpose, a new method of extracting significant lncRNA based on pathway crosstalk and dysfunction caused by the differentially expressed genes in lung adenocarcinoma (LUAD) was proposed. The pathway analysis method based on global influence (PAGI) was first applied to find the feature genes that play an important role in the crosstalks of disease-related pathways. Then to explore the hub lncRNAs, the weighted gene coexpression network analysis (WGCNA) was used to construct coexpression models of the feature genes and lncRNAs. The experiment results showed that 64 out of the 322 hub lncRNAs were closely related to the clinical features of patients with LUAD. Among them, nine lncRNAs (UCA1, LINC00857, PVT1, PCAT6, LINC00460, LINC00319, AP000553.1, AP000439.2, and AP005233.2) were identified to be tightly correlated with non-smallâ€“cell lung cancer (NSCLC) pathways. In summary, we offer an effective way to extract significant lncRNA by dysfunctional pathway crosstalk in LUAD which allows the selected lncRNAs with more biologically interpreted and reproducible results. This method can be applied to other diseases and provide useful information for understanding the pathogenesis of human cancer."
0,Effect of Electroencephalography-Guided Anesthetic Administration on Postoperative Delirium Among Older Adults Undergoing Major Surgery: The ENGAGES Randomized Clinical Trial,"Importance: Intraoperative electroencephalogram (EEG) waveform suppression, often suggesting excessive general anesthesia, has been associated with postoperative delirium. Objective: To assess whether EEG-guided anesthetic administration decreases the incidence of postoperative delirium. Design, Setting, and Participants: Randomized clinical trial of 1232 adults aged 60 years and older undergoing major surgery and receiving general anesthesia at Barnes-Jewish Hospital in St Louis. Recruitment was from January 2015 to May 2018, with follow-up until July 2018. Interventions: Patients were randomized 1:1 (stratified by cardiac vs noncardiac surgery and positive vs negative recent fall history) to receive EEG-guided anesthetic administration (n = 614) or usual anesthetic care (n = 618). Main Outcomes and Measures: The primary outcome was incident delirium during postoperative days 1 through 5. Intraoperative measures included anesthetic concentration, EEG suppression, and hypotension. Adverse events included undesirable intraoperative movement, intraoperative awareness with recall, postoperative nausea and vomiting, medical complications, and death. Results: Of the 1232 randomized patients (median age, 69 years [range, 60 to 95]; 563 women [45.7%]), 1213 (98.5%) were assessed for the primary outcome. Delirium during postoperative days 1 to 5 occurred in 157 of 604 patients (26.0%) in the guided group and 140 of 609 patients (23.0%) in the usual care group (difference, 3.0% [95% CI, -2.0% to 8.0%]; P = .22). Median end-tidal volatile anesthetic concentration was significantly lower in the guided group than the usual care group (0.69 vs 0.80 minimum alveolar concentration; difference, -0.11 [95% CI, -0.13 to -0.10), and median cumulative time with EEG suppression was significantly less (7 vs 13 minutes; difference, -6.0 [95% CI, -9.9 to -2.1]). There was no significant difference between groups in the median cumulative time with mean arterial pressure below 60 mm Hg (7 vs 7 minutes; difference, 0.0 [95% CI, -1.7 to 1.7]). Undesirable movement occurred in 137 patients (22.3%) in the guided and 95 (15.4%) in the usual care group. No patients reported intraoperative awareness. Postoperative nausea and vomiting was reported in 48 patients (7.8%) in the guided and 55 patients (8.9%) in the usual care group. Serious adverse events were reported in 124 patients (20.2%) in the guided and 130 (21.0%) in the usual care group. Within 30 days of surgery, 4 patients (0.65%) in the guided group and 19 (3.07%) in the usual care group died. Conclusions and Relevance: Among older adults undergoing major surgery, EEG-guided anesthetic administration, compared with usual care, did not decrease the incidence of postoperative delirium. This finding does not support the use of EEG-guided anesthetic administration for this indication. Trial Registration: ClinicalTrials.gov Identifier: NCT02241655.","Effect of Electroencephalography-Guided Anesthetic Administration on Postoperative Delirium Among Older Adults Undergoing Major Surgery: The ENGAGES Randomized Clinical Trial. Importance: Intraoperative electroencephalogram (EEG) waveform suppression, often suggesting excessive general anesthesia, has been associated with postoperative delirium. Objective: To assess whether EEG-guided anesthetic administration decreases the incidence of postoperative delirium. Design, Setting, and Participants: Randomized clinical trial of 1232 adults aged 60 years and older undergoing major surgery and receiving general anesthesia at Barnes-Jewish Hospital in St Louis. Recruitment was from January 2015 to May 2018, with follow-up until July 2018. Interventions: Patients were randomized 1:1 (stratified by cardiac vs noncardiac surgery and positive vs negative recent fall history) to receive EEG-guided anesthetic administration (n = 614) or usual anesthetic care (n = 618). Main Outcomes and Measures: The primary outcome was incident delirium during postoperative days 1 through 5. Intraoperative measures included anesthetic concentration, EEG suppression, and hypotension. Adverse events included undesirable intraoperative movement, intraoperative awareness with recall, postoperative nausea and vomiting, medical complications, and death. Results: Of the 1232 randomized patients (median age, 69 years [range, 60 to 95]; 563 women [45.7%]), 1213 (98.5%) were assessed for the primary outcome. Delirium during postoperative days 1 to 5 occurred in 157 of 604 patients (26.0%) in the guided group and 140 of 609 patients (23.0%) in the usual care group (difference, 3.0% [95% CI, -2.0% to 8.0%]; P = .22). Median end-tidal volatile anesthetic concentration was significantly lower in the guided group than the usual care group (0.69 vs 0.80 minimum alveolar concentration; difference, -0.11 [95% CI, -0.13 to -0.10), and median cumulative time with EEG suppression was significantly less (7 vs 13 minutes; difference, -6.0 [95% CI, -9.9 to -2.1]). There was no significant difference between groups in the median cumulative time with mean arterial pressure below 60 mm Hg (7 vs 7 minutes; difference, 0.0 [95% CI, -1.7 to 1.7]). Undesirable movement occurred in 137 patients (22.3%) in the guided and 95 (15.4%) in the usual care group. No patients reported intraoperative awareness. Postoperative nausea and vomiting was reported in 48 patients (7.8%) in the guided and 55 patients (8.9%) in the usual care group. Serious adverse events were reported in 124 patients (20.2%) in the guided and 130 (21.0%) in the usual care group. Within 30 days of surgery, 4 patients (0.65%) in the guided group and 19 (3.07%) in the usual care group died. Conclusions and Relevance: Among older adults undergoing major surgery, EEG-guided anesthetic administration, compared with usual care, did not decrease the incidence of postoperative delirium. This finding does not support the use of EEG-guided anesthetic administration for this indication. Trial Registration: ClinicalTrials.gov Identifier: NCT02241655."
0,A new prediction model for ventricular arrhythmias in arrhythmogenic right ventricular cardiomyopathy,,
0,Diagnosis of Suspected Pulmonary Embolism in Pregnancy,,
0,Observations and Lessons Learned From the Artificial Intelligence Studies for Diabetic Retinopathy Screening,,
0,Cortical mechanisms of spatial hearing,,
0,The Potential and Pitfalls of Crowdsourced Algorithm Development in Radiation Oncology,,
0,Integrative subspace clustering by common and specific decomposition for applications on cancer subtype identification,"Background: Recent high throughput technologies have been applied for collecting heterogeneous biomedical omics datasets. Computational analysis of the multi-omics datasets could potentially reveal deep insights for a given disease. Most existing clustering methods by multi-omics data assume strong consistency among different sources of datasets, and thus may lose efficacy when the consistency is relatively weak. Furthermore, they could not identify the conflicting parts for each view, which might be important in applications such as cancer subtype identification. Methods: In this work, we propose an integrative subspace clustering method (ISC) by common and specific decomposition to identify clustering structures with multi-omics datasets. The main idea of our ISC method is that the original representations for the samples in each view could be reconstructed by the concatenation of a common part and a view-specific part in orthogonal subspaces. The problem can be formulated as a matrix decomposition problem and solved efficiently by our proposed algorithm. Results: The experiments on simulation and text datasets show that our method outperforms other state-of-Art methods. Our method is further evaluated by identifying cancer types using a colorectal dataset. We finally apply our method to cancer subtype identification for five cancers using TCGA datasets, and the survival analysis shows that the subtypes we found are significantly better than other compared methods. Conclusion: We conclude that our ISC model could not only discover the weak common information across views but also identify the view-specific information.","Integrative subspace clustering by common and specific decomposition for applications on cancer subtype identification. Background: Recent high throughput technologies have been applied for collecting heterogeneous biomedical omics datasets. Computational analysis of the multi-omics datasets could potentially reveal deep insights for a given disease. Most existing clustering methods by multi-omics data assume strong consistency among different sources of datasets, and thus may lose efficacy when the consistency is relatively weak. Furthermore, they could not identify the conflicting parts for each view, which might be important in applications such as cancer subtype identification. Methods: In this work, we propose an integrative subspace clustering method (ISC) by common and specific decomposition to identify clustering structures with multi-omics datasets. The main idea of our ISC method is that the original representations for the samples in each view could be reconstructed by the concatenation of a common part and a view-specific part in orthogonal subspaces. The problem can be formulated as a matrix decomposition problem and solved efficiently by our proposed algorithm. Results: The experiments on simulation and text datasets show that our method outperforms other state-of-Art methods. Our method is further evaluated by identifying cancer types using a colorectal dataset. We finally apply our method to cancer subtype identification for five cancers using TCGA datasets, and the survival analysis shows that the subtypes we found are significantly better than other compared methods. Conclusion: We conclude that our ISC model could not only discover the weak common information across views but also identify the view-specific information."
0,Clinical practice recommendations for the diagnosis and management of X-linked hypophosphataemia,"X-linked hypophosphataemia (XLH) is the most common cause of inherited phosphate wasting and is associated with severe complications such as rickets, lower limb deformities, pain, poor mineralization of the teeth and disproportionate short stature in children as well as hyperparathyroidism, osteomalacia, enthesopathies, osteoarthritis and pseudofractures in adults. The characteristics and severity of XLH vary between patients. Because of its rarity, the diagnosis and specific treatment of XLH are frequently delayed, which has a detrimental effect on patient outcomes. In this Evidence-Based Guideline, we recommend that the diagnosis of XLH is based on signs of rickets and/or osteomalacia in association with hypophosphataemia and renal phosphate wasting in the absence of vitamin D or calcium deficiency. Whenever possible, the diagnosis should be confirmed by molecular genetic analysis or measurement of levels of fibroblast growth factor 23 (FGF23) before treatment. Owing to the multisystemic nature of the disease, patients should be seen regularly by multidisciplinary teams organized by a metabolic bone disease expert. In this article, we summarize the current evidence and provide recommendations on features of the disease, including new treatment modalities, to improve knowledge and provide guidance for diagnosis and multidisciplinary care.","Clinical practice recommendations for the diagnosis and management of X-linked hypophosphataemia. X-linked hypophosphataemia (XLH) is the most common cause of inherited phosphate wasting and is associated with severe complications such as rickets, lower limb deformities, pain, poor mineralization of the teeth and disproportionate short stature in children as well as hyperparathyroidism, osteomalacia, enthesopathies, osteoarthritis and pseudofractures in adults. The characteristics and severity of XLH vary between patients. Because of its rarity, the diagnosis and specific treatment of XLH are frequently delayed, which has a detrimental effect on patient outcomes. In this Evidence-Based Guideline, we recommend that the diagnosis of XLH is based on signs of rickets and/or osteomalacia in association with hypophosphataemia and renal phosphate wasting in the absence of vitamin D or calcium deficiency. Whenever possible, the diagnosis should be confirmed by molecular genetic analysis or measurement of levels of fibroblast growth factor 23 (FGF23) before treatment. Owing to the multisystemic nature of the disease, patients should be seen regularly by multidisciplinary teams organized by a metabolic bone disease expert. In this article, we summarize the current evidence and provide recommendations on features of the disease, including new treatment modalities, to improve knowledge and provide guidance for diagnosis and multidisciplinary care."
0,Focus on learning and memory,,
0,Characterization of expressed human meibum using hyperspectral stimulated Raman scattering microscopy,,
0,Transcriptomic and Single-Cell Analysis of the Murine Parotid Gland,"The salivary complex of mammals consists of 3 major pairs of glands: the parotid, submandibular, and sublingual glands. While the 3 glands share similar functional properties, such as saliva secretion, their differences are largely based on the types of secretions they produce. While recent studies have begun to shed light on the underlying molecular differences among the glands, few have examined the global transcriptional repertoire over various stages of gland maturation. To better elucidate the molecular nature of the parotid gland, we have performed RNA sequencing to generate comprehensive and global gene expression profiles of this gland at different stages of maturation. Our transcriptomic characterization and hierarchical clustering analysis with adult organ RNA sequencing data sets has identified a number of molecular players and pathways that are relevant for parotid gland biology. Moreover, our detailed analysis has revealed a unique parotid gland-specific gene signature that may represent important players that could impart parotid gland-specific biological properties. To complement our transcriptomic studies, we have performed single-cell RNA sequencing to map the transcriptomes of parotid epithelial cells. Interrogation of the single-cell transcriptomes revealed the degree of molecular and cellular heterogeneity of the various epithelial cell types within the parotid gland. Moreover, we uncovered a mixed-lineage population of cells that may reflect molecular priming of differentiation potentials. Overall our comprehensive studies provide a powerful tool for the discovery of novel molecular players important in parotid gland biology.","Transcriptomic and Single-Cell Analysis of the Murine Parotid Gland. The salivary complex of mammals consists of 3 major pairs of glands: the parotid, submandibular, and sublingual glands. While the 3 glands share similar functional properties, such as saliva secretion, their differences are largely based on the types of secretions they produce. While recent studies have begun to shed light on the underlying molecular differences among the glands, few have examined the global transcriptional repertoire over various stages of gland maturation. To better elucidate the molecular nature of the parotid gland, we have performed RNA sequencing to generate comprehensive and global gene expression profiles of this gland at different stages of maturation. Our transcriptomic characterization and hierarchical clustering analysis with adult organ RNA sequencing data sets has identified a number of molecular players and pathways that are relevant for parotid gland biology. Moreover, our detailed analysis has revealed a unique parotid gland-specific gene signature that may represent important players that could impart parotid gland-specific biological properties. To complement our transcriptomic studies, we have performed single-cell RNA sequencing to map the transcriptomes of parotid epithelial cells. Interrogation of the single-cell transcriptomes revealed the degree of molecular and cellular heterogeneity of the various epithelial cell types within the parotid gland. Moreover, we uncovered a mixed-lineage population of cells that may reflect molecular priming of differentiation potentials. Overall our comprehensive studies provide a powerful tool for the discovery of novel molecular players important in parotid gland biology."
0,Opioid-lnduced Constipation (OIC) Clinical Decision Support Tool,,
0,A Noisy Flow-Volume Loop,,
0,"Sex differences in GBM revealed by analysis of patient imaging, transcriptome, and survival data",,
0,Validation of the Decipher Test for Predicting Distant Metastatic Recurrence in Men with High-risk Nonmetastatic Prostate Cancer 10 Years After Surgery,"We investigated the prognostic role of Decipher among patients with high-risk prostate cancer. In European and US cohorts, each 10% increase in the Decipher score translated to a 53% and 58% increase in the risk of distant metastases, respectively, within 10 yr.","Validation of the Decipher Test for Predicting Distant Metastatic Recurrence in Men with High-risk Nonmetastatic Prostate Cancer 10 Years After Surgery. We investigated the prognostic role of Decipher among patients with high-risk prostate cancer. In European and US cohorts, each 10% increase in the Decipher score translated to a 53% and 58% increase in the risk of distant metastases, respectively, within 10 yr."
0,"Molecular docking, dynamics, and pharmacology studies on bexarotene as an agonist of ligand-activated transcription factors, retinoid X receptors","Retinoid X receptors (RXRs) belong to the nuclear receptor superfamily, and upon ligand activation, these receptors control gene transcription via either homodimerization with themselves or heterodimerization with the partner-nuclear receptor. The protective effects of RXRs and RXR agonists have been reported in several neurodegenerative diseases, including in the retina. This study was aimed to prioritize compounds from natural and synthetic origin retinoids as potential RXR agonists by molecular docking and molecular dynamic simulation strategies. The docking studies indicated bexarotene as a lead compound that can activate various RXR receptor isoforms (Î±, Î², and Î³) and has a strong binding affinity to the receptor protein than retinoic acid, which is known as a natural endogenous RXR agonist. Dynamic simulation studies confirmed that the hydrogen bonding and hydrophobic interactions were highly stable in all the three isoforms of the RXR-bexarotene complex. To further validate the significance of the RXR receptor in neurons, in vitro pharmacological treatment of neuronal SH-SY5Y cells with bexarotene was performed. In vitro data from SH-SY5Y cells confirmed that bexarotene activated RXR-simulated neurite outgrowth significantly. We conclude that bexarotene could be potentially used as an exogenous activator of RXRs and emerge as a good drug target for several neurodegenerative disorders.","Molecular docking, dynamics, and pharmacology studies on bexarotene as an agonist of ligand-activated transcription factors, retinoid X receptors. Retinoid X receptors (RXRs) belong to the nuclear receptor superfamily, and upon ligand activation, these receptors control gene transcription via either homodimerization with themselves or heterodimerization with the partner-nuclear receptor. The protective effects of RXRs and RXR agonists have been reported in several neurodegenerative diseases, including in the retina. This study was aimed to prioritize compounds from natural and synthetic origin retinoids as potential RXR agonists by molecular docking and molecular dynamic simulation strategies. The docking studies indicated bexarotene as a lead compound that can activate various RXR receptor isoforms (Î±, Î², and Î³) and has a strong binding affinity to the receptor protein than retinoic acid, which is known as a natural endogenous RXR agonist. Dynamic simulation studies confirmed that the hydrogen bonding and hydrophobic interactions were highly stable in all the three isoforms of the RXR-bexarotene complex. To further validate the significance of the RXR receptor in neurons, in vitro pharmacological treatment of neuronal SH-SY5Y cells with bexarotene was performed. In vitro data from SH-SY5Y cells confirmed that bexarotene activated RXR-simulated neurite outgrowth significantly. We conclude that bexarotene could be potentially used as an exogenous activator of RXRs and emerge as a good drug target for several neurodegenerative disorders."
0,Daphne Koller,,
0,Molecular and histological correlations in liver cancer,,
0,Incidence of neonatal neutropenia and leukopenia after in utero exposure to chemotherapy for maternal cancer,"Objective: The main purpose of this article was to report the incidence of neonatal neutropenia or leukopenia after chemotherapy exposure during pregnancy according to the time elapsed between treatment during pregnancy and birth. Background: A single study reports 33% of infants exposed to chemotherapy within the last month of pregnancy are born with neutropenia, which can place the newborn at risk for nosocomial infections. On the basis of this report, chemotherapy is typically stopped by 34 weeks of pregnancy to avoid maternal or neonatal myelosuppression at delivery. Such a pause in treatment may affect maternal health. Determining the true incidence of neutropenia after chemotherapy in relation to the time of this lapse in treatment is important to support this practice. Materials and Methods: Complete blood counts are collected for newborn whose mothers were treated for cancer during pregnancy and enrolled in the Cancer and Pregnancy Registry. Neutropenia was defined as absolute neutrophil count< 1000 mm3 and leukopenia was defined as white blood cells < 5000 cells /Î¼L. Incidence of neutropenia was calculated according to the time elapsed from last chemotherapy treatment until birth. Fisher's exact test is used to determine if neutropenia or leukopenia is related to the time elapsed between chemotherapy during pregnancy and newborn birth. A Bayesian analysis evaluated the occurrence of neutropenia and leukopenia according to the number of days between the initiation of chemotherapy and birth. Results: A total of 135 infants exposed to chemotherapy in utero with a complete blood count collected at birth were identified from the database. Only 7.3% and 2.9% of infants were born with neutropenia or leukopenia, respectively. The highest incidence of newborn neutropenia occurred in infants delivered 22 to 28 days after chemotherapy. Conclusions: The incidence of neutropenia peaks when chemotherapy is given 22 to 28 days before birth, while leukopenia is highest if delivery is < 7 days from chemotherapy.","Incidence of neonatal neutropenia and leukopenia after in utero exposure to chemotherapy for maternal cancer. Objective: The main purpose of this article was to report the incidence of neonatal neutropenia or leukopenia after chemotherapy exposure during pregnancy according to the time elapsed between treatment during pregnancy and birth. Background: A single study reports 33% of infants exposed to chemotherapy within the last month of pregnancy are born with neutropenia, which can place the newborn at risk for nosocomial infections. On the basis of this report, chemotherapy is typically stopped by 34 weeks of pregnancy to avoid maternal or neonatal myelosuppression at delivery. Such a pause in treatment may affect maternal health. Determining the true incidence of neutropenia after chemotherapy in relation to the time of this lapse in treatment is important to support this practice. Materials and Methods: Complete blood counts are collected for newborn whose mothers were treated for cancer during pregnancy and enrolled in the Cancer and Pregnancy Registry. Neutropenia was defined as absolute neutrophil count< 1000 mm3 and leukopenia was defined as white blood cells < 5000 cells /Î¼L. Incidence of neutropenia was calculated according to the time elapsed from last chemotherapy treatment until birth. Fisher's exact test is used to determine if neutropenia or leukopenia is related to the time elapsed between chemotherapy during pregnancy and newborn birth. A Bayesian analysis evaluated the occurrence of neutropenia and leukopenia according to the number of days between the initiation of chemotherapy and birth. Results: A total of 135 infants exposed to chemotherapy in utero with a complete blood count collected at birth were identified from the database. Only 7.3% and 2.9% of infants were born with neutropenia or leukopenia, respectively. The highest incidence of newborn neutropenia occurred in infants delivered 22 to 28 days after chemotherapy. Conclusions: The incidence of neutropenia peaks when chemotherapy is given 22 to 28 days before birth, while leukopenia is highest if delivery is < 7 days from chemotherapy."
0,Chronic Rhinosinusitis with Nasal Polyps,,
0,AliClu - Temporal sequence alignment for clustering longitudinal clinical data,"BACKGROUND: Patient stratification is a critical task in clinical decision making since it can allow physicians to choose treatments in a personalized way. Given the increasing availability of electronic medical records (EMRs) with longitudinal data, one crucial problem is how to efficiently cluster the patients based on the temporal information from medical appointments. In this work, we propose applying the Temporal Needleman-Wunsch (TNW) algorithm to align discrete sequences with the transition time information between symbols. These symbols may correspond to a patient's current therapy, their overall health status, or any other discrete state. The transition time information represents the duration of each of those states. The obtained TNW pairwise scores are then used to perform hierarchical clustering. To find the best number of clusters and assess their stability, a resampling technique is applied. RESULTS: We propose the AliClu, a novel tool for clustering temporal clinical data based on the TNW algorithm coupled with clustering validity assessments through bootstrapping. The AliClu was applied for the analysis of the rheumatoid arthritis EMRs obtained from the Portuguese database of rheumatologic patient visits (Reuma.pt). In particular, the AliClu was used for the analysis of therapy switches, which were coded as letters corresponding to biologic drugs and included their durations before each change occurred. The obtained optimized clusters allow one to stratify the patients based on their temporal therapy profiles and to support the identification of common features for those groups. CONCLUSIONS: The AliClu is a promising computational strategy to analyse longitudinal patient data by providing validated clusters and by unravelling the patterns that exist in clinical outcomes. Patient stratification is performed in an automatic or semi-automatic way, allowing one to tune the alignment, clustering, and validation parameters. The AliClu is freely available at https://github.com/sysbiomed/AliClu.","AliClu - Temporal sequence alignment for clustering longitudinal clinical data. BACKGROUND: Patient stratification is a critical task in clinical decision making since it can allow physicians to choose treatments in a personalized way. Given the increasing availability of electronic medical records (EMRs) with longitudinal data, one crucial problem is how to efficiently cluster the patients based on the temporal information from medical appointments. In this work, we propose applying the Temporal Needleman-Wunsch (TNW) algorithm to align discrete sequences with the transition time information between symbols. These symbols may correspond to a patient's current therapy, their overall health status, or any other discrete state. The transition time information represents the duration of each of those states. The obtained TNW pairwise scores are then used to perform hierarchical clustering. To find the best number of clusters and assess their stability, a resampling technique is applied. RESULTS: We propose the AliClu, a novel tool for clustering temporal clinical data based on the TNW algorithm coupled with clustering validity assessments through bootstrapping. The AliClu was applied for the analysis of the rheumatoid arthritis EMRs obtained from the Portuguese database of rheumatologic patient visits (Reuma.pt). In particular, the AliClu was used for the analysis of therapy switches, which were coded as letters corresponding to biologic drugs and included their durations before each change occurred. The obtained optimized clusters allow one to stratify the patients based on their temporal therapy profiles and to support the identification of common features for those groups. CONCLUSIONS: The AliClu is a promising computational strategy to analyse longitudinal patient data by providing validated clusters and by unravelling the patterns that exist in clinical outcomes. Patient stratification is performed in an automatic or semi-automatic way, allowing one to tune the alignment, clustering, and validation parameters. The AliClu is freely available at https://github.com/sysbiomed/AliClu."
0,Meta-Analysis Reveals Reproducible Gut Microbiome Alterations in Response to a High-Fat Diet,"Multiple research groups have shown that diet impacts the gut microbiome; however, variability in experimental design and quantitative assessment have made it challenging to assess the degree to which similar diets have reproducible effects across studies. Through an unbiased subject-level meta-analysis framework, we re-analyzed 27 dietary studies including 1,101 samples from rodents and humans. We demonstrate that a high-fat diet (HFD) reproducibly changes gut microbial community structure. Finer taxonomic analysis revealed that the most reproducible signals of a HFD are Lactococcus species, which we experimentally demonstrate to be common dietary contaminants. Additionally, a machine-learning approach defined a signature that predicts the dietary intake of mice and demonstrated that phylogenetic and gene-centric transformations of this model can be translated to humans. Together, these results demonstrate the utility of microbiome meta-analyses in identifying robust and reproducible features for mechanistic studies in preclinical models.","Meta-Analysis Reveals Reproducible Gut Microbiome Alterations in Response to a High-Fat Diet. Multiple research groups have shown that diet impacts the gut microbiome; however, variability in experimental design and quantitative assessment have made it challenging to assess the degree to which similar diets have reproducible effects across studies. Through an unbiased subject-level meta-analysis framework, we re-analyzed 27 dietary studies including 1,101 samples from rodents and humans. We demonstrate that a high-fat diet (HFD) reproducibly changes gut microbial community structure. Finer taxonomic analysis revealed that the most reproducible signals of a HFD are Lactococcus species, which we experimentally demonstrate to be common dietary contaminants. Additionally, a machine-learning approach defined a signature that predicts the dietary intake of mice and demonstrated that phylogenetic and gene-centric transformations of this model can be translated to humans. Together, these results demonstrate the utility of microbiome meta-analyses in identifying robust and reproducible features for mechanistic studies in preclinical models."
0,Artificial intelligence - upping the game in gastrointestinal endoscopy?,,
0,High-content phenotypic assay for proliferation of human iPSC-derived cardiomyocytes identifies L-type calcium channels as targets,"Over 5 million people in the United States suffer from heart failure, due to the limited ability to regenerate functional cardiac tissue. One potential therapeutic strategy is to enhance proliferation of resident cardiomyocytes. However, phenotypic screening for therapeutic agents is challenged by the limited ability of conventional markers to discriminate between cardiomyocyte proliferation and endoreplication (e.g. polyploidy and multinucleation). Here, we developed a novel assay that combines automated live-cell microscopy and image processing algorithms to discriminate between proliferation and endoreplication by quantifying changes in the number of nuclei, changes in the number of cells, binucleation, and nuclear DNA content. We applied this assay to further prioritize hits from a primary screen for DNA synthesis, identifying 30 compounds that enhance proliferation of human induced pluripotent stem cell-derived cardiomyocytes. Among the most active compounds from the phenotypic screen are clinically approved L-type calcium channel blockers from multiple chemical classes whose activities were confirmed across different sources of human induced pluripotent stem cell-derived cardiomyocytes. Identification of compounds that stimulate human cardiomyocyte proliferation may provide new therapeutic strategies for heart failure.","High-content phenotypic assay for proliferation of human iPSC-derived cardiomyocytes identifies L-type calcium channels as targets. Over 5 million people in the United States suffer from heart failure, due to the limited ability to regenerate functional cardiac tissue. One potential therapeutic strategy is to enhance proliferation of resident cardiomyocytes. However, phenotypic screening for therapeutic agents is challenged by the limited ability of conventional markers to discriminate between cardiomyocyte proliferation and endoreplication (e.g. polyploidy and multinucleation). Here, we developed a novel assay that combines automated live-cell microscopy and image processing algorithms to discriminate between proliferation and endoreplication by quantifying changes in the number of nuclei, changes in the number of cells, binucleation, and nuclear DNA content. We applied this assay to further prioritize hits from a primary screen for DNA synthesis, identifying 30 compounds that enhance proliferation of human induced pluripotent stem cell-derived cardiomyocytes. Among the most active compounds from the phenotypic screen are clinically approved L-type calcium channel blockers from multiple chemical classes whose activities were confirmed across different sources of human induced pluripotent stem cell-derived cardiomyocytes. Identification of compounds that stimulate human cardiomyocyte proliferation may provide new therapeutic strategies for heart failure."
0,Surface-constrained volumetric registration for the early developing brain,,
0,Braving the new world of artificial intelligence,,
0,Delirium detection using relative delta power based on 1-minute single-channel EEG: a multicentre study,"BACKGROUND: Delirium is frequently unrecognised. EEG shows slower frequencies (i.e. below 4 Hz) during delirium, which might be useful in improving delirium recognition. We studied the discriminative performance of a brief single-channel EEG recording for delirium detection in an independent cohort of patients. METHODS: In this prospective, multicentre study, postoperative patients aged >/=60 yr were included (n=159). Before operation and during the first 3 postoperative days, patients underwent a 5-min EEG recording, followed by a video-recorded standardised cognitive assessment. Two or, in case of disagreement, three delirium experts classified each postoperative day based on the video and chart review. Relative delta power (1-4 Hz) was based on 1-min artifact-free EEG. The diagnostic value of the relative delta power was evaluated by the area under the receiver operating characteristic curve (AUROC), using the expert classification as the gold standard. RESULTS: Experts classified 84 (23.3%) postoperative days as either delirium or possible delirium, and 276 (76.7%) non-delirium days. The AUROC of the relative EEG delta power was 0.75 [95% confidence interval (CI) 0.69-0.82]. Exploratory analysis showed that relative power from 1 to 6 Hz had significantly higher AUROC (0.78, 95% CI 0.72-0.84, P=0.014). CONCLUSIONS: Delirium/possible delirium can be detected in older postoperative patients based on a single-channel EEG recording that can be automatically analysed. This objective detection method with a continuous scale instead of a dichotomised outcome is a promising approach for routine detection of delirium. CLINICAL TRIAL REGISTRATION: NCT02404181.","Delirium detection using relative delta power based on 1-minute single-channel EEG: a multicentre study. BACKGROUND: Delirium is frequently unrecognised. EEG shows slower frequencies (i.e. below 4 Hz) during delirium, which might be useful in improving delirium recognition. We studied the discriminative performance of a brief single-channel EEG recording for delirium detection in an independent cohort of patients. METHODS: In this prospective, multicentre study, postoperative patients aged >/=60 yr were included (n=159). Before operation and during the first 3 postoperative days, patients underwent a 5-min EEG recording, followed by a video-recorded standardised cognitive assessment. Two or, in case of disagreement, three delirium experts classified each postoperative day based on the video and chart review. Relative delta power (1-4 Hz) was based on 1-min artifact-free EEG. The diagnostic value of the relative delta power was evaluated by the area under the receiver operating characteristic curve (AUROC), using the expert classification as the gold standard. RESULTS: Experts classified 84 (23.3%) postoperative days as either delirium or possible delirium, and 276 (76.7%) non-delirium days. The AUROC of the relative EEG delta power was 0.75 [95% confidence interval (CI) 0.69-0.82]. Exploratory analysis showed that relative power from 1 to 6 Hz had significantly higher AUROC (0.78, 95% CI 0.72-0.84, P=0.014). CONCLUSIONS: Delirium/possible delirium can be detected in older postoperative patients based on a single-channel EEG recording that can be automatically analysed. This objective detection method with a continuous scale instead of a dichotomised outcome is a promising approach for routine detection of delirium. CLINICAL TRIAL REGISTRATION: NCT02404181."
0,Mitigation of T-cell dependent immunogenicity by reengineering factor VIIa analogue,"Vatreptacog alfa (VA), a recombinant activated human factor VII (rFVIIa) variant with 3 amino acid substitutions, was developed to provide increased procoagulant activity in hemophilia patients with inhibitors to factor VIII or factor IX. In phase 3 clinical trials, changes introduced during the bioengineering of VA resulted in the development of undesired anti-drug antibodies in some patients, leading to the termination of a potentially promising therapeutic protein product. Here, we use preclinical biomarkers associated with clinical immunogenicity to validate our deimmunization strategy applied to this bioengineered rFVIIa analog. The reengineered rFVIIa analog variants retained increased intrinsic thrombin generation activity but did not elicit T-cell responses in peripheral blood mononuclear cells isolated from 50 HLA typed subjects representing the human population. Our algorithm, rational immunogenicity determination, offers a broadly applicable deimmunizing strategy for bioengineered proteins.","Mitigation of T-cell dependent immunogenicity by reengineering factor VIIa analogue. Vatreptacog alfa (VA), a recombinant activated human factor VII (rFVIIa) variant with 3 amino acid substitutions, was developed to provide increased procoagulant activity in hemophilia patients with inhibitors to factor VIII or factor IX. In phase 3 clinical trials, changes introduced during the bioengineering of VA resulted in the development of undesired anti-drug antibodies in some patients, leading to the termination of a potentially promising therapeutic protein product. Here, we use preclinical biomarkers associated with clinical immunogenicity to validate our deimmunization strategy applied to this bioengineered rFVIIa analog. The reengineered rFVIIa analog variants retained increased intrinsic thrombin generation activity but did not elicit T-cell responses in peripheral blood mononuclear cells isolated from 50 HLA typed subjects representing the human population. Our algorithm, rational immunogenicity determination, offers a broadly applicable deimmunizing strategy for bioengineered proteins."
0,"Comment on ""Reconstruction/repair of Iatrogenic Biliary Injuries: Is the Robot Offering a New Option? Short Clinical Report""",,
0,Implications of Tuberculosis Sputum Culture Test Sensitivity on Accuracy of Other Diagnostic Modalities,,
0,Fertility treatment use and breastfeeding outcomes,,
0,"Associations of genetics, behaviors, and life course circumstances with a novel aging and healthspan measure: Evidence from the Health and Retirement Study",,
0,Symptom-based stratification of patients with primary SjÃ¶gren's syndrome: multi-dimensional characterisation of international observational cohorts and reanalyses of randomised clinical trials,"Background: Heterogeneity is a major obstacle to developing effective treatments for patients with primary SjÃ¶gren's syndrome. We aimed to develop a robust method for stratification, exploiting heterogeneity in patient-reported symptoms, and to relate these differences to pathobiology and therapeutic response. Methods: We did hierarchical cluster analysis using five common symptoms associated with primary SjÃ¶gren's syndrome (pain, fatigue, dryness, anxiety, and depression), followed by multinomial logistic regression to identify subgroups in the UK Primary SjÃ¶gren's Syndrome Registry (UKPSSR). We assessed clinical and biological differences between these subgroups, including transcriptional differences in peripheral blood. Patients from two independent validation cohorts in Norway and France were used to confirm patient stratification. Data from two phase 3 clinical trials were similarly stratified to assess the differences between subgroups in treatment response to hydroxychloroquine and rituximab. Findings: In the UKPSSR cohort (n=608), we identified four subgroups: Low symptom burden (LSB), high symptom burden (HSB), dryness dominant with fatigue (DDF), and pain dominant with fatigue (PDF). Significant differences in peripheral blood lymphocyte counts, anti-SSA and anti-SSB antibody positivity, as well as serum IgG, Îº-free light chain, Î²2-microglobulin, and CXCL13 concentrations were observed between these subgroups, along with differentially expressed transcriptomic modules in peripheral blood. Similar findings were observed in the independent validation cohorts (n=396). Reanalysis of trial data stratifying patients into these subgroups suggested a treatment effect with hydroxychloroquine in the HSB subgroup and with rituximab in the DDF subgroup compared with placebo. Interpretation: Stratification on the basis of patient-reported symptoms of patients with primary SjÃ¶gren's syndrome revealed distinct pathobiological endotypes with distinct responses to immunomodulatory treatments. Our data have important implications for clinical management, trial design, and therapeutic development. Similar stratification approaches might be useful for patients with other chronic immune-mediated diseases. Funding: UK Medical Research Council, British Sjogren's Syndrome Association, French Ministry of Health, Arthritis Research UK, Foundation for Research in Rheumatology. Video Abstract: [Figure presented]","Symptom-based stratification of patients with primary SjÃ¶gren's syndrome: multi-dimensional characterisation of international observational cohorts and reanalyses of randomised clinical trials. Background: Heterogeneity is a major obstacle to developing effective treatments for patients with primary SjÃ¶gren's syndrome. We aimed to develop a robust method for stratification, exploiting heterogeneity in patient-reported symptoms, and to relate these differences to pathobiology and therapeutic response. Methods: We did hierarchical cluster analysis using five common symptoms associated with primary SjÃ¶gren's syndrome (pain, fatigue, dryness, anxiety, and depression), followed by multinomial logistic regression to identify subgroups in the UK Primary SjÃ¶gren's Syndrome Registry (UKPSSR). We assessed clinical and biological differences between these subgroups, including transcriptional differences in peripheral blood. Patients from two independent validation cohorts in Norway and France were used to confirm patient stratification. Data from two phase 3 clinical trials were similarly stratified to assess the differences between subgroups in treatment response to hydroxychloroquine and rituximab. Findings: In the UKPSSR cohort (n=608), we identified four subgroups: Low symptom burden (LSB), high symptom burden (HSB), dryness dominant with fatigue (DDF), and pain dominant with fatigue (PDF). Significant differences in peripheral blood lymphocyte counts, anti-SSA and anti-SSB antibody positivity, as well as serum IgG, Îº-free light chain, Î²2-microglobulin, and CXCL13 concentrations were observed between these subgroups, along with differentially expressed transcriptomic modules in peripheral blood. Similar findings were observed in the independent validation cohorts (n=396). Reanalysis of trial data stratifying patients into these subgroups suggested a treatment effect with hydroxychloroquine in the HSB subgroup and with rituximab in the DDF subgroup compared with placebo. Interpretation: Stratification on the basis of patient-reported symptoms of patients with primary SjÃ¶gren's syndrome revealed distinct pathobiological endotypes with distinct responses to immunomodulatory treatments. Our data have important implications for clinical management, trial design, and therapeutic development. Similar stratification approaches might be useful for patients with other chronic immune-mediated diseases. Funding: UK Medical Research Council, British Sjogren's Syndrome Association, French Ministry of Health, Arthritis Research UK, Foundation for Research in Rheumatology. Video Abstract: [Figure presented]"
0,Author Correction: End-to-end lung cancer screening with three-dimensional deep learning on low-dose chest computed tomography,An amendment to this paper has been published and can be accessed via a link at the top of the paper.,Author Correction: End-to-end lung cancer screening with three-dimensional deep learning on low-dose chest computed tomography. An amendment to this paper has been published and can be accessed via a link at the top of the paper.
0,Defining Risk Factors for Chemotherapeutic Intervention in Infants With Stage 4S Neuroblastoma: A Report From Children's Oncology Group Study ANBL0531,,
0,Preserving the balance: diverse forms of long-term GABAergic synaptic plasticity,,
0,Dual-Energy CT in Children: Imaging Algorithms and Clinical Applications,"Dual-energy CT enables the simultaneous acquisition of CT images at two different x-ray energy spectra. By acquiring high- and low-energy spectral data, dual-energy CT can provide unique qualitative and quantitative information about tissue composition, allowing differentiation of multiple materials including iodinated contrast agents. The two dual-energy CT postprocessing techniques that best exploit the advantages of dual-energy CT in children are the material-decomposition images (which include virtual nonenhanced, iodine, perfused lung blood volume, lung vessel, automated bone removal, and renal stone characterization images) and virtual monoenergetic images. Clinical applications include assessment of the arterial system, lung perfusion, neoplasm, bowel diseases, renal calculi, tumor response to treatment, and metal implants. Of importance, the radiation exposure level of dual-energy CT is equivalent to or less than that of conventional single-energy CT. In this review, the authors discuss the basic principles of the dual-energy CT technologies and postprocessing techniques and review current clinical applications in the pediatric chest and abdomen.","Dual-Energy CT in Children: Imaging Algorithms and Clinical Applications. Dual-energy CT enables the simultaneous acquisition of CT images at two different x-ray energy spectra. By acquiring high- and low-energy spectral data, dual-energy CT can provide unique qualitative and quantitative information about tissue composition, allowing differentiation of multiple materials including iodinated contrast agents. The two dual-energy CT postprocessing techniques that best exploit the advantages of dual-energy CT in children are the material-decomposition images (which include virtual nonenhanced, iodine, perfused lung blood volume, lung vessel, automated bone removal, and renal stone characterization images) and virtual monoenergetic images. Clinical applications include assessment of the arterial system, lung perfusion, neoplasm, bowel diseases, renal calculi, tumor response to treatment, and metal implants. Of importance, the radiation exposure level of dual-energy CT is equivalent to or less than that of conventional single-energy CT. In this review, the authors discuss the basic principles of the dual-energy CT technologies and postprocessing techniques and review current clinical applications in the pediatric chest and abdomen."
0,Re-formulating Gehan's design as a flexible two-stage single-arm trial,"BACKGROUND: Gehan's two-stage design was historically the design of choice for phase II oncology trials. One of the reasons it is less frequently used today is that it does not allow for a formal test of treatment efficacy, and therefore does not control conventional type-I and type-II error-rates. METHODS: We describe how recently developed methodology for flexible two-stage single-arm trials can be used to incorporate the hypothesis test commonly associated with phase II trials in to Gehan's design. We additionally detail how this hypothesis test can be optimised in order to maximise its power, and describe how the second stage sample sizes can be chosen to more readily provide the operating characteristics that were originally envisioned by Gehan. Finally, we contrast our modified Gehan designs to Simon's designs, based on two examples motivated by real clinical trials. RESULTS: Gehan's original designs are often greatly under- or over-powered when compared to type-II error-rates typically used in phase II. However, we demonstrate that the control parameters of his design can be chosen to resolve this problem. With this, though, the modified Gehan designs have operating characteristics similar to the more familiar Simon designs. CONCLUSIONS: The trial design settings in which Gehan's design will be preferable over Simon's designs are likely limited. Provided the second stage sample sizes are chosen carefully, however, one scenario of potential utility is when the trial's primary goal is to ascertain the treatment response rate to a certain precision.","Re-formulating Gehan's design as a flexible two-stage single-arm trial. BACKGROUND: Gehan's two-stage design was historically the design of choice for phase II oncology trials. One of the reasons it is less frequently used today is that it does not allow for a formal test of treatment efficacy, and therefore does not control conventional type-I and type-II error-rates. METHODS: We describe how recently developed methodology for flexible two-stage single-arm trials can be used to incorporate the hypothesis test commonly associated with phase II trials in to Gehan's design. We additionally detail how this hypothesis test can be optimised in order to maximise its power, and describe how the second stage sample sizes can be chosen to more readily provide the operating characteristics that were originally envisioned by Gehan. Finally, we contrast our modified Gehan designs to Simon's designs, based on two examples motivated by real clinical trials. RESULTS: Gehan's original designs are often greatly under- or over-powered when compared to type-II error-rates typically used in phase II. However, we demonstrate that the control parameters of his design can be chosen to resolve this problem. With this, though, the modified Gehan designs have operating characteristics similar to the more familiar Simon designs. CONCLUSIONS: The trial design settings in which Gehan's design will be preferable over Simon's designs are likely limited. Provided the second stage sample sizes are chosen carefully, however, one scenario of potential utility is when the trial's primary goal is to ascertain the treatment response rate to a certain precision."
0,Prescribing in primary care: art versus algorithm,,
0,Deeper learning,,
0,Precise Temporal Regulation of Molecular Diffusion within Dendritic Spines by Actin Polymers during Structural Plasticity,"The biochemical transduction of excitatory synaptic signals occurs in the cytoplasm within dendritic spines. The associated reaction kinetics are shaped by the mobility of the signaling molecules; however, accurate monitoring of diffusional events within the femtoliter-sized spine structures has not yet been demonstrated. Here, we applied two-photon fluorescence correlation spectroscopy and raster image correlation spectroscopy to monitor protein dynamics within spines, revealing that F-actin restricts the mobility of proteins with a molecular mass of >100 kDa. This restriction is transiently removed during actin remodeling at the initial phase of spine structural plasticity. Photobleaching experiments combined with super-resolution imaging indicate that this increase in mobility facilitates molecular interactions, which may modulate the functions of key postsynaptic signaling molecules, such as Tiam1 and CaMKII. Thus, actin polymers in dendritic spines act as precise temporal regulators of molecular diffusion and modulate signal transduction during synaptic plasticity. Obashi et al. show that actin polymers within dendritic spines restrict mobility of large molecules using optical measurements of fluorescence correlation. Acute actin remodeling induced by plasticity-inducing stimuli increases the mobility of large postsynaptic signaling molecules, which regulate long-term changes in synaptic property.","Precise Temporal Regulation of Molecular Diffusion within Dendritic Spines by Actin Polymers during Structural Plasticity. The biochemical transduction of excitatory synaptic signals occurs in the cytoplasm within dendritic spines. The associated reaction kinetics are shaped by the mobility of the signaling molecules; however, accurate monitoring of diffusional events within the femtoliter-sized spine structures has not yet been demonstrated. Here, we applied two-photon fluorescence correlation spectroscopy and raster image correlation spectroscopy to monitor protein dynamics within spines, revealing that F-actin restricts the mobility of proteins with a molecular mass of >100 kDa. This restriction is transiently removed during actin remodeling at the initial phase of spine structural plasticity. Photobleaching experiments combined with super-resolution imaging indicate that this increase in mobility facilitates molecular interactions, which may modulate the functions of key postsynaptic signaling molecules, such as Tiam1 and CaMKII. Thus, actin polymers in dendritic spines act as precise temporal regulators of molecular diffusion and modulate signal transduction during synaptic plasticity. Obashi et al. show that actin polymers within dendritic spines restrict mobility of large molecules using optical measurements of fluorescence correlation. Acute actin remodeling induced by plasticity-inducing stimuli increases the mobility of large postsynaptic signaling molecules, which regulate long-term changes in synaptic property."
0,Epigenetic modifications but not genetic polymorphisms regulate KEAP1 expression in colorectal cancer,"Kelch-like ECH-associated protein 1 (KEAP1), as a negative regulator of nuclear factor erythroid 2 like 2 (NRF2), plays a pivotal role in NRF2 signaling pathway and involves in tumorigenesis. Polymorphisms and methylation in gene promoter region may influence its expression and be related to cancer susceptibility. In this study, we examined the effect of the KEAP1-NRF2 interaction on the risk of colorectal cancer (CRC). The polymorphisms of NRF2 and KEAP1 were genotyped using the improved multiplex ligase detection reaction assay. KEAP1 promoter methylation and histone modification were analyzed using bisulfite genome sequencing and chromatin immunoprecipitation (ChIP) assay, respectively. The KEAP1 rs1048290 CC genotype and C allele were associated with increased risks of CRC (CC vs GG: odds ratio [OR] = 1.39; 95% confidence interval [CI], 1.08-1.78; CC vs GG/GC: OR = 1.29; 95% CI, 1.05-1.58; C vs G: OR = 1.18; 95% CI, 1.04-1.34). The rs1048290-rs11545829 GT haplotype was associated with a reduced risk of CRC. KEAP1-NRF2 interaction analysis revealed that the rs6721961, rs35652124, rs1048290, and rs11545829 conferred the susceptibility to CRC. The hypermethylation of KEAP1 promoter resulted in lower levels of KEAP1 messenger RNA (mRNA). After treatment with 5-aza-2â€²-deoxycytidine/trichostatin A, KEAP1 promoter methylation was decreased and KEAP1 mRNA levels were increased. ChIP-quantitative polymerase chain reaction results showed an enhanced enrichment of H3K4Me3 and H3K27Ac to the promoter of KEAP1. In vitro methylation analysis showed that the methylated plasmid decreased the transcriptional activity by 70%-84%. These findings suggest that the KEAP1- NRF2 pathway could potentially impact CRC risk and the downregulation of KEAP1 could be explained in part by epigenetic modifications.","Epigenetic modifications but not genetic polymorphisms regulate KEAP1 expression in colorectal cancer. Kelch-like ECH-associated protein 1 (KEAP1), as a negative regulator of nuclear factor erythroid 2 like 2 (NRF2), plays a pivotal role in NRF2 signaling pathway and involves in tumorigenesis. Polymorphisms and methylation in gene promoter region may influence its expression and be related to cancer susceptibility. In this study, we examined the effect of the KEAP1-NRF2 interaction on the risk of colorectal cancer (CRC). The polymorphisms of NRF2 and KEAP1 were genotyped using the improved multiplex ligase detection reaction assay. KEAP1 promoter methylation and histone modification were analyzed using bisulfite genome sequencing and chromatin immunoprecipitation (ChIP) assay, respectively. The KEAP1 rs1048290 CC genotype and C allele were associated with increased risks of CRC (CC vs GG: odds ratio [OR] = 1.39; 95% confidence interval [CI], 1.08-1.78; CC vs GG/GC: OR = 1.29; 95% CI, 1.05-1.58; C vs G: OR = 1.18; 95% CI, 1.04-1.34). The rs1048290-rs11545829 GT haplotype was associated with a reduced risk of CRC. KEAP1-NRF2 interaction analysis revealed that the rs6721961, rs35652124, rs1048290, and rs11545829 conferred the susceptibility to CRC. The hypermethylation of KEAP1 promoter resulted in lower levels of KEAP1 messenger RNA (mRNA). After treatment with 5-aza-2â€²-deoxycytidine/trichostatin A, KEAP1 promoter methylation was decreased and KEAP1 mRNA levels were increased. ChIP-quantitative polymerase chain reaction results showed an enhanced enrichment of H3K4Me3 and H3K27Ac to the promoter of KEAP1. In vitro methylation analysis showed that the methylated plasmid decreased the transcriptional activity by 70%-84%. These findings suggest that the KEAP1- NRF2 pathway could potentially impact CRC risk and the downregulation of KEAP1 could be explained in part by epigenetic modifications."
0,Exploring specific prognostic biomarkers in triple-negative breast cancer,"Lacking of both prognostic biomarkers and therapeutic targets, triple-negative breast cancer (TNBC) underscores pivotal needs to uncover novel biomarkers and viable therapies. MicroRNAs have broad biological functions in cancers and may serve as ideal biomarkers. In this study, by data mining of the Cancer Genome Atlas database, we screened out 4 differentially-expressed microRNAs (DEmiRNAs) between TNBC and normal samples: miR-135b-5p, miR-9-3p, miR-135b-3p and miR-455-5p. They were specially correlated with the prognosis of TNBC but not non-TNBC. The weighted correlation network analysis (WGCNA) for potential target genes of 3 good prognosis-related DEmiRNAs (miR-135b-5p, miR-9-3p, miR-135b-3p) identified 4 hub genes with highly positive correlation with TNBC subtype: FOXC1, BCL11A, FAM171A1 and RGMA. The targeting relationships between miR-9-3p and FOXC1/FAM171A1, miR-135b-3p and RGMA were validated by dual-luciferase reporter assays. Importantly, the regulatory functions of 4 DEmiRNAs and 3 verified target genes on cell proliferation and migration were explored in TNBC cell lines. In conclusion, we shed lights on these 4 DEmiRNAs (miR-135b-5p, miR-9-3p, miR-135b-3p, miR-455-5p) and 3 hub genes (FOXC1, FAM171A1, RGMA) as specific prognostic biomarkers and promising therapeutic targets for TNBC.","Exploring specific prognostic biomarkers in triple-negative breast cancer. Lacking of both prognostic biomarkers and therapeutic targets, triple-negative breast cancer (TNBC) underscores pivotal needs to uncover novel biomarkers and viable therapies. MicroRNAs have broad biological functions in cancers and may serve as ideal biomarkers. In this study, by data mining of the Cancer Genome Atlas database, we screened out 4 differentially-expressed microRNAs (DEmiRNAs) between TNBC and normal samples: miR-135b-5p, miR-9-3p, miR-135b-3p and miR-455-5p. They were specially correlated with the prognosis of TNBC but not non-TNBC. The weighted correlation network analysis (WGCNA) for potential target genes of 3 good prognosis-related DEmiRNAs (miR-135b-5p, miR-9-3p, miR-135b-3p) identified 4 hub genes with highly positive correlation with TNBC subtype: FOXC1, BCL11A, FAM171A1 and RGMA. The targeting relationships between miR-9-3p and FOXC1/FAM171A1, miR-135b-3p and RGMA were validated by dual-luciferase reporter assays. Importantly, the regulatory functions of 4 DEmiRNAs and 3 verified target genes on cell proliferation and migration were explored in TNBC cell lines. In conclusion, we shed lights on these 4 DEmiRNAs (miR-135b-5p, miR-9-3p, miR-135b-3p, miR-455-5p) and 3 hub genes (FOXC1, FAM171A1, RGMA) as specific prognostic biomarkers and promising therapeutic targets for TNBC."
0,"In patients with suspected AMI and LBBB, algorithms based on ECG and troponin data were tested to rule MI in or out",,
0,Will AI Improve Tumor Delineation Accuracy for Radiation Therapy?,,
0,Zinc ions increase GH signaling ability through regulation of available plasma membrane-localized GHR,"It is well known that zinc ion (Zn2+) can regulate the biological activity of growth hormone (GH). However, until now, the mechanism by which Zn2+ regulates GH biological activity remains unclear. In the current study, we first performed molecular docking between Zn2+ and porcine GH (pGH) using computational biology. We then explored the effect of Zn2+ on the GH signaling ability in the cell model expressing porcine growth hormone receptor (GHR). It was found that the phosphorylation levels of Janus kinase 2, signal transducers and activators of transcription 5/3/1, and GHR increased significantly under Zn2+ treatment, indicating that Zn2+ can enhance the signaling ability of GH/GHR. On this basis, we further explored how Zn2+ regulates the biological activity of GH/GHR. The results showed that downregulation and turnover of GHR changed under Zn2+/pGH treatment. Zn2+ enhanced the membrane residence time of pGH/GHR and delayed GHR downregulation. Further investigation showed that the internalization dynamic of pGH/GHR was changed by Zn2+, which prolonged the residence time of pGH/GHR in the cell membrane. These factors acted together to upregulate the signaling of GH/GHR. This study lays a foundation for further exploration of the biological effects of Zn2+ on GH. (Figure presented.).","Zinc ions increase GH signaling ability through regulation of available plasma membrane-localized GHR. It is well known that zinc ion (Zn2+) can regulate the biological activity of growth hormone (GH). However, until now, the mechanism by which Zn2+ regulates GH biological activity remains unclear. In the current study, we first performed molecular docking between Zn2+ and porcine GH (pGH) using computational biology. We then explored the effect of Zn2+ on the GH signaling ability in the cell model expressing porcine growth hormone receptor (GHR). It was found that the phosphorylation levels of Janus kinase 2, signal transducers and activators of transcription 5/3/1, and GHR increased significantly under Zn2+ treatment, indicating that Zn2+ can enhance the signaling ability of GH/GHR. On this basis, we further explored how Zn2+ regulates the biological activity of GH/GHR. The results showed that downregulation and turnover of GHR changed under Zn2+/pGH treatment. Zn2+ enhanced the membrane residence time of pGH/GHR and delayed GHR downregulation. Further investigation showed that the internalization dynamic of pGH/GHR was changed by Zn2+, which prolonged the residence time of pGH/GHR in the cell membrane. These factors acted together to upregulate the signaling of GH/GHR. This study lays a foundation for further exploration of the biological effects of Zn2+ on GH. (Figure presented.)."
0,Alternative dosing guidelines to improve outcomes in childhood tuberculosis: a mathematical modelling study,,
0,Systematic identification and analysis of dysregulated miRNA and transcription factor feed-forward loops in hypertrophic cardiomyopathy,"Hypertrophic cardiomyopathy (HCM) is the most common genetic cardiovascular disease. Although some genes and miRNAs related with HCM have been studied, the molecular regulatory mechanisms between miRNAs and transcription factors (TFs) in HCM have not been systematically elucidated. In this study, we proposed a novel method for identifying dysregulated miRNA-TF feed-forward loops (FFLs) by integrating sample matched miRNA and gene expression profiles and experimentally verified interactions of TF-target gene and miRNA-target gene. We identified 316 dysregulated miRNA-TF FFLs in HCM, which were confirmed to be closely related with HCM from various perspectives. Subpathway enrichment analysis demonstrated that the method was outperformed by the existing method. Furthermore, we systematically analysed the global architecture and feature of gene regulation by miRNAs and TFs in HCM, and the FFL composed of hsa-miR-17-5p, FASN and STAT3 was inferred to play critical roles in HCM. Additionally, we identified two panels of biomarkers defined by three TFs (CEBPB, HIF1A, and STAT3) and four miRNAs (hsa-miR-155-5p, hsa-miR-17-5p, hsa-miR-20a-5p, and hsa-miR-181a-5p) in a discovery cohort of 126 samples, which could differentiate HCM patients from healthy controls with better performance. Our work provides HCM-related dysregulated miRNA-TF FFLs for further experimental study, and provides candidate biomarkers for HCM diagnosis and treatment.","Systematic identification and analysis of dysregulated miRNA and transcription factor feed-forward loops in hypertrophic cardiomyopathy. Hypertrophic cardiomyopathy (HCM) is the most common genetic cardiovascular disease. Although some genes and miRNAs related with HCM have been studied, the molecular regulatory mechanisms between miRNAs and transcription factors (TFs) in HCM have not been systematically elucidated. In this study, we proposed a novel method for identifying dysregulated miRNA-TF feed-forward loops (FFLs) by integrating sample matched miRNA and gene expression profiles and experimentally verified interactions of TF-target gene and miRNA-target gene. We identified 316 dysregulated miRNA-TF FFLs in HCM, which were confirmed to be closely related with HCM from various perspectives. Subpathway enrichment analysis demonstrated that the method was outperformed by the existing method. Furthermore, we systematically analysed the global architecture and feature of gene regulation by miRNAs and TFs in HCM, and the FFL composed of hsa-miR-17-5p, FASN and STAT3 was inferred to play critical roles in HCM. Additionally, we identified two panels of biomarkers defined by three TFs (CEBPB, HIF1A, and STAT3) and four miRNAs (hsa-miR-155-5p, hsa-miR-17-5p, hsa-miR-20a-5p, and hsa-miR-181a-5p) in a discovery cohort of 126 samples, which could differentiate HCM patients from healthy controls with better performance. Our work provides HCM-related dysregulated miRNA-TF FFLs for further experimental study, and provides candidate biomarkers for HCM diagnosis and treatment."
0,A whole-brain atlas of monosynaptic input targeting four different cell types in the medial prefrontal cortex of the mouse,,
0,Finding Glaucoma in Color Fundus Photographs Using Deep Learning,,
0,The binding affinity of PTPN13's tandem PDZ2/3 domain is allosterically modulated,"Background: Protein tyrosine phosphatase PTPN13, also known as PTP-BL in mice, is a large multi-domain non-transmembrane scaffolding protein with a molecular mass of 270 kDa. It is involved in the regulation of several cellular processes such as cytokinesis and actin-cytoskeletal rearrangement. The modular structure of PTPN13 consists of an N-terminal KIND domain, a FERM domain, and five PDZ domains, followed by a C-terminal protein tyrosine phosphatase domain. PDZ domains are among the most abundant protein modules and they play a crucial role in signal transduction of protein networks. Results: Here, we have analysed the binding characteristics of the isolated PDZ domains 2 and 3 from PTPN13 and compared them to the tandem domain PDZ2/3, which interacts with 12 C-terminal residues of the tumour suppressor protein of APC, using heteronuclear multidimensional NMR spectroscopy. Furthermore, we could show for the first time that PRK2 is a weak binding partner of PDZ2 and we demonstrate that the presence of PDZ3 alters the binding affinity of PDZ2 for APC, suggesting an allosteric effect and thereby modulating the binding characteristics of PDZ2. A HADDOCK-based molecular model of the PDZ2/3 tandem domain from PTPN13 supports these results. Conclusions: Our study of tandem PDZ2/3 in complex with APC suggests that the interaction of PDZ3 with PDZ2 induces an allosteric modulation within PDZ2 emanating from the back of the domain to the ligand binding site. Thus, the modified binding preference of PDZ2 for APC could be explained by an allosteric effect and provides further evidence for the pivotal function of PDZ2 in the PDZ123 domain triplet within PTPN13.","The binding affinity of PTPN13's tandem PDZ2/3 domain is allosterically modulated. Background: Protein tyrosine phosphatase PTPN13, also known as PTP-BL in mice, is a large multi-domain non-transmembrane scaffolding protein with a molecular mass of 270 kDa. It is involved in the regulation of several cellular processes such as cytokinesis and actin-cytoskeletal rearrangement. The modular structure of PTPN13 consists of an N-terminal KIND domain, a FERM domain, and five PDZ domains, followed by a C-terminal protein tyrosine phosphatase domain. PDZ domains are among the most abundant protein modules and they play a crucial role in signal transduction of protein networks. Results: Here, we have analysed the binding characteristics of the isolated PDZ domains 2 and 3 from PTPN13 and compared them to the tandem domain PDZ2/3, which interacts with 12 C-terminal residues of the tumour suppressor protein of APC, using heteronuclear multidimensional NMR spectroscopy. Furthermore, we could show for the first time that PRK2 is a weak binding partner of PDZ2 and we demonstrate that the presence of PDZ3 alters the binding affinity of PDZ2 for APC, suggesting an allosteric effect and thereby modulating the binding characteristics of PDZ2. A HADDOCK-based molecular model of the PDZ2/3 tandem domain from PTPN13 supports these results. Conclusions: Our study of tandem PDZ2/3 in complex with APC suggests that the interaction of PDZ3 with PDZ2 induces an allosteric modulation within PDZ2 emanating from the back of the domain to the ligand binding site. Thus, the modified binding preference of PDZ2 for APC could be explained by an allosteric effect and provides further evidence for the pivotal function of PDZ2 in the PDZ123 domain triplet within PTPN13."
0,Entropy of mitochondrial DNA circulating in blood is associated with hepatocellular carcinoma,"Background: Ultra-Deep Sequencing (UDS) enabled identification of specific changes in human genome occurring in malignant tumors, with current approaches calling for the detection of specific mutations associated with certain cancers. However, such associations are frequently idiosyncratic and cannot be generalized for diagnostics. Mitochondrial DNA (mtDNA) has been shown to be functionally associated with several cancer types. Here, we study the association of intra-host mtDNA diversity with Hepatocellular Carcinoma (HCC). Results: UDS mtDNA exome data from blood of patients with HCC (n = 293) and non-cancer controls (NC, n = 391) were used to: (i) measure the genetic heterogeneity of nucleotide sites from the entire population of intra-host mtDNA variants rather than to detect specific mutations, and (ii) apply machine learning algorithms to develop a classifier for HCC detection. Average total entropy of HCC mtDNA is 1.24-times lower than of NC mtDNA (p = 2.84E-47). Among all polymorphic sites, 2.09% had a significantly different mean entropy between HCC and NC, with 0.32% of the HCC mtDNA sites having greater (p < 0.05) and 1.77% of the sites having lower mean entropy (p < 0.05) as compared to NC. The entropy profile of each sample was used to further explore the association between mtDNA heterogeneity and HCC by means of a Random Forest (RF) classifier The RF-classifier separated 232 HCC and 232 NC patients with accuracy of up to 99.78% and average accuracy of 92.23% in the 10-fold cross-validation. The classifier accurately separated 93.08% of HCC (n = 61) and NC (n = 159) patients in a validation dataset that was not used for the RF parameter optimization. Conclusions: Polymorphic sites contributing most to the mtDNA association with HCC are scattered along the mitochondrial genome, affecting all mitochondrial genes. The findings suggest that application of heterogeneity profiles of intra-host mtDNA variants from blood may help overcome barriers associated with the complex association of specific mutations with cancer, enabling the development of accurate, rapid, inexpensive and minimally invasive diagnostic detection of cancer.","Entropy of mitochondrial DNA circulating in blood is associated with hepatocellular carcinoma. Background: Ultra-Deep Sequencing (UDS) enabled identification of specific changes in human genome occurring in malignant tumors, with current approaches calling for the detection of specific mutations associated with certain cancers. However, such associations are frequently idiosyncratic and cannot be generalized for diagnostics. Mitochondrial DNA (mtDNA) has been shown to be functionally associated with several cancer types. Here, we study the association of intra-host mtDNA diversity with Hepatocellular Carcinoma (HCC). Results: UDS mtDNA exome data from blood of patients with HCC (n = 293) and non-cancer controls (NC, n = 391) were used to: (i) measure the genetic heterogeneity of nucleotide sites from the entire population of intra-host mtDNA variants rather than to detect specific mutations, and (ii) apply machine learning algorithms to develop a classifier for HCC detection. Average total entropy of HCC mtDNA is 1.24-times lower than of NC mtDNA (p = 2.84E-47). Among all polymorphic sites, 2.09% had a significantly different mean entropy between HCC and NC, with 0.32% of the HCC mtDNA sites having greater (p < 0.05) and 1.77% of the sites having lower mean entropy (p < 0.05) as compared to NC. The entropy profile of each sample was used to further explore the association between mtDNA heterogeneity and HCC by means of a Random Forest (RF) classifier The RF-classifier separated 232 HCC and 232 NC patients with accuracy of up to 99.78% and average accuracy of 92.23% in the 10-fold cross-validation. The classifier accurately separated 93.08% of HCC (n = 61) and NC (n = 159) patients in a validation dataset that was not used for the RF parameter optimization. Conclusions: Polymorphic sites contributing most to the mtDNA association with HCC are scattered along the mitochondrial genome, affecting all mitochondrial genes. The findings suggest that application of heterogeneity profiles of intra-host mtDNA variants from blood may help overcome barriers associated with the complex association of specific mutations with cancer, enabling the development of accurate, rapid, inexpensive and minimally invasive diagnostic detection of cancer."
0,A Comparison between the Compass Fundus Perimeter and the Humphrey Field Analyzer,"PURPOSE: To evaluate relative diagnostic precision and test-retest variability of 2 devices, the Compass (CMP, CenterVue, Padova, Italy) fundus perimeter and the Humphrey Field Analyzer (HFA, Zeiss, Dublin, CA), in detecting glaucomatous optic neuropathy (GON). DESIGN: Multicenter, cross-sectional, case-control study. PARTICIPANTS: We sequentially enrolled 499 patients with glaucoma and 444 normal subjects to analyze relative precision. A separate group of 44 patients with glaucoma and 54 normal subjects was analyzed to assess test-retest variability. METHODS: One eye of recruited subjects was tested with the index tests: HFA (Swedish interactive thresholding algorithm [SITA] standard strategy) and CMP (Zippy Estimation by Sequential Testing [ZEST] strategy), 24-2 grid. The reference test for GON was specialist evaluation of fundus photographs or OCT, independent of the visual field (VF). For both devices, linear regression was used to calculate the sensitivity decrease with age in the normal group to compute pointwise total deviation (TD) values and mean deviation (MD). We derived 5% and 1% pointwise normative limits. The MD and the total number of TD values below 5% (TD 5%) or 1% (TD 1%) limits per field were used as classifiers. MAIN OUTCOME MEASURES: We used partial receiver operating characteristic (pROC) curves and partial area under the curve (pAUC) to compare the diagnostic precision of the devices. Pointwise mean absolute deviation and Bland-Altman plots for the mean sensitivity (MS) were computed to assess test-retest variability. RESULTS: Retinal sensitivity was generally lower with CMP, with an average mean difference of 1.85+/-0.06 decibels (dB) (mean +/- standard error, P < 0.001) in healthy subjects and 1.46+/-0.05 dB (mean +/- standard error, P < 0.001) in patients with glaucoma. Both devices showed similar discriminative power. The MD metric had marginally better discrimination with CMP (pAUC difference +/- standard error, 0.019+/-0.009, P = 0.035). The 95% limits of agreement for the MS were reduced by 13% in CMP compared with HFA in participants with glaucoma and by 49% in normal participants. Mean absolute deviation was similar, with no significant differences. CONCLUSIONS: Relative diagnostic precision of the 2 devices is equivalent. Test-retest variability of MS for CMP was better than for HFA.","A Comparison between the Compass Fundus Perimeter and the Humphrey Field Analyzer. PURPOSE: To evaluate relative diagnostic precision and test-retest variability of 2 devices, the Compass (CMP, CenterVue, Padova, Italy) fundus perimeter and the Humphrey Field Analyzer (HFA, Zeiss, Dublin, CA), in detecting glaucomatous optic neuropathy (GON). DESIGN: Multicenter, cross-sectional, case-control study. PARTICIPANTS: We sequentially enrolled 499 patients with glaucoma and 444 normal subjects to analyze relative precision. A separate group of 44 patients with glaucoma and 54 normal subjects was analyzed to assess test-retest variability. METHODS: One eye of recruited subjects was tested with the index tests: HFA (Swedish interactive thresholding algorithm [SITA] standard strategy) and CMP (Zippy Estimation by Sequential Testing [ZEST] strategy), 24-2 grid. The reference test for GON was specialist evaluation of fundus photographs or OCT, independent of the visual field (VF). For both devices, linear regression was used to calculate the sensitivity decrease with age in the normal group to compute pointwise total deviation (TD) values and mean deviation (MD). We derived 5% and 1% pointwise normative limits. The MD and the total number of TD values below 5% (TD 5%) or 1% (TD 1%) limits per field were used as classifiers. MAIN OUTCOME MEASURES: We used partial receiver operating characteristic (pROC) curves and partial area under the curve (pAUC) to compare the diagnostic precision of the devices. Pointwise mean absolute deviation and Bland-Altman plots for the mean sensitivity (MS) were computed to assess test-retest variability. RESULTS: Retinal sensitivity was generally lower with CMP, with an average mean difference of 1.85+/-0.06 decibels (dB) (mean +/- standard error, P < 0.001) in healthy subjects and 1.46+/-0.05 dB (mean +/- standard error, P < 0.001) in patients with glaucoma. Both devices showed similar discriminative power. The MD metric had marginally better discrimination with CMP (pAUC difference +/- standard error, 0.019+/-0.009, P = 0.035). The 95% limits of agreement for the MS were reduced by 13% in CMP compared with HFA in participants with glaucoma and by 49% in normal participants. Mean absolute deviation was similar, with no significant differences. CONCLUSIONS: Relative diagnostic precision of the 2 devices is equivalent. Test-retest variability of MS for CMP was better than for HFA."
0,Lesional and perilesional tissue characterization by automated image processing in a novel gyrencephalic animal model of peracute intracerebral hemorrhage,"Intracerebral hemorrhage (ICH) is an important stroke subtype, but preclinical research is limited by a lack of translational animal models. Large animal models are useful to comparatively investigate key pathophysiological parameters in human ICH. To (i) establish an acute model of moderate ICH in adult sheep and (ii) an advanced neuroimage processing pipeline for automatic brain tissue and hemorrhagic lesion determination; 14 adult sheep were assigned for stereotactically induced ICH into cerebral white matter under physiological monitoring. Six hours after ICH neuroimaging using 1.5T MRI including structural as well as perfusion and diffusion, weighted imaging was performed before scarification and subsequent neuropathological investigation including immunohistological staining. Controlled, stereotactic application of autologous blood caused a space-occupying intracerebral hematoma of moderate severity, predominantly affecting white matter at 5 h post-injection. Neuroimage post-processing including lesion probability maps enabled automatic quantification of structural alterations including perilesional diffusion and perfusion restrictions. Neuropathological and immunohistological investigation confirmed perilesional vacuolation, axonal damage, and perivascular blood as seen after human ICH. The model and imaging platform reflects key aspects of human ICH and enables future translational research on hematoma expansion/evacuation, white matter changes, hematoma evacuation, and other aspects.","Lesional and perilesional tissue characterization by automated image processing in a novel gyrencephalic animal model of peracute intracerebral hemorrhage. Intracerebral hemorrhage (ICH) is an important stroke subtype, but preclinical research is limited by a lack of translational animal models. Large animal models are useful to comparatively investigate key pathophysiological parameters in human ICH. To (i) establish an acute model of moderate ICH in adult sheep and (ii) an advanced neuroimage processing pipeline for automatic brain tissue and hemorrhagic lesion determination; 14 adult sheep were assigned for stereotactically induced ICH into cerebral white matter under physiological monitoring. Six hours after ICH neuroimaging using 1.5T MRI including structural as well as perfusion and diffusion, weighted imaging was performed before scarification and subsequent neuropathological investigation including immunohistological staining. Controlled, stereotactic application of autologous blood caused a space-occupying intracerebral hematoma of moderate severity, predominantly affecting white matter at 5 h post-injection. Neuroimage post-processing including lesion probability maps enabled automatic quantification of structural alterations including perilesional diffusion and perfusion restrictions. Neuropathological and immunohistological investigation confirmed perilesional vacuolation, axonal damage, and perivascular blood as seen after human ICH. The model and imaging platform reflects key aspects of human ICH and enables future translational research on hematoma expansion/evacuation, white matter changes, hematoma evacuation, and other aspects."
0,Landscape of the Plasmodium Interactome Reveals Both Conserved and Species-Specific Functionality,"Malaria represents a major global health issue, and the identification of new intervention targets remains an urgent priority. This search is hampered by more than one-third of the genes of malaria-causing Plasmodium parasites being uncharacterized. We report a large-scale protein interaction network in Plasmodium schizonts, generated by combining blue native-polyacrylamide electrophoresis with quantitative mass spectrometry and machine learning. This integrative approach, spanning 3 species, identifies >20,000 putative protein interactions, organized into 600 protein clusters. We validate selected interactions, assigning functions in chromatin regulation to previously unannotated proteins and suggesting a role for an EELM2 domain-containing protein and a putative microrchidia protein as mechanistic links between AP2-domain transcription factors and epigenetic regulation. Our interactome represents a high-confidence map of the native organization of core cellular processes in Plasmodium parasites. The network reveals putative functions for uncharacterized proteins, provides mechanistic and structural insight, and uncovers potential alternative therapeutic targets. More than one-third of Plasmodium genes are uncharacterized functionally. Hillier et al. combine biochemical fractionation, protein correlation profiling, and machine learning to generate a protein interaction network for Plasmodium. This global cellular organization map sheds light on the function of known and uncharacterized proteins and highlights conserved and species-specific functionality.","Landscape of the Plasmodium Interactome Reveals Both Conserved and Species-Specific Functionality. Malaria represents a major global health issue, and the identification of new intervention targets remains an urgent priority. This search is hampered by more than one-third of the genes of malaria-causing Plasmodium parasites being uncharacterized. We report a large-scale protein interaction network in Plasmodium schizonts, generated by combining blue native-polyacrylamide electrophoresis with quantitative mass spectrometry and machine learning. This integrative approach, spanning 3 species, identifies >20,000 putative protein interactions, organized into 600 protein clusters. We validate selected interactions, assigning functions in chromatin regulation to previously unannotated proteins and suggesting a role for an EELM2 domain-containing protein and a putative microrchidia protein as mechanistic links between AP2-domain transcription factors and epigenetic regulation. Our interactome represents a high-confidence map of the native organization of core cellular processes in Plasmodium parasites. The network reveals putative functions for uncharacterized proteins, provides mechanistic and structural insight, and uncovers potential alternative therapeutic targets. More than one-third of Plasmodium genes are uncharacterized functionally. Hillier et al. combine biochemical fractionation, protein correlation profiling, and machine learning to generate a protein interaction network for Plasmodium. This global cellular organization map sheds light on the function of known and uncharacterized proteins and highlights conserved and species-specific functionality."
0,Investigation of deleterious effects of nsSNPs in the POT1 gene: a structural genomics-based approach to understand the mechanism of cancer development,"Protection of telomere 1 (POT1) is one of the key components of shelterin complex, implicated in maintaining the telomere homeostasis, and thus stability of the eukaryotic genome. A large number of non-synonymous single nucleotide polymorphisms (nsSNPs) in the POT1 gene have been reported to cause varieties of human diseases, including cancer. In recent years, a number of mutations in POT1 has been markedly increased, and interpreting the effect of these large numbers of mutations to understand the mechanism of associated diseases seems impossible using experimental approaches. Herein, we employ varieties of computational methods such as PROVEAN, PolyPhen-2, SIFT, PoPMuSiC, SDM2, STRUM, and MAESTRO to identify the effects of 387 nsSNPs on the structure and function of POT1 protein. We have identified about 183 nsSNPs as deleterious and termed them as â€œhigh-confidence nsSNPs.â€ Distribution of these high-confidence nsSNPs demonstrates that the mutation in oligonucleotide binding domain 1 is highly deleterious (one in every three nsSNPs), and high-confidence nsSNPs show a strong correlation with residue conservation. The structure analysis provides a detailed insights into the structural changes occurred in consequence of conserved mutations which lead to the cancer progression. This study, for the first time, offers a newer prospective on the role of POT1 mutations on the structure, function, and their relation to associated diseases.","Investigation of deleterious effects of nsSNPs in the POT1 gene: a structural genomics-based approach to understand the mechanism of cancer development. Protection of telomere 1 (POT1) is one of the key components of shelterin complex, implicated in maintaining the telomere homeostasis, and thus stability of the eukaryotic genome. A large number of non-synonymous single nucleotide polymorphisms (nsSNPs) in the POT1 gene have been reported to cause varieties of human diseases, including cancer. In recent years, a number of mutations in POT1 has been markedly increased, and interpreting the effect of these large numbers of mutations to understand the mechanism of associated diseases seems impossible using experimental approaches. Herein, we employ varieties of computational methods such as PROVEAN, PolyPhen-2, SIFT, PoPMuSiC, SDM2, STRUM, and MAESTRO to identify the effects of 387 nsSNPs on the structure and function of POT1 protein. We have identified about 183 nsSNPs as deleterious and termed them as â€œhigh-confidence nsSNPs.â€ Distribution of these high-confidence nsSNPs demonstrates that the mutation in oligonucleotide binding domain 1 is highly deleterious (one in every three nsSNPs), and high-confidence nsSNPs show a strong correlation with residue conservation. The structure analysis provides a detailed insights into the structural changes occurred in consequence of conserved mutations which lead to the cancer progression. This study, for the first time, offers a newer prospective on the role of POT1 mutations on the structure, function, and their relation to associated diseases."
0,Insight into the Neuron's Insight,,
0,A Map of Human Type 1 Diabetes Progression by Imaging Mass Cytometry,"Type 1 diabetes (T1D) results from the autoimmune destruction of insulin-producing Î² cells. A comprehensive picture of the changes during T1D development is lacking due to limited sample availability, inability to sample longitudinally, and the paucity of technologies enabling comprehensive tissue profiling. Here, we analyzed 1,581 islets from 12 human donors, including eight with T1D, using imaging mass cytometry (IMC). IMC enabled simultaneous measurement of 35 biomarkers with single-cell and spatial resolution. We performed pseudotime analysis of islets through T1D progression from snapshot data to reconstruct the evolution of Î² cell loss and insulitis. Our analyses revealed that Î² cell destruction is preceded by a Î² cell marker loss and by recruitment of cytotoxic and helper T cells. The approaches described herein demonstrate the value of IMC for improving our understanding of T1D pathogenesis, and our data lay the foundation for hypothesis generation and follow-on experiments.","A Map of Human Type 1 Diabetes Progression by Imaging Mass Cytometry. Type 1 diabetes (T1D) results from the autoimmune destruction of insulin-producing Î² cells. A comprehensive picture of the changes during T1D development is lacking due to limited sample availability, inability to sample longitudinally, and the paucity of technologies enabling comprehensive tissue profiling. Here, we analyzed 1,581 islets from 12 human donors, including eight with T1D, using imaging mass cytometry (IMC). IMC enabled simultaneous measurement of 35 biomarkers with single-cell and spatial resolution. We performed pseudotime analysis of islets through T1D progression from snapshot data to reconstruct the evolution of Î² cell loss and insulitis. Our analyses revealed that Î² cell destruction is preceded by a Î² cell marker loss and by recruitment of cytotoxic and helper T cells. The approaches described herein demonstrate the value of IMC for improving our understanding of T1D pathogenesis, and our data lay the foundation for hypothesis generation and follow-on experiments."
0,Dual-Energy CT-derived Iodine Maps: Use in Assessing Pleural Carcinomatosis,,
0,Understanding the Effects of General Anesthetics on Cortical Network Activity Using Ex Vivo Preparations,,
0,Artificial Intelligence in Health Care: A Report From the National Academy of Medicine,,
0,Using Machine Learning to Monitor Keratoconus Progression-Reply,,
0,Molecular modeling investigation of the potential mechanism for phytochemical-induced skin collagen biosynthesis by inhibition of the protein phosphatase 1 holoenzyme,"The most prominent feature of UV-induced photoaged skin is decreased type 1 procollagen. Increase of the TGF-Î²/Smad signaling through inhibition of the TÎ²RI dephosphorylation by the GADD34â€“PP1c phosphatase complex represents a promising strategy for the increase in type 1 collagen production and prevention of UV-induced skin photoaging. In this study, the molecular docking and dynamics simulations, and pharmacophore modeling method were run to investigate a possible binding site as well as binding modes between apigenin, daidzein, asiaticoside, obovatol, and astragaloside IV and PP1c. Through docking study, the possible binding site for these phytochemicals was predicted as the hydrophobic (PP1â€“substrate binding) groove. The result indicates that PP1 is the significant target of these compounds. Moreover, the 20,000-ps MD simulations present that the binding locations and modes predicted by the docking have been slightly changed considering that the MD simulations proffer more reliable details upon the proteinâ€“ligand recognition. The MM-GBSA binding free energy calculations and pharmacophore modeling rationally identify that the highly hydrophobic surfaces/pockets at close proximity of the catalytic core are the most favorable binding locations of the herbal compounds, and that some experimental facts upon a possible mechanism of increase in collagen biosynthesis can be explained. The present study theoretically offers the reliable binding target of the herbal compounds, and therefore helps to understanding the action mechanism for natural small molecules that enhance collagen production.","Molecular modeling investigation of the potential mechanism for phytochemical-induced skin collagen biosynthesis by inhibition of the protein phosphatase 1 holoenzyme. The most prominent feature of UV-induced photoaged skin is decreased type 1 procollagen. Increase of the TGF-Î²/Smad signaling through inhibition of the TÎ²RI dephosphorylation by the GADD34â€“PP1c phosphatase complex represents a promising strategy for the increase in type 1 collagen production and prevention of UV-induced skin photoaging. In this study, the molecular docking and dynamics simulations, and pharmacophore modeling method were run to investigate a possible binding site as well as binding modes between apigenin, daidzein, asiaticoside, obovatol, and astragaloside IV and PP1c. Through docking study, the possible binding site for these phytochemicals was predicted as the hydrophobic (PP1â€“substrate binding) groove. The result indicates that PP1 is the significant target of these compounds. Moreover, the 20,000-ps MD simulations present that the binding locations and modes predicted by the docking have been slightly changed considering that the MD simulations proffer more reliable details upon the proteinâ€“ligand recognition. The MM-GBSA binding free energy calculations and pharmacophore modeling rationally identify that the highly hydrophobic surfaces/pockets at close proximity of the catalytic core are the most favorable binding locations of the herbal compounds, and that some experimental facts upon a possible mechanism of increase in collagen biosynthesis can be explained. The present study theoretically offers the reliable binding target of the herbal compounds, and therefore helps to understanding the action mechanism for natural small molecules that enhance collagen production."
0,Clinical correlates of longitudinal MRI changes in CADASIL,"Previous studies showed that various types of cerebral lesions, as assessed on MRI, largely contribute to the clinical severity of CADASIL. However, the clinical impact of longitudinal changes of classical markers of small vessel disease on conventional MRI has been only poorly investigated. One hundred sixty NOTCH3 mutation carriers (mean age Â± SD, 49.8 Â± 10.9 years) were followed over three years. Validated methods were used to determine the percent brain volume change (PBVC), number of incident lacunes, change of volume of white matter hyperintensities and change of number of cerebral microbleeds. Multivariable logistic regression analyses were performed to assess the independent association between changes of these MRI markers and incident clinical events. Mixed-effect multiple linear regression analyses were used to assess their association with changes of clinical scales. Over a mean period of 3.1 Â± 0.2 years, incident lacunes are found independently associated with incident stroke and change of Trail Making Test Part B. PBVC is independently associated with all incident events and clinical scale changes except the modified Rankin Scale at three years. Our results suggest that, on conventional MRI, PBVC and the number of incident lacunes are the most sensitive and independent correlates of clinical worsening over three years in CADASIL.","Clinical correlates of longitudinal MRI changes in CADASIL. Previous studies showed that various types of cerebral lesions, as assessed on MRI, largely contribute to the clinical severity of CADASIL. However, the clinical impact of longitudinal changes of classical markers of small vessel disease on conventional MRI has been only poorly investigated. One hundred sixty NOTCH3 mutation carriers (mean age Â± SD, 49.8 Â± 10.9 years) were followed over three years. Validated methods were used to determine the percent brain volume change (PBVC), number of incident lacunes, change of volume of white matter hyperintensities and change of number of cerebral microbleeds. Multivariable logistic regression analyses were performed to assess the independent association between changes of these MRI markers and incident clinical events. Mixed-effect multiple linear regression analyses were used to assess their association with changes of clinical scales. Over a mean period of 3.1 Â± 0.2 years, incident lacunes are found independently associated with incident stroke and change of Trail Making Test Part B. PBVC is independently associated with all incident events and clinical scale changes except the modified Rankin Scale at three years. Our results suggest that, on conventional MRI, PBVC and the number of incident lacunes are the most sensitive and independent correlates of clinical worsening over three years in CADASIL."
0,Privacy-protecting estimation of adjusted risk ratios using modified Poisson regression in multi-center studies,"BACKGROUND: Multi-center studies can generate robust and generalizable evidence, but privacy considerations and legal restrictions often make it challenging or impossible to pool individual-level data across data-contributing sites. With binary outcomes, privacy-protecting distributed algorithms to conduct logistic regression analyses have been developed. However, the risk ratio often provides a more transparent interpretation of the exposure-outcome association than the odds ratio. Modified Poisson regression has been proposed to directly estimate adjusted risk ratios and produce confidence intervals with the correct nominal coverage when individual-level data are available. There are currently no distributed regression algorithms to estimate adjusted risk ratios while avoiding pooling of individual-level data in multi-center studies. METHODS: By leveraging the Newton-Raphson procedure, we adapted the modified Poisson regression method to estimate multivariable-adjusted risk ratios using only summary-level information in multi-center studies. We developed and tested the proposed method using both simulated and real-world data examples. We compared its results with the results from the corresponding pooled individual-level data analysis. RESULTS: Our proposed method produced the same adjusted risk ratio estimates and standard errors as the corresponding pooled individual-level data analysis without pooling individual-level data across data-contributing sites. CONCLUSIONS: We developed and validated a distributed modified Poisson regression algorithm for valid and privacy-protecting estimation of adjusted risk ratios and confidence intervals in multi-center studies. This method allows computation of a more interpretable measure of association for binary outcomes, along with valid construction of confidence intervals, without sharing of individual-level data.","Privacy-protecting estimation of adjusted risk ratios using modified Poisson regression in multi-center studies. BACKGROUND: Multi-center studies can generate robust and generalizable evidence, but privacy considerations and legal restrictions often make it challenging or impossible to pool individual-level data across data-contributing sites. With binary outcomes, privacy-protecting distributed algorithms to conduct logistic regression analyses have been developed. However, the risk ratio often provides a more transparent interpretation of the exposure-outcome association than the odds ratio. Modified Poisson regression has been proposed to directly estimate adjusted risk ratios and produce confidence intervals with the correct nominal coverage when individual-level data are available. There are currently no distributed regression algorithms to estimate adjusted risk ratios while avoiding pooling of individual-level data in multi-center studies. METHODS: By leveraging the Newton-Raphson procedure, we adapted the modified Poisson regression method to estimate multivariable-adjusted risk ratios using only summary-level information in multi-center studies. We developed and tested the proposed method using both simulated and real-world data examples. We compared its results with the results from the corresponding pooled individual-level data analysis. RESULTS: Our proposed method produced the same adjusted risk ratio estimates and standard errors as the corresponding pooled individual-level data analysis without pooling individual-level data across data-contributing sites. CONCLUSIONS: We developed and validated a distributed modified Poisson regression algorithm for valid and privacy-protecting estimation of adjusted risk ratios and confidence intervals in multi-center studies. This method allows computation of a more interpretable measure of association for binary outcomes, along with valid construction of confidence intervals, without sharing of individual-level data."
0,Cell Type Purification by Single-Cell Transcriptome-Trained Sorting,,
0,Anemia of inflammation,,
0,Artificial Intelligence Algorithms for Medical Prediction Should Be Nonproprietary and Readily Available,,
0,Fast and accurate bacterial species identification in urine specimens using LC-MS/MS mass spectrometry and machine learning,"Fast identification of microbial species in clinical samples is essential to provide an appropriate antibiotherapy to the patient and reduce the prescription of broad-spectrum antimicrobials leading to antibioresistances. MALDITOF- MS technology has become a tool of choice for microbial identification but has several drawbacks: It requires a long step of bacterial culture before analysis (>24 h), has a low specificity and is not quantitative. We developed a new strategy for identifying bacterial species in urine using specific LC-MS/MS peptidic signatures. In the first training step, libraries of peptides are obtained on pure bacterial colonies in DDA mode, their detection in urine is then verified in DIA mode, followed by the use of machine learning classifiers (NaiveBayes, BayesNet and Hoeffding tree) to define a peptidic signature to distinguish each bacterial species from the others. Then, in the second step, this signature is monitored in unknown urine samples using targeted proteomics. This method, allowing bacterial identification in less than 4 h, has been applied to fifteen species representing 84% of all Urinary Tract Infections. More than 31,000 peptides in 190 samples were quantified by DIA and classified by machine learning to determine an 82 peptides signature and build a prediction model. This signature was validated for its use in routine using Parallel Reaction Monitoring on two different instruments. Linearity and reproducibility of the method were demonstrated as well as its accuracy on donor specimens. Within 4h and without bacterial culture, our method was able to predict the predominant bacteria infecting a sample in 97% of cases and 100% above the standard threshold. This work demonstrates the efficiency of our method for the rapid and specific identification of the bacterial species causing UTI and could be extended in the future to other biological specimens and to bacteria having specific virulence or resistance factors.","Fast and accurate bacterial species identification in urine specimens using LC-MS/MS mass spectrometry and machine learning. Fast identification of microbial species in clinical samples is essential to provide an appropriate antibiotherapy to the patient and reduce the prescription of broad-spectrum antimicrobials leading to antibioresistances. MALDITOF- MS technology has become a tool of choice for microbial identification but has several drawbacks: It requires a long step of bacterial culture before analysis (>24 h), has a low specificity and is not quantitative. We developed a new strategy for identifying bacterial species in urine using specific LC-MS/MS peptidic signatures. In the first training step, libraries of peptides are obtained on pure bacterial colonies in DDA mode, their detection in urine is then verified in DIA mode, followed by the use of machine learning classifiers (NaiveBayes, BayesNet and Hoeffding tree) to define a peptidic signature to distinguish each bacterial species from the others. Then, in the second step, this signature is monitored in unknown urine samples using targeted proteomics. This method, allowing bacterial identification in less than 4 h, has been applied to fifteen species representing 84% of all Urinary Tract Infections. More than 31,000 peptides in 190 samples were quantified by DIA and classified by machine learning to determine an 82 peptides signature and build a prediction model. This signature was validated for its use in routine using Parallel Reaction Monitoring on two different instruments. Linearity and reproducibility of the method were demonstrated as well as its accuracy on donor specimens. Within 4h and without bacterial culture, our method was able to predict the predominant bacteria infecting a sample in 97% of cases and 100% above the standard threshold. This work demonstrates the efficiency of our method for the rapid and specific identification of the bacterial species causing UTI and could be extended in the future to other biological specimens and to bacteria having specific virulence or resistance factors."
0,In silico evidence of direct interaction between statins and Î²-amyloid,"Introduction: Aggregation of amyloid-Î² (AÎ²) peptides represents a crucial step in the pathogenesis of Alzheimer disease (AD). Compelling evidence from preclinical studies has established that statins may reduce amyloidogenesis and AÎ²-mediated neurodegeneration, supporting a potential role of statin treatment in the prevention of AD. Different statins have been shown to interfere indirectly with AÎ² production and clearance through either cholesterol-dependent or cholesterol-independent mechanisms. However, whether there may be a direct interaction between statins and AÎ² metabolism is still unclear. Materials and methods: To test the possible direct interaction between statins and AÎ², we performed an in silico study by testing the orientation of different ligands, including statins and sulindac (the standard ligand of AÎ²), in the AÎ² active site using molecular operating environment (MOE) software. Results: Docking experiments showed that all the tested statins could directly interact with AÎ² protofibrils. Among statins, pitavastatin had the strongest interaction with AÎ² (pki = 7.66), followed by atorvastatin (pk i = 7.63), rosuvastatin (pk i = 6.99), fluvastatin (pk i =6.96), pravastatin (pk i = 6.46), lovastatin (pk i = 6.37), and simvastatin (pk i = 5.90). According to the above-mentioned results, pitavastatin, atorvastatin, rosuvastatin, and fluvastatin had a stronger binding to AÎ² compared with the standard ligand sulindac (pk i = 6.62). Conclusion: This study showed a direct interaction between statins and AÎ² protofibrils, which may underlie the protective role of this widely used class of drugs against amyloidogenesis and AÎ²-mediated neurodegeneration.","In silico evidence of direct interaction between statins and Î²-amyloid. Introduction: Aggregation of amyloid-Î² (AÎ²) peptides represents a crucial step in the pathogenesis of Alzheimer disease (AD). Compelling evidence from preclinical studies has established that statins may reduce amyloidogenesis and AÎ²-mediated neurodegeneration, supporting a potential role of statin treatment in the prevention of AD. Different statins have been shown to interfere indirectly with AÎ² production and clearance through either cholesterol-dependent or cholesterol-independent mechanisms. However, whether there may be a direct interaction between statins and AÎ² metabolism is still unclear. Materials and methods: To test the possible direct interaction between statins and AÎ², we performed an in silico study by testing the orientation of different ligands, including statins and sulindac (the standard ligand of AÎ²), in the AÎ² active site using molecular operating environment (MOE) software. Results: Docking experiments showed that all the tested statins could directly interact with AÎ² protofibrils. Among statins, pitavastatin had the strongest interaction with AÎ² (pki = 7.66), followed by atorvastatin (pk i = 7.63), rosuvastatin (pk i = 6.99), fluvastatin (pk i =6.96), pravastatin (pk i = 6.46), lovastatin (pk i = 6.37), and simvastatin (pk i = 5.90). According to the above-mentioned results, pitavastatin, atorvastatin, rosuvastatin, and fluvastatin had a stronger binding to AÎ² compared with the standard ligand sulindac (pk i = 6.62). Conclusion: This study showed a direct interaction between statins and AÎ² protofibrils, which may underlie the protective role of this widely used class of drugs against amyloidogenesis and AÎ²-mediated neurodegeneration."
0,The rebirth of cad: How is modern ai different from the cad we know?,,
0,"In patients with suspected AMI and LBBB, algorithms based on ECG and troponin data were tested to rule MI in or out",,
0,"The association between antidepressant treatment and brain connectivity in two double-blind, placebo-controlled clinical trials: a treatment mechanism study",,
0,Network plasticity involved in the spread of neural activity within the rhinal cortices as revealed by voltage-sensitive dye imaging in mouse brain slices,"The rhinal cortices, such as the perirhinal cortex (PC) and the entorhinal cortex (EC), are located within the bidirectional pathway between the neocortex and the hippocampus. Physiological studies indicate that the perirhinal transmission of neocortical inputs to the EC occurs at an extremely low probability, though many anatomical studies indicated strong connections exist in the pathway. Our previous study in rat brain slices indicated that an increase in excitability in deep layers of the PC/EC border initiated the neural activity transfer from the PC to the EC. In the present study, we hypothesized that such changes in network dynamics are not incidental observations but rather due to the plastic features of the perirhinal network, which links with the EC. To confirm this idea, we analyzed the network properties of neural transmission throughout the rhinal cortices and the plastic behavior of the network by performing a single-photon wide-field optical recording technique with a voltage-sensitive dye (VSD) in mouse brain slices of the PC, the EC, and the hippocampus. The low concentration of 4-aminopyridine (4-AP; 40 Î¼M) enhanced neural activity in the PC, which eventually propagated to the EC via the deep layers of the PC/EC border. Interestingly, washout of 4-AP was unable to reverse entorhinal activation to the previous state. This change in the network property persisted for more than 1 h. This observation was not limited to the application of 4-AP. Burst stimulation to neurons in the perirhinal deep layers also induced the same change of network property. These results indicate the long-lasting modification of physiological connection between the PC and the EC, suggesting the existence of plasticity in the perirhinal-entorhinal network.","Network plasticity involved in the spread of neural activity within the rhinal cortices as revealed by voltage-sensitive dye imaging in mouse brain slices. The rhinal cortices, such as the perirhinal cortex (PC) and the entorhinal cortex (EC), are located within the bidirectional pathway between the neocortex and the hippocampus. Physiological studies indicate that the perirhinal transmission of neocortical inputs to the EC occurs at an extremely low probability, though many anatomical studies indicated strong connections exist in the pathway. Our previous study in rat brain slices indicated that an increase in excitability in deep layers of the PC/EC border initiated the neural activity transfer from the PC to the EC. In the present study, we hypothesized that such changes in network dynamics are not incidental observations but rather due to the plastic features of the perirhinal network, which links with the EC. To confirm this idea, we analyzed the network properties of neural transmission throughout the rhinal cortices and the plastic behavior of the network by performing a single-photon wide-field optical recording technique with a voltage-sensitive dye (VSD) in mouse brain slices of the PC, the EC, and the hippocampus. The low concentration of 4-aminopyridine (4-AP; 40 Î¼M) enhanced neural activity in the PC, which eventually propagated to the EC via the deep layers of the PC/EC border. Interestingly, washout of 4-AP was unable to reverse entorhinal activation to the previous state. This change in the network property persisted for more than 1 h. This observation was not limited to the application of 4-AP. Burst stimulation to neurons in the perirhinal deep layers also induced the same change of network property. These results indicate the long-lasting modification of physiological connection between the PC and the EC, suggesting the existence of plasticity in the perirhinal-entorhinal network."
0,Effect of Including Important Clinical Variables on Accuracy of the Lung Allocation Score for Cystic Fibrosis and Chronic Obstructive Pulmonary Disease,"Rationale: Clinical variables associated with shortened survival in patients with advanced-stage cystic fibrosis (CF) are not included in the lung allocation score (LAS).Objectives: To identify variables associated with wait-list and post-transplant mortality for CF lung transplant candidates using a novel database and to analyze the impact of including new CF-specific variables in the LAS system.Methods: A deterministic matching algorithm identified patients from the Scientific Registry of Transplant Recipients and the Cystic Fibrosis Foundation Patient Registry. LAS wait-list and post-transplant survival models were recalculated using CF-specific variables. This multicenter, retrospective, population-based study of all lung transplant wait-list candidates aged 12 years or older from January 1, 2011, to December 31, 2014, included 9,043 patients on the lung transplant waiting list and 6,110 lung transplant recipients between 2011 and 2014, comprising 1,020 and 677 with CF, respectively.Measurements and Main Results: Measured outcomes were changes in LAS and lung allocation rank. For CF candidates, any Burkholderia sp. (hazard ratio [HR], 2.8; 95% confidence interval [CI], 1.2-6.6), 29-42 days hospitalized (HR 2.8; CI 1.3-5.9), massive hemoptysis (HR 2.1; CI 1.1-3.9), and relative drop in FEV1 >/=30% over 12 months (HR 1.7; CI 1.0-2.8) increased wait-list mortality risk; pulmonary exacerbation time 15-28 days (1.8; 1.1-2.9) increased post-transplant mortality risk. A relative drop in FEV1 >/=10% in chronic obstructive pulmonary disease (COPD) candidates was associated with increased wait-list mortality risk (HR 2.6; CI 1.2-5.4). Variability in LAS score and rank increased in patients with CF. Priority for transplant increased for COPD candidates. Access did not change for other diagnosis groups.Conclusions: Adding CF-specific variables improved discrimination among wait-listed CF candidates and benefited COPD candidates.","Effect of Including Important Clinical Variables on Accuracy of the Lung Allocation Score for Cystic Fibrosis and Chronic Obstructive Pulmonary Disease. Rationale: Clinical variables associated with shortened survival in patients with advanced-stage cystic fibrosis (CF) are not included in the lung allocation score (LAS).Objectives: To identify variables associated with wait-list and post-transplant mortality for CF lung transplant candidates using a novel database and to analyze the impact of including new CF-specific variables in the LAS system.Methods: A deterministic matching algorithm identified patients from the Scientific Registry of Transplant Recipients and the Cystic Fibrosis Foundation Patient Registry. LAS wait-list and post-transplant survival models were recalculated using CF-specific variables. This multicenter, retrospective, population-based study of all lung transplant wait-list candidates aged 12 years or older from January 1, 2011, to December 31, 2014, included 9,043 patients on the lung transplant waiting list and 6,110 lung transplant recipients between 2011 and 2014, comprising 1,020 and 677 with CF, respectively.Measurements and Main Results: Measured outcomes were changes in LAS and lung allocation rank. For CF candidates, any Burkholderia sp. (hazard ratio [HR], 2.8; 95% confidence interval [CI], 1.2-6.6), 29-42 days hospitalized (HR 2.8; CI 1.3-5.9), massive hemoptysis (HR 2.1; CI 1.1-3.9), and relative drop in FEV1 >/=30% over 12 months (HR 1.7; CI 1.0-2.8) increased wait-list mortality risk; pulmonary exacerbation time 15-28 days (1.8; 1.1-2.9) increased post-transplant mortality risk. A relative drop in FEV1 >/=10% in chronic obstructive pulmonary disease (COPD) candidates was associated with increased wait-list mortality risk (HR 2.6; CI 1.2-5.4). Variability in LAS score and rank increased in patients with CF. Priority for transplant increased for COPD candidates. Access did not change for other diagnosis groups.Conclusions: Adding CF-specific variables improved discrimination among wait-listed CF candidates and benefited COPD candidates."
0,A guide to deep learning in healthcare,"Here we present deep-learning techniques for healthcare, centering our discussion on deep learning in computer vision, natural language processing, reinforcement learning, and generalized methods. We describe how these computational techniques can impact a few key areas of medicine and explore how to build end-to-end systems. Our discussion of computer vision focuses largely on medical imaging, and we describe the application of natural language processing to domains such as electronic health record data. Similarly, reinforcement learning is discussed in the context of robotic-assisted surgery, and generalized deep-learning methods for genomics are reviewed.","A guide to deep learning in healthcare. Here we present deep-learning techniques for healthcare, centering our discussion on deep learning in computer vision, natural language processing, reinforcement learning, and generalized methods. We describe how these computational techniques can impact a few key areas of medicine and explore how to build end-to-end systems. Our discussion of computer vision focuses largely on medical imaging, and we describe the application of natural language processing to domains such as electronic health record data. Similarly, reinforcement learning is discussed in the context of robotic-assisted surgery, and generalized deep-learning methods for genomics are reviewed."
0,Nucleoid Size Scaling and Intracellular Organization of Translation across Bacteria,"The scaling of organelles with cell size is thought to be exclusive to eukaryotes. Here, we demonstrate that similar scaling relationships hold for the bacterial nucleoid. Despite the absence of a nuclear membrane, nucleoid size strongly correlates with cell size, independent of changes in DNA amount and across various nutrient conditions. This correlation is observed in diverse bacteria, revealing a near-constant ratio between nucleoid and cell size for a given species. As in eukaryotes, the nucleocytoplasmic ratio in bacteria varies greatly among species. This spectrum of nucleocytoplasmic ratios is independent of genome size, and instead it appears linked to the average population cell size. Bacteria with different nucleocytoplasmic ratios have a cytoplasm with different biophysical properties, impacting ribosome mobility and localization. Together, our findings identify new organizational principles and biophysical features of bacterial cells, implicating the nucleocytoplasmic ratio and cell size as determinants of the intracellular organization of translation. Different bacterial species have different characteristic nucleocytoplasmic ratios, impacting the biophysical properties of the cytosol and the spatial distribution of translation machinery.","Nucleoid Size Scaling and Intracellular Organization of Translation across Bacteria. The scaling of organelles with cell size is thought to be exclusive to eukaryotes. Here, we demonstrate that similar scaling relationships hold for the bacterial nucleoid. Despite the absence of a nuclear membrane, nucleoid size strongly correlates with cell size, independent of changes in DNA amount and across various nutrient conditions. This correlation is observed in diverse bacteria, revealing a near-constant ratio between nucleoid and cell size for a given species. As in eukaryotes, the nucleocytoplasmic ratio in bacteria varies greatly among species. This spectrum of nucleocytoplasmic ratios is independent of genome size, and instead it appears linked to the average population cell size. Bacteria with different nucleocytoplasmic ratios have a cytoplasm with different biophysical properties, impacting ribosome mobility and localization. Together, our findings identify new organizational principles and biophysical features of bacterial cells, implicating the nucleocytoplasmic ratio and cell size as determinants of the intracellular organization of translation. Different bacterial species have different characteristic nucleocytoplasmic ratios, impacting the biophysical properties of the cytosol and the spatial distribution of translation machinery."
0,Innovation in Genomic Data Sharing at the NIH,,
0,Application of High-Sensitivity Troponin in Suspected Myocardial Infarction,,
0,Low plasma lysophosphatidylcholines are associated with impaired mitochondrial oxidative capacity in adults in the Baltimore Longitudinal Study of Aging,"The decrease in skeletal muscle mitochondrial oxidative capacity with age adversely affects muscle strength and physical performance. Factors that are associated with this decrease have not been well characterized. Low plasma lysophosphatidylcholines (LPC), a major class of systemic bioactive lipids, are predictive of aging phenotypes such as cognitive impairment and decline of gait speed in older adults. Therefore, we tested the hypothesis that low plasma LPC are associated with impaired skeletal muscle mitochondrial oxidative capacity. Skeletal muscle mitochondrial oxidative capacity was measured using in vivo phosphorus magnetic resonance spectroscopy (31P-MRS) in 385 participants (256 women, 129 men), aged 24â€“97Â years (mean 72.5) in the Baltimore Longitudinal Study of Aging. Postexercise recovery rate of phosphocreatine (PCr), kPCr, was used as a biomarker of mitochondrial oxidative capacity. Plasma LPC were measured using liquid chromatographyâ€“tandem mass spectrometry. Adults in the highest quartile of kPCr had higher plasma LPC 16:0 (pÂ =Â 0.04), 16:1 (pÂ =Â 0.004), 17:0 (pÂ =Â 0.01), 18:1 (pÂ =Â 0.0002), 18:2 (pÂ =Â 0.002), and 20:3 (pÂ =Â 0.0007), but not 18:0 (pÂ =Â 0.07), 20:4 (pÂ =Â 0.09) compared with those in the lower three quartiles in multivariable linear regression models adjusting for age, sex, and height. Multiple machine-learning algorithms showed an area under the receiver operating characteristic curve of 0.638 (95% confidence interval, 0.554, 0.723) comparing six LPC in adults in the lower three quartiles of kPCr with the highest quartile. Low plasma LPC are associated with impaired mitochondrial oxidative capacity in adults.","Low plasma lysophosphatidylcholines are associated with impaired mitochondrial oxidative capacity in adults in the Baltimore Longitudinal Study of Aging. The decrease in skeletal muscle mitochondrial oxidative capacity with age adversely affects muscle strength and physical performance. Factors that are associated with this decrease have not been well characterized. Low plasma lysophosphatidylcholines (LPC), a major class of systemic bioactive lipids, are predictive of aging phenotypes such as cognitive impairment and decline of gait speed in older adults. Therefore, we tested the hypothesis that low plasma LPC are associated with impaired skeletal muscle mitochondrial oxidative capacity. Skeletal muscle mitochondrial oxidative capacity was measured using in vivo phosphorus magnetic resonance spectroscopy (31P-MRS) in 385 participants (256 women, 129 men), aged 24â€“97Â years (mean 72.5) in the Baltimore Longitudinal Study of Aging. Postexercise recovery rate of phosphocreatine (PCr), kPCr, was used as a biomarker of mitochondrial oxidative capacity. Plasma LPC were measured using liquid chromatographyâ€“tandem mass spectrometry. Adults in the highest quartile of kPCr had higher plasma LPC 16:0 (pÂ =Â 0.04), 16:1 (pÂ =Â 0.004), 17:0 (pÂ =Â 0.01), 18:1 (pÂ =Â 0.0002), 18:2 (pÂ =Â 0.002), and 20:3 (pÂ =Â 0.0007), but not 18:0 (pÂ =Â 0.07), 20:4 (pÂ =Â 0.09) compared with those in the lower three quartiles in multivariable linear regression models adjusting for age, sex, and height. Multiple machine-learning algorithms showed an area under the receiver operating characteristic curve of 0.638 (95% confidence interval, 0.554, 0.723) comparing six LPC in adults in the lower three quartiles of kPCr with the highest quartile. Low plasma LPC are associated with impaired mitochondrial oxidative capacity in adults."
0,Detecting Prostate Cancer with Deep Learning for MRI: A Small Step Forward,,
0,Emerging intersections between neuroscience and glioma biology,,
0,The intrinsic attractor manifold and population dynamics of a canonical cognitive circuit across waking and sleep,"Neural circuits construct distributed representations of key variables-external stimuli or internal constructs of quantities relevant for survival, such as an estimate of one's location in the world-as vectors of population activity. Although population activity vectors may have thousands of entries (dimensions), we consider that they trace out a low-dimensional manifold whose dimension and topology match the represented variable. This manifold perspective enables blind discovery and decoding of the represented variable using only neural population activity (without knowledge of the input, output, behavior or topography). We characterize and directly visualize manifold structure in the mammalian head direction circuit, revealing that the states form a topologically nontrivial one-dimensional ring. The ring exhibits isometry and is invariant across waking and rapid eye movement sleep. This result directly demonstrates that there are continuous attractor dynamics and enables powerful inference about mechanism. Finally, external rather than internal noise limits memory fidelity, and the manifold approach reveals new dynamical trajectories during sleep.","The intrinsic attractor manifold and population dynamics of a canonical cognitive circuit across waking and sleep. Neural circuits construct distributed representations of key variables-external stimuli or internal constructs of quantities relevant for survival, such as an estimate of one's location in the world-as vectors of population activity. Although population activity vectors may have thousands of entries (dimensions), we consider that they trace out a low-dimensional manifold whose dimension and topology match the represented variable. This manifold perspective enables blind discovery and decoding of the represented variable using only neural population activity (without knowledge of the input, output, behavior or topography). We characterize and directly visualize manifold structure in the mammalian head direction circuit, revealing that the states form a topologically nontrivial one-dimensional ring. The ring exhibits isometry and is invariant across waking and rapid eye movement sleep. This result directly demonstrates that there are continuous attractor dynamics and enables powerful inference about mechanism. Finally, external rather than internal noise limits memory fidelity, and the manifold approach reveals new dynamical trajectories during sleep."
0,Matrix metalloproteinases as target genes for gene regulatory networks driving molecular and cellular pathways related to a multistep pathogenesis of cerebrovascular disease,"The present study investigated a joint contribution of matrix metalloproteinases (MMPs) genes to ischemic stroke (IS) development and analyzed interactions between MMP genes and genome-wide associated loci for IS. A total of 1288 unrelated Russians (600 IS patients and 688 healthy individuals) from Central Russia were recruited for the study. Genotyping of seven single nucleotide polymorphisms (SNPs) of MMP genes (rs1799750, rs243865, rs3025058, rs11225395, rs17576, rs486055, and rs2276109) and eight genome-wide associated loci for IS were done using Taq-Manâ€“based assays and MALDI-TOF mass spectrometry iPLEX platform, respectively. Allele âˆ’ 799T at rs11225395 of the MMP8 gene was significantly associated with a decreased risk of IS after adjustment for sex and age (OR = 0.82; 95%CI, 0.70-0.96; P = 0.016). The model-based multifactor dimensionality reduction method has revealed 21 two-order, 124 three-order, and 474 four-order gene-gene (GÃ—G) interactions models meaningfully (Pperm < 0.05) associated with the IS risk. The bioinformatic analysis enabled establishing the studied MMP gene polymorphisms possess a clear regulatory potential and may be targeted by gene regulatory networks driving molecular and cellular pathways related to the pathogenesis of IS. In conclusion, the present study was the first to identify an association between polymorphism rs11225395 of the MMP8 gene and IS risk. The study findings also indicate that MMPs deserve special attention as a potential class of genes influencing the multistep mechanisms of cerebrovascular disease including atherosclerosis in cerebral arteries, acute cerebral artery occlusion as well as the ischemic injury of the brain and its recovery.","Matrix metalloproteinases as target genes for gene regulatory networks driving molecular and cellular pathways related to a multistep pathogenesis of cerebrovascular disease. The present study investigated a joint contribution of matrix metalloproteinases (MMPs) genes to ischemic stroke (IS) development and analyzed interactions between MMP genes and genome-wide associated loci for IS. A total of 1288 unrelated Russians (600 IS patients and 688 healthy individuals) from Central Russia were recruited for the study. Genotyping of seven single nucleotide polymorphisms (SNPs) of MMP genes (rs1799750, rs243865, rs3025058, rs11225395, rs17576, rs486055, and rs2276109) and eight genome-wide associated loci for IS were done using Taq-Manâ€“based assays and MALDI-TOF mass spectrometry iPLEX platform, respectively. Allele âˆ’ 799T at rs11225395 of the MMP8 gene was significantly associated with a decreased risk of IS after adjustment for sex and age (OR = 0.82; 95%CI, 0.70-0.96; P = 0.016). The model-based multifactor dimensionality reduction method has revealed 21 two-order, 124 three-order, and 474 four-order gene-gene (GÃ—G) interactions models meaningfully (Pperm < 0.05) associated with the IS risk. The bioinformatic analysis enabled establishing the studied MMP gene polymorphisms possess a clear regulatory potential and may be targeted by gene regulatory networks driving molecular and cellular pathways related to the pathogenesis of IS. In conclusion, the present study was the first to identify an association between polymorphism rs11225395 of the MMP8 gene and IS risk. The study findings also indicate that MMPs deserve special attention as a potential class of genes influencing the multistep mechanisms of cerebrovascular disease including atherosclerosis in cerebral arteries, acute cerebral artery occlusion as well as the ischemic injury of the brain and its recovery."
0,Virtual Unenhanced Images at Dual-Energy CT: Influence on Renal Lesion Characterization,,
0,Refining the management of acute coronary and aortic syndromes,,
0,"Theaflavin-3,3Â´-digallate increases the antibacterial activity of Î²-lactam antibiotics by inhibiting metallo-Î²-lactamase activity","Metallo-Î²-lactamases (MBLs) are some of the best known Î²-lactamases produced by common Gram-positive and Gram-negative pathogens and are crucial factors in the rise of bacterial resistance against Î²-lactam antibiotics. Although many types of Î²-lactamase inhibitors have been successfully developed and used in clinical settings, no MBL inhibitors have been identified to date. Nitrocefin, checkerboard and time-kill assays were used to examine the enzyme behaviour in vitro. Molecular docking calculation, molecular dynamics simulation, calculation of the binding free energy and ligand-residue interaction decomposition were used for mechanistic research. The behaviour of the enzymes in vivo was investigated by a mouse infection experiment. We showed that theaflavin-3,3Â´-digallate (TFDG), a natural compound lacking antibacterial activities, can inhibit the hydrolysis of MBLs. In the checkerboard and time-kill assays, we observed a synergistic effect of TFDG with Î²-lactam antibiotics against methicillin-resistant Staphylococcus aureus BAA1717. Molecular dynamics simulations were used to identify the mechanism of the inhibition of MBLs by TFDG, and we observed that the hydrolysis activity of the MBLs was restricted by the binding of TFDG to Gln242 and Ser369. Furthermore, the combination of TFDG with Î²-lactam antibiotics showed effective protection in a mouse Staphylococcus aureus pneumonia model. These findings suggest that TFDG can effectively inhibit the hydrolysis activity of MBLs and enhance the antibacterial activity of Î²-lactam antibiotics against pathogens in vitro and in vivo.","Theaflavin-3,3Â´-digallate increases the antibacterial activity of Î²-lactam antibiotics by inhibiting metallo-Î²-lactamase activity. Metallo-Î²-lactamases (MBLs) are some of the best known Î²-lactamases produced by common Gram-positive and Gram-negative pathogens and are crucial factors in the rise of bacterial resistance against Î²-lactam antibiotics. Although many types of Î²-lactamase inhibitors have been successfully developed and used in clinical settings, no MBL inhibitors have been identified to date. Nitrocefin, checkerboard and time-kill assays were used to examine the enzyme behaviour in vitro. Molecular docking calculation, molecular dynamics simulation, calculation of the binding free energy and ligand-residue interaction decomposition were used for mechanistic research. The behaviour of the enzymes in vivo was investigated by a mouse infection experiment. We showed that theaflavin-3,3Â´-digallate (TFDG), a natural compound lacking antibacterial activities, can inhibit the hydrolysis of MBLs. In the checkerboard and time-kill assays, we observed a synergistic effect of TFDG with Î²-lactam antibiotics against methicillin-resistant Staphylococcus aureus BAA1717. Molecular dynamics simulations were used to identify the mechanism of the inhibition of MBLs by TFDG, and we observed that the hydrolysis activity of the MBLs was restricted by the binding of TFDG to Gln242 and Ser369. Furthermore, the combination of TFDG with Î²-lactam antibiotics showed effective protection in a mouse Staphylococcus aureus pneumonia model. These findings suggest that TFDG can effectively inhibit the hydrolysis activity of MBLs and enhance the antibacterial activity of Î²-lactam antibiotics against pathogens in vitro and in vivo."
0,A Rule-Out Strategy Based on High-Sensitivity Troponin and HEART Score Reduces Hospital Admissions,"STUDY OBJECTIVE: We evaluate whether a combination of a 1-hour high-sensitivity cardiac troponin algorithm and History, ECG, Age, Risk Factors, and Troponin (HEART) score reduces admission rate (primary outcome) and affects time to discharge, health care-related costs, and 30-day outcome (secondary outcomes) in patients with symptoms suggestive of an acute coronary syndrome. METHODS: This prospective observational multicenter study was conducted before (2013 to 2014) and after (2015 to 2016) implementation of a strategy including level of high-sensitivity cardiac troponin T or I at 0 and 1 hour, combined with the HEART score. Patients with a nonelevated baseline high-sensitivity cardiac troponin level, a 1-hour change in high-sensitivity cardiac troponin T level less than 3 ng/L, or high-sensitivity cardiac troponin I level less than 6 ng/L and a HEART score less than or equal to 3 were considered to be ruled out of having acute coronary syndrome. A logistic regression analysis was performed to adjust for differences in baseline characteristics. RESULTS: A total of 1,233 patients were included at 6 centers. There were no differences in regard to median age (64 versus 63 years) and proportion of men (57% versus 54%) between the periods. After introduction of the new strategy, the admission rate decreased from 59% to 33% (risk ratio 0.55 [95% confidence interval {CI} 0.48 to 0.63]; odds ratio 0.33 [95% CI 0.26 to 0.42]; adjusted odds ratio 0.33 [95% CI 0.25 to 0.42]). The median hospital stay was reduced from 23.2 to 4.7 hours (95% CI of difference -20.4 to -11.4); median health care-related costs, from $1,748 to $1,079 (95% CI of difference -$953 to -$391). The number of clinical events was very low. CONCLUSION: In this before-after study, clinical implementation of a 1-hour high-sensitivity cardiac troponin algorithm combined with the HEART score was associated with a reduction in admission rate and health care burden, with very low rates of adverse clinical events.","A Rule-Out Strategy Based on High-Sensitivity Troponin and HEART Score Reduces Hospital Admissions. STUDY OBJECTIVE: We evaluate whether a combination of a 1-hour high-sensitivity cardiac troponin algorithm and History, ECG, Age, Risk Factors, and Troponin (HEART) score reduces admission rate (primary outcome) and affects time to discharge, health care-related costs, and 30-day outcome (secondary outcomes) in patients with symptoms suggestive of an acute coronary syndrome. METHODS: This prospective observational multicenter study was conducted before (2013 to 2014) and after (2015 to 2016) implementation of a strategy including level of high-sensitivity cardiac troponin T or I at 0 and 1 hour, combined with the HEART score. Patients with a nonelevated baseline high-sensitivity cardiac troponin level, a 1-hour change in high-sensitivity cardiac troponin T level less than 3 ng/L, or high-sensitivity cardiac troponin I level less than 6 ng/L and a HEART score less than or equal to 3 were considered to be ruled out of having acute coronary syndrome. A logistic regression analysis was performed to adjust for differences in baseline characteristics. RESULTS: A total of 1,233 patients were included at 6 centers. There were no differences in regard to median age (64 versus 63 years) and proportion of men (57% versus 54%) between the periods. After introduction of the new strategy, the admission rate decreased from 59% to 33% (risk ratio 0.55 [95% confidence interval {CI} 0.48 to 0.63]; odds ratio 0.33 [95% CI 0.26 to 0.42]; adjusted odds ratio 0.33 [95% CI 0.25 to 0.42]). The median hospital stay was reduced from 23.2 to 4.7 hours (95% CI of difference -20.4 to -11.4); median health care-related costs, from $1,748 to $1,079 (95% CI of difference -$953 to -$391). The number of clinical events was very low. CONCLUSION: In this before-after study, clinical implementation of a 1-hour high-sensitivity cardiac troponin algorithm combined with the HEART score was associated with a reduction in admission rate and health care burden, with very low rates of adverse clinical events."
0,Diagnostic Case-Control versus Diagnostic Cohort Studies for Clinical Validation of Artificial Intelligence Algorithm Performance,,
0,An Ophthalmologist's Guide to Deciphering Studies in Artificial Intelligence,,
0,"Epidemiology, Pathophysiology, and Treatment of Diverticulitis",,
0,Clinical utility of the 2016 ASE/EACVI recommendations for the evaluation of left ventricular diastolic function in the stratification of post-discharge prognosis in patients with acute heart failure,"Aims: Left ventricular diastolic dysfunction (LVDD) has prognostic significance in heart failure (HF). We aimed to assess the impact of LVDD grade stratified by the updated 2016 echocardiographic algorithm (DD2016) on post-discharge outcomes in patients admitted for acute HF and compare with the previous 2009 algorithm (DD2009). Methods and results: The study included 481 patients hospitalized for acute decompensated HF. Comprehensive echocardiography and LVDD evaluation were performed just before hospital discharge. The primary endpoint was a composite of cardiovascular death and readmission for HF. The concordance between DD2016 and DD2009 was moderate (Îº = 0.44, P < 0.001); the reclassification rate was 39%. During the follow-up (median: 15 months), 127 (26%) patients experienced the primary endpoint. In the Kaplan-Meier analysis, Grade III in DD2016 showed a lower event-free survival rate than Grades I and II (log rank, P < 0.001 and P = 0.048, respectively) and was independently associated with a higher incidence of the primary endpoint than Grade I [hazard ratio 1.89; 95% confidence interval (CI) 1.17-3.04; P = 0.009]. Grade II or III in DD2016, reflecting elevation of left ventricular (LV) filling pressure, added an incremental predictive value of the primary endpoint to clinical variables irrespective of LV ejection fraction. DD2016 was comparable to DD2009 in predicting the endpoint (net reclassification improvement = 11%; 95% CI -7% to 30%, P = 0.23). Conclusion: Despite simplification of the algorithm for LVDD evaluation, the prognostic value of DD2016 for post-discharge cardiovascular events in HF patients was maintained and not compromised in comparison with DD2009.","Clinical utility of the 2016 ASE/EACVI recommendations for the evaluation of left ventricular diastolic function in the stratification of post-discharge prognosis in patients with acute heart failure. Aims: Left ventricular diastolic dysfunction (LVDD) has prognostic significance in heart failure (HF). We aimed to assess the impact of LVDD grade stratified by the updated 2016 echocardiographic algorithm (DD2016) on post-discharge outcomes in patients admitted for acute HF and compare with the previous 2009 algorithm (DD2009). Methods and results: The study included 481 patients hospitalized for acute decompensated HF. Comprehensive echocardiography and LVDD evaluation were performed just before hospital discharge. The primary endpoint was a composite of cardiovascular death and readmission for HF. The concordance between DD2016 and DD2009 was moderate (Îº = 0.44, P < 0.001); the reclassification rate was 39%. During the follow-up (median: 15 months), 127 (26%) patients experienced the primary endpoint. In the Kaplan-Meier analysis, Grade III in DD2016 showed a lower event-free survival rate than Grades I and II (log rank, P < 0.001 and P = 0.048, respectively) and was independently associated with a higher incidence of the primary endpoint than Grade I [hazard ratio 1.89; 95% confidence interval (CI) 1.17-3.04; P = 0.009]. Grade II or III in DD2016, reflecting elevation of left ventricular (LV) filling pressure, added an incremental predictive value of the primary endpoint to clinical variables irrespective of LV ejection fraction. DD2016 was comparable to DD2009 in predicting the endpoint (net reclassification improvement = 11%; 95% CI -7% to 30%, P = 0.23). Conclusion: Despite simplification of the algorithm for LVDD evaluation, the prognostic value of DD2016 for post-discharge cardiovascular events in HF patients was maintained and not compromised in comparison with DD2009."
0,Exploring sand fly salivary proteins to design multiepitope subunit vaccine to fight against visceral leishmaniasis,"Visceral leishmaniasis (VL) is caused by the parasites of Leishmania donovani complex, leads to the death of 20 000 to 40 000 people from 56 affected countries, worldwide. Till date, there is not a single available vaccine candidate to prevent the VL infection, and treatment only relies upon expensive and toxic chemotherapeutic options. Consequently, immunoinformatics approach was applied to design a multiepitope-based subunit vaccine to enhance the humoral as well as cell-mediated immunity. Constructed vaccine candidate was further subjected to evaluation on allergenicity and antigenicity and physiochemical parameters. Later on, disulfide engineering was performed to increase the stability of vaccine construct. Also, molecular docking and molecular dynamics simulation study were performed to check the binding affinity and stability of toll-like receptor-4 to vaccine construct complex. Finally, codon optimization and in silico cloning were performed to ensure the expression of proposed vaccine construct in a microbial expression system.","Exploring sand fly salivary proteins to design multiepitope subunit vaccine to fight against visceral leishmaniasis. Visceral leishmaniasis (VL) is caused by the parasites of Leishmania donovani complex, leads to the death of 20 000 to 40 000 people from 56 affected countries, worldwide. Till date, there is not a single available vaccine candidate to prevent the VL infection, and treatment only relies upon expensive and toxic chemotherapeutic options. Consequently, immunoinformatics approach was applied to design a multiepitope-based subunit vaccine to enhance the humoral as well as cell-mediated immunity. Constructed vaccine candidate was further subjected to evaluation on allergenicity and antigenicity and physiochemical parameters. Later on, disulfide engineering was performed to increase the stability of vaccine construct. Also, molecular docking and molecular dynamics simulation study were performed to check the binding affinity and stability of toll-like receptor-4 to vaccine construct complex. Finally, codon optimization and in silico cloning were performed to ensure the expression of proposed vaccine construct in a microbial expression system."
0,BUGSnet: an R package to facilitate the conduct and reporting of Bayesian network Meta-analyses,"BACKGROUND: Several reviews have noted shortcomings regarding the quality and reporting of network meta-analyses (NMAs). We suspect that this issue may be partially attributable to limitations in current NMA software which do not readily produce all of the output needed to satisfy current guidelines. RESULTS: To better facilitate the conduct and reporting of NMAs, we have created an R package called ""BUGSnet"" (Bayesian inference Using Gibbs Sampling to conduct a Network meta-analysis). This R package relies upon Just Another Gibbs Sampler (JAGS) to conduct Bayesian NMA using a generalized linear model. BUGSnet contains a suite of functions that can be used to describe the evidence network, estimate a model and assess the model fit and convergence, assess the presence of heterogeneity and inconsistency, and output the results in a variety of formats including league tables and surface under the cumulative rank curve (SUCRA) plots. We provide a demonstration of the functions contained within BUGSnet by recreating a Bayesian NMA found in the second technical support document composed by the National Institute for Health and Care Excellence Decision Support Unit (NICE-DSU). We have also mapped these functions to checklist items within current reporting and best practice guidelines. CONCLUSION: BUGSnet is a new R package that can be used to conduct a Bayesian NMA and produce all of the necessary output needed to satisfy current scientific and regulatory standards. We hope that this software will help to improve the conduct and reporting of NMAs.","BUGSnet: an R package to facilitate the conduct and reporting of Bayesian network Meta-analyses. BACKGROUND: Several reviews have noted shortcomings regarding the quality and reporting of network meta-analyses (NMAs). We suspect that this issue may be partially attributable to limitations in current NMA software which do not readily produce all of the output needed to satisfy current guidelines. RESULTS: To better facilitate the conduct and reporting of NMAs, we have created an R package called ""BUGSnet"" (Bayesian inference Using Gibbs Sampling to conduct a Network meta-analysis). This R package relies upon Just Another Gibbs Sampler (JAGS) to conduct Bayesian NMA using a generalized linear model. BUGSnet contains a suite of functions that can be used to describe the evidence network, estimate a model and assess the model fit and convergence, assess the presence of heterogeneity and inconsistency, and output the results in a variety of formats including league tables and surface under the cumulative rank curve (SUCRA) plots. We provide a demonstration of the functions contained within BUGSnet by recreating a Bayesian NMA found in the second technical support document composed by the National Institute for Health and Care Excellence Decision Support Unit (NICE-DSU). We have also mapped these functions to checklist items within current reporting and best practice guidelines. CONCLUSION: BUGSnet is a new R package that can be used to conduct a Bayesian NMA and produce all of the necessary output needed to satisfy current scientific and regulatory standards. We hope that this software will help to improve the conduct and reporting of NMAs."
0,Distinct mortality patterns at 0-2 days versus the remaining neonatal period: results from population-based assessment in the Indian state of Bihar,,
0,All over the place: deciphering HRAS signaling from different subcellular compartments,"RAS (rat sarcoma virus oncogene homolog) oncogenes regulate fundamental biological processes through an ever-expanding signaling network. Using interaction proteomics, phosphoproteomics, transcriptomics, and integration of these datasets with a novel biostatistics approach, we have investigated Harvey-RAS (HRAS) signaling from different subcellular sites. The results reveal highly diversified signaling networks that regulate different aspects of HRAS functions.","All over the place: deciphering HRAS signaling from different subcellular compartments. RAS (rat sarcoma virus oncogene homolog) oncogenes regulate fundamental biological processes through an ever-expanding signaling network. Using interaction proteomics, phosphoproteomics, transcriptomics, and integration of these datasets with a novel biostatistics approach, we have investigated Harvey-RAS (HRAS) signaling from different subcellular sites. The results reveal highly diversified signaling networks that regulate different aspects of HRAS functions."
0,Enhancing Atherosclerosis Regression in Diabetic Mice Through Apo AI (Apolipoprotein AI),,
0,Single-Cell Heterogeneity Analysis and CRISPR Screen Identify Key Î²-Cell-Specific Disease Genes,"Fang et al. found that Î² cells from healthy, obese, and diabetic donors have a distinct cellular heterogeneity pattern, which allows sensitive identification of disease signature genes from a small number of donors. Combined with results from a genome-wide CRISPR screen, they further annotated signature genes with insulin regulatory functions.","Single-Cell Heterogeneity Analysis and CRISPR Screen Identify Key Î²-Cell-Specific Disease Genes. Fang et al. found that Î² cells from healthy, obese, and diabetic donors have a distinct cellular heterogeneity pattern, which allows sensitive identification of disease signature genes from a small number of donors. Combined with results from a genome-wide CRISPR screen, they further annotated signature genes with insulin regulatory functions."
0,"Discovery of N-phenyl-(2,4-dihydroxypyrimidine-5-sulfonamido) phenylurea-based thymidylate synthase (TS) inhibitor as a novel multi-effects antitumor drugs with minimal toxicity","Thymidylate synthase (TS) is a hot target for tumor chemotherapy, and its inhibitors are an essential direction for anti-tumor drug research. To our knowledge, currently, there are no reported thymidylate synthase inhibitors that could inhibit cancer cell migration. Therefore, for optimal therapeutic purposes, combines our previous reports and findings, we hope to obtain a multi-effects inhibitor. This study according to the principle of flattening we designed and synthesized 18 of N-phenyl-(2,4-dihydroxypyrimidine-5-sulfonamido)phenyl urea derivatives as multi-effects inhibitors. The biological evaluation results showed that target compounds could significantly inhibit the hTS enzyme, BRaf kinase and EGFR kinase activity in vitro, and most of the compounds had excellent anti-cell viability for six cancer cell lines. Notably, the candidate compound L14e (IC50 = 0.67 Î¼M) had the superior anti-cell viability and safety to A549 and H460 cells compared with pemetrexed. Further studies had shown that L14e could cause G1/S phase arrest then induce intrinsic apoptosis. Transwell, western blot, and tube formation results proved that L14e could inhibit the activation of the EGFR signaling pathway, then ultimately achieve the purpose of inhibiting cancer cell migration and angiogenesis in cancer tissues. Furthermore, in vivo pharmacology evaluations of L14e showed significant antitumor activity in A549 cells xenografts with minimal toxicity. All of these results demonstrated that the L14e has the potential for drug discovery as a multi-effects inhibitor and provides a new reference for clinical treatment of non-small cell lung cancer.","Discovery of N-phenyl-(2,4-dihydroxypyrimidine-5-sulfonamido) phenylurea-based thymidylate synthase (TS) inhibitor as a novel multi-effects antitumor drugs with minimal toxicity. Thymidylate synthase (TS) is a hot target for tumor chemotherapy, and its inhibitors are an essential direction for anti-tumor drug research. To our knowledge, currently, there are no reported thymidylate synthase inhibitors that could inhibit cancer cell migration. Therefore, for optimal therapeutic purposes, combines our previous reports and findings, we hope to obtain a multi-effects inhibitor. This study according to the principle of flattening we designed and synthesized 18 of N-phenyl-(2,4-dihydroxypyrimidine-5-sulfonamido)phenyl urea derivatives as multi-effects inhibitors. The biological evaluation results showed that target compounds could significantly inhibit the hTS enzyme, BRaf kinase and EGFR kinase activity in vitro, and most of the compounds had excellent anti-cell viability for six cancer cell lines. Notably, the candidate compound L14e (IC50 = 0.67 Î¼M) had the superior anti-cell viability and safety to A549 and H460 cells compared with pemetrexed. Further studies had shown that L14e could cause G1/S phase arrest then induce intrinsic apoptosis. Transwell, western blot, and tube formation results proved that L14e could inhibit the activation of the EGFR signaling pathway, then ultimately achieve the purpose of inhibiting cancer cell migration and angiogenesis in cancer tissues. Furthermore, in vivo pharmacology evaluations of L14e showed significant antitumor activity in A549 cells xenografts with minimal toxicity. All of these results demonstrated that the L14e has the potential for drug discovery as a multi-effects inhibitor and provides a new reference for clinical treatment of non-small cell lung cancer."
0,A review of head and neck cancer staging system in the TNM classification of malignant tumors (eighth edition),"A number of major modifications were made to the classification of head and neck carcinomas in the eighth edition of the American Joint Committee on Cancer, Cancer Staging Manual and Union for International Cancer Control TNM classification of Malignant Tumors. These modifications were aimed at improving the prognosis prediction accuracy of the system. In this article, we review the new edition of the TNM classification system. Among the several changes in the new system, a separate algorithm for p16-positive oropharyngeal carcinoma was included, as were new chapters on â€˜Head and Neck Skin Carcinomaâ€™ and â€˜Unknown Primary Carcinomaâ€”Cervical Nodes.â€™ Changes to Tumor (T) classification were made by introducing the depth of invasion of oral carcinoma, whereas changes to Node (N) classification were made by adding extra-nodal extension. It is believed that these changes will help improve the accuracy of the system in the prediction of prognosis. However, it is necessary to verify their validity through further clinical research.","A review of head and neck cancer staging system in the TNM classification of malignant tumors (eighth edition). A number of major modifications were made to the classification of head and neck carcinomas in the eighth edition of the American Joint Committee on Cancer, Cancer Staging Manual and Union for International Cancer Control TNM classification of Malignant Tumors. These modifications were aimed at improving the prognosis prediction accuracy of the system. In this article, we review the new edition of the TNM classification system. Among the several changes in the new system, a separate algorithm for p16-positive oropharyngeal carcinoma was included, as were new chapters on â€˜Head and Neck Skin Carcinomaâ€™ and â€˜Unknown Primary Carcinomaâ€”Cervical Nodes.â€™ Changes to Tumor (T) classification were made by introducing the depth of invasion of oral carcinoma, whereas changes to Node (N) classification were made by adding extra-nodal extension. It is believed that these changes will help improve the accuracy of the system in the prediction of prognosis. However, it is necessary to verify their validity through further clinical research."
0,The Moral Standings of Artificial Intelligence and A Relational Approach,,
0,Marking the Path Toward Artificial Intelligence-Based Image Classification in Dermatology,,
0,"Adaptive platform trials: definition, design, conduct and reporting considerations",,
0,Structural insights of resveratrol with its binding partners in the toll-like receptor 4 pathway,"The benefits associated with resveratrol (Resv; 3,4â€²,5-trihydroxy-trans-stilbene) are known for a long time. The therapeutic properties of Resv are observed in diseases like cancer, neurological disorders, atherosclerosis, aging, inflammation, etc. Multiple studies suggest that the beneficial properties of Resv are due to its binding to targets in multiple pathways. The same has been reflected in inflammation, where Resv has been shown to inhibit nuclear factor Îº light-chain enhancer of activated B cells in the toll-like receptor 4 (TLR4) pathway. There are multiple cellular targets which bind to Resv, however the mode and the key interactions involved remain elusive for many of them. In the current work, we have investigated the structural insights of Resv with three of its binding partners involved in the inflammatory TLR4 signaling pathway. Through a structure-based modelling and molecular dynamics study, we have unraveled the molecular and atomic interactions involved in the Resv-binary complexes of inhibitor of ÎºB kinase, cyclooxygeanse-2, and tank-binding kinase I, all three of which are key players in TLR4 inflammatory signaling. This study is the latest addition to the investigations of the structural partners of Resv and its molecular interactions.","Structural insights of resveratrol with its binding partners in the toll-like receptor 4 pathway. The benefits associated with resveratrol (Resv; 3,4â€²,5-trihydroxy-trans-stilbene) are known for a long time. The therapeutic properties of Resv are observed in diseases like cancer, neurological disorders, atherosclerosis, aging, inflammation, etc. Multiple studies suggest that the beneficial properties of Resv are due to its binding to targets in multiple pathways. The same has been reflected in inflammation, where Resv has been shown to inhibit nuclear factor Îº light-chain enhancer of activated B cells in the toll-like receptor 4 (TLR4) pathway. There are multiple cellular targets which bind to Resv, however the mode and the key interactions involved remain elusive for many of them. In the current work, we have investigated the structural insights of Resv with three of its binding partners involved in the inflammatory TLR4 signaling pathway. Through a structure-based modelling and molecular dynamics study, we have unraveled the molecular and atomic interactions involved in the Resv-binary complexes of inhibitor of ÎºB kinase, cyclooxygeanse-2, and tank-binding kinase I, all three of which are key players in TLR4 inflammatory signaling. This study is the latest addition to the investigations of the structural partners of Resv and its molecular interactions."
0,"In vitro cell migration, invasion, and adhesion assays: From cell imaging to data analysis","Cell migration is a key procedure involved in many biological processes including embryological development, tissue formation, immune defense or inflammation, and cancer progression. How physical, chemical, and molecular aspects can affect cell motility is a challenge to understand migratory cells behavior. In vitro assays are excellent approaches to extrapolate to in vivo situations and study live cells behavior. Here we present four in vitro protocols that describe step-by-step cell migration, invasion and adhesion strategies and their corresponding image data quantification. These current protocols are based on two-dimensional wound healing assays (comparing traditional pipette tip-scratch assay vs. culture insert assay), 2D individual cell-tracking experiments by live cell imaging and three-dimensional spreading and transwell assays. All together, they cover different phenotypes and hallmarks of cell motility and adhesion, providing orthogonal information that can be used either individually or collectively in many different experimental setups. These optimized protocols will facilitate physiological and cellular characterization of these processes, which may be used for fast screening of specific therapeutic cancer drugs for migratory function, novel strategies in cancer diagnosis, and for assaying new molecules involved in adhesion and invasion metastatic properties of cancer cells.","In vitro cell migration, invasion, and adhesion assays: From cell imaging to data analysis. Cell migration is a key procedure involved in many biological processes including embryological development, tissue formation, immune defense or inflammation, and cancer progression. How physical, chemical, and molecular aspects can affect cell motility is a challenge to understand migratory cells behavior. In vitro assays are excellent approaches to extrapolate to in vivo situations and study live cells behavior. Here we present four in vitro protocols that describe step-by-step cell migration, invasion and adhesion strategies and their corresponding image data quantification. These current protocols are based on two-dimensional wound healing assays (comparing traditional pipette tip-scratch assay vs. culture insert assay), 2D individual cell-tracking experiments by live cell imaging and three-dimensional spreading and transwell assays. All together, they cover different phenotypes and hallmarks of cell motility and adhesion, providing orthogonal information that can be used either individually or collectively in many different experimental setups. These optimized protocols will facilitate physiological and cellular characterization of these processes, which may be used for fast screening of specific therapeutic cancer drugs for migratory function, novel strategies in cancer diagnosis, and for assaying new molecules involved in adhesion and invasion metastatic properties of cancer cells."
0,The unfolded protein response modulators GSK2606414 and KIRA6 are potent KIT inhibitors,"IRE1, PERK, and ATF6 are the three transducers of the mammalian canonical unfolded protein response (UPR). GSK2606414 is a potent inhibitor of PERK, while KIRA6 inhibits the kinase activity of IRE1. Both molecules are frequently used to probe the biological roles of the UPR in mammalian cells. In a direct binding assay, GSK2606414 bound to the cytoplasmic domain of KIT with dissociation constants (Kd) value of 664 Â± 294 nM whereas KIRA6 showed a Kd value of 10.8 Â± 2.9 ÂµM. In silico docking studies confirmed a compact interaction of GSK2606414 and KIRA6 with KIT ATP binding pocket. In cultured cells, GSK2606414 inhibited KIT tyrosine kinase activity at nanomolar concentrations and in a PERK-independent manner. Moreover, in contrast to other KIT inhibitors, GSK2606414 enhanced KIT endocytosis and its lysosomal degradation. Although KIRA6 also inhibited KIT at nanomolar concentrations, it did not prompt KIT degradation, and rescued KIT from GSK2606414-mediated degradation. Consistent with KIT inhibition, nanomolar concentrations of GSK2606414 and KIRA6 were sufficient to induce cell death in a KIT signaling-dependent mast cell leukemia cell line. Our data show for the first time that KIT is a shared target for two seemingly unrelated UPR inhibitors at concentrations that overlap with PERK and IRE1 inhibition. Furthermore, these data underscore discrepancies between in vitro binding measurements of kinase inhibitors and inhibition of the tyrosine kinase receptors in living cells.","The unfolded protein response modulators GSK2606414 and KIRA6 are potent KIT inhibitors. IRE1, PERK, and ATF6 are the three transducers of the mammalian canonical unfolded protein response (UPR). GSK2606414 is a potent inhibitor of PERK, while KIRA6 inhibits the kinase activity of IRE1. Both molecules are frequently used to probe the biological roles of the UPR in mammalian cells. In a direct binding assay, GSK2606414 bound to the cytoplasmic domain of KIT with dissociation constants (Kd) value of 664 Â± 294 nM whereas KIRA6 showed a Kd value of 10.8 Â± 2.9 ÂµM. In silico docking studies confirmed a compact interaction of GSK2606414 and KIRA6 with KIT ATP binding pocket. In cultured cells, GSK2606414 inhibited KIT tyrosine kinase activity at nanomolar concentrations and in a PERK-independent manner. Moreover, in contrast to other KIT inhibitors, GSK2606414 enhanced KIT endocytosis and its lysosomal degradation. Although KIRA6 also inhibited KIT at nanomolar concentrations, it did not prompt KIT degradation, and rescued KIT from GSK2606414-mediated degradation. Consistent with KIT inhibition, nanomolar concentrations of GSK2606414 and KIRA6 were sufficient to induce cell death in a KIT signaling-dependent mast cell leukemia cell line. Our data show for the first time that KIT is a shared target for two seemingly unrelated UPR inhibitors at concentrations that overlap with PERK and IRE1 inhibition. Furthermore, these data underscore discrepancies between in vitro binding measurements of kinase inhibitors and inhibition of the tyrosine kinase receptors in living cells."
0,Neurodegeneration of the Substantia Nigra after Ipsilateral Infarct: MRI R2*Mapping and Relationship to Clinical Outcome,,
0,"The role of implantable cardioverter-defibrillators and sudden cardiac death prevention: indications, device selection, and outcome",,
0,Identifying Epistasis in Cancer Genomes: A Delicate Affair,"Recent studies of the tumor genome seek to identify cancer pathways as groups of genes in which mutations are epistatic with one another or, specifically, ""mutually exclusive."" Here, we show that most mutations are mutually exclusive not due to pathway structure but to interactions with disease subtype and tumor mutation load. In particular, many cancer driver genes are mutated preferentially in tumors with few mutations overall, causing mutations in these cancer genes to appear mutually exclusive with numerous others. Researchers should view current epistasis maps with caution until we better understand the multiple cause-and-effect relationships among factors such as tumor subtype, positive selection for mutations, and gross tumor characteristics including mutational signatures and load.","Identifying Epistasis in Cancer Genomes: A Delicate Affair. Recent studies of the tumor genome seek to identify cancer pathways as groups of genes in which mutations are epistatic with one another or, specifically, ""mutually exclusive."" Here, we show that most mutations are mutually exclusive not due to pathway structure but to interactions with disease subtype and tumor mutation load. In particular, many cancer driver genes are mutated preferentially in tumors with few mutations overall, causing mutations in these cancer genes to appear mutually exclusive with numerous others. Researchers should view current epistasis maps with caution until we better understand the multiple cause-and-effect relationships among factors such as tumor subtype, positive selection for mutations, and gross tumor characteristics including mutational signatures and load."
0,Added value of aortic pulse wave velocity index for the detection of coronary heart disease by elective coronary angiography,"Background: Non-invasive tests leading to elective coronary angiography (CAG) have low diagnostic yield for obstructive coronary heart disease (CHD). Aortic stiffness, an independent predictor of CHD events can be easily measured by pulse wave velocity (PWV). We aimed at retrospectively evaluating the diagnostic accuracy PWV index to detect CHD in consecutive patients with suspected CHD that underwent CAG. Method: In population of 86 healthy patients with available PWV data, a theoretical PWV was derived. In different population of 62 individuals who underwent CAG for suspected CHD, PWV index was calculated as index [(measured PWVâ€“theoretical PWV)/theoretical PWV]. Logistic regression and comparisons between ROC curves were used to add value of CAG indication performance of PWV index. Results: Out of 62, seventeen patients presented obstructive CHD and 22 patients had non-obstructive CHD. PWV index and severity of CHD were positively correlated (p < 0.0001). After applying several models that included classical CHD predictor, the higher performance to detect abnormal CAG was obtained with the combined classifier PWV index/carotid plaque with 87% sensitivity, 93% specificity, 0.92 accuracy and 0.31 threshold. To detect obstructive CAG, individual classifier PWV index presents 94% sensitivity, 91% specificity, 0.95 accuracy and 0.46 threshold. Conclusion: PWV index is individualized approach that optimizes CHD diagnostic strategies and thus might be clinically useful for reducing the rate of unnecessary invasive CAG.","Added value of aortic pulse wave velocity index for the detection of coronary heart disease by elective coronary angiography. Background: Non-invasive tests leading to elective coronary angiography (CAG) have low diagnostic yield for obstructive coronary heart disease (CHD). Aortic stiffness, an independent predictor of CHD events can be easily measured by pulse wave velocity (PWV). We aimed at retrospectively evaluating the diagnostic accuracy PWV index to detect CHD in consecutive patients with suspected CHD that underwent CAG. Method: In population of 86 healthy patients with available PWV data, a theoretical PWV was derived. In different population of 62 individuals who underwent CAG for suspected CHD, PWV index was calculated as index [(measured PWVâ€“theoretical PWV)/theoretical PWV]. Logistic regression and comparisons between ROC curves were used to add value of CAG indication performance of PWV index. Results: Out of 62, seventeen patients presented obstructive CHD and 22 patients had non-obstructive CHD. PWV index and severity of CHD were positively correlated (p < 0.0001). After applying several models that included classical CHD predictor, the higher performance to detect abnormal CAG was obtained with the combined classifier PWV index/carotid plaque with 87% sensitivity, 93% specificity, 0.92 accuracy and 0.31 threshold. To detect obstructive CAG, individual classifier PWV index presents 94% sensitivity, 91% specificity, 0.95 accuracy and 0.46 threshold. Conclusion: PWV index is individualized approach that optimizes CHD diagnostic strategies and thus might be clinically useful for reducing the rate of unnecessary invasive CAG."
0,Treatment of Nonmetastatic Breast Cancer,,
0,Making Machine Learning Models Clinically Useful,,
0,Pharmacotherapeutics and molecular mechanism of phytochemicals in alleviating hormone-responsive breast cancer,"Breast cancer (BC) is the leading cause of death among women worldwide devoid of effective treatment. It is therefore important to develop agents that can reverse, reduce, or slow the growth of BC. The use of natural products as chemopreventive agents provides enormous advantages. The aim of the current investigation is to determine the efficacy of the phytochemicals against BC along with the approved drugs to screen the most desirable and effective phytocompound. In the current study, 36 phytochemicals have been evaluated against aromatase to identify the potential candidate drug along with the approved drugs employing the Cdocker module accessible on the Discovery Studio (DS) v4.5 and thereafter analysing the stability of the protein ligand complex using GROningen MAchine for Chemical Simulations v5.0.6 (GROMACS). Additionally, these compounds were assessed for the inhibitory features employing the structure-based pharmacophore (SBP). The Cdocker protocol available with the DS has computed higher dock scores for the phytochemicals complemented by lower binding energies. The top-ranked compounds that have anchored with key residues located at the binding pocket of the protein were subjected to molecular dynamics (MD) simulations employing GROMACS. The resultant findings reveal the stability of the protein backbone and further guide to comprehend on the involvement of key residues Phe134, Val370, and Met374 that mechanistically inhibit BC. Among 36 compounds, curcumin, capsaicin, rosmarinic acid, and 6-shogaol have emerged as promising phytochemicals conferred with the highest Cdocker interaction energy, key residue interactions, stable MD results than reference drugs, and imbibing the key inhibitory features. Taken together, the current study illuminates the use of natural compounds as potential drugs against BC. Additionally, these compounds could also serve as scaffolds in designing and development of new drugs.","Pharmacotherapeutics and molecular mechanism of phytochemicals in alleviating hormone-responsive breast cancer. Breast cancer (BC) is the leading cause of death among women worldwide devoid of effective treatment. It is therefore important to develop agents that can reverse, reduce, or slow the growth of BC. The use of natural products as chemopreventive agents provides enormous advantages. The aim of the current investigation is to determine the efficacy of the phytochemicals against BC along with the approved drugs to screen the most desirable and effective phytocompound. In the current study, 36 phytochemicals have been evaluated against aromatase to identify the potential candidate drug along with the approved drugs employing the Cdocker module accessible on the Discovery Studio (DS) v4.5 and thereafter analysing the stability of the protein ligand complex using GROningen MAchine for Chemical Simulations v5.0.6 (GROMACS). Additionally, these compounds were assessed for the inhibitory features employing the structure-based pharmacophore (SBP). The Cdocker protocol available with the DS has computed higher dock scores for the phytochemicals complemented by lower binding energies. The top-ranked compounds that have anchored with key residues located at the binding pocket of the protein were subjected to molecular dynamics (MD) simulations employing GROMACS. The resultant findings reveal the stability of the protein backbone and further guide to comprehend on the involvement of key residues Phe134, Val370, and Met374 that mechanistically inhibit BC. Among 36 compounds, curcumin, capsaicin, rosmarinic acid, and 6-shogaol have emerged as promising phytochemicals conferred with the highest Cdocker interaction energy, key residue interactions, stable MD results than reference drugs, and imbibing the key inhibitory features. Taken together, the current study illuminates the use of natural compounds as potential drugs against BC. Additionally, these compounds could also serve as scaffolds in designing and development of new drugs."
0,Can skin cancer diagnosis be transformed by AI?,,
0,Minimally Invasive Approach for Diagnosing TMJ Osteoarthritis,,
0,Interim Results from the IMPACT Study: Evidence for Prostate-specific Antigen Screening in BRCA2 Mutation Carriers,,
0,"Potential Excessive Testing at Scale: Biomarkers, Genomics, and Machine Learning",,
0,Challenges in the diagnosis of paediatric pneumonia in intervention field trials: recommendations from a pneumonia field trial working group,,
0,"Comment on ""What Expert Surgeons Never Tell You About Robot-assisted Surgery for Rectal Cancer?""",,
0,The Chylomicronemia Syndrome Is Most Often Multifactorial: A Narrative Review of Causes and Treatment,"The chylomicronemia syndrome occurs when triglyceride levels are severely elevated (usually >16.95 mmol/L [1500 mg/dL]) and is characterized by such clinical features as abdominal pain, acute pancreatitis, eruptive xanthomas, and lipemia retinalis. It may result from 1 of 3 conditions: the presence of secondary forms of hypertriglyceridemia concurrent with genetic causes of hypertriglyceridemia, termed multifactorial chylomicronemia syndrome (MFCS); a deficiency in the enzyme lipoprotein lipase and some associated proteins, termed familial chylomicronemia syndrome (FCS); or familial partial lipodystrophy. Most chylomicronemia syndrome cases are the result of MFCS; FCS is very rare. In all these conditions, triglyceride-rich lipoproteins accumulate because of impaired plasma clearance. This review describes the 3 major causes of the chylomicronemia syndrome; their consequences; and the approaches to treatment, which differ considerably by group.","The Chylomicronemia Syndrome Is Most Often Multifactorial: A Narrative Review of Causes and Treatment. The chylomicronemia syndrome occurs when triglyceride levels are severely elevated (usually >16.95 mmol/L [1500 mg/dL]) and is characterized by such clinical features as abdominal pain, acute pancreatitis, eruptive xanthomas, and lipemia retinalis. It may result from 1 of 3 conditions: the presence of secondary forms of hypertriglyceridemia concurrent with genetic causes of hypertriglyceridemia, termed multifactorial chylomicronemia syndrome (MFCS); a deficiency in the enzyme lipoprotein lipase and some associated proteins, termed familial chylomicronemia syndrome (FCS); or familial partial lipodystrophy. Most chylomicronemia syndrome cases are the result of MFCS; FCS is very rare. In all these conditions, triglyceride-rich lipoproteins accumulate because of impaired plasma clearance. This review describes the 3 major causes of the chylomicronemia syndrome; their consequences; and the approaches to treatment, which differ considerably by group."
0,Effect of Selepressin vs Placebo on Ventilator- and Vasopressor-Free Days in Patients With Septic Shock: The SEPSIS-ACT Randomized Clinical Trial,,
0,MiRNA-disease interaction prediction based on kernel neighborhood similarity and multi-network bidirectional propagation,"Background: Studies have shown that miRNAs are functionally associated with the development of many human diseases, but the roles of miRNAs in diseases and their underlying molecular mechanisms have not been fully understood. The research on miRNA-disease interaction has received more and more attention. Compared with the complexity and high cost of biological experiments, computational methods can rapidly and efficiently predict the potential miRNA-disease interaction and can be used as a beneficial supplement to experimental methods. Results: In this paper, we proposed a novel computational model of kernel neighborhood similarity and multi-network bidirectional propagation (KNMBP) for miRNA-disease interaction prediction, especially for new miRNAs and new diseases. First, we integrated multiple data sources of diseases and miRNAs, respectively, to construct a novel disease semantic similarity network and miRNA functional similarity network. Secondly, based on the modified miRNA-disease interactions, we use the kernel neighborhood similarity algorithm to calculate the disease kernel neighborhood similarity and the miRNA kernel neighborhood similarity. Finally, we utilize bidirectional propagation algorithm to predict the miRNA-disease interaction scores based on the integrated disease similarity network and miRNA similarity network. As a result, the AUC value of 5-fold cross validation for all interactions by KNMBP is 0.93126 based on the commonly used dataset, and the AUC values for all interactions, for all miRNAs, for all disease is 0.937950.863630.86937 based on another dataset extracted by ourselves, which are higher than other state-of-the-art methods. In addition, our model has good parameter robustness. The case study further demonstrated the predictive performance of the model for novel miRNA-disease interactions. Conclusions: Our KNMBP algorithm efficiently integrates multiple omics data from miRNAs and diseases to stably and efficiently predict potential miRNA-disease interactions. It is anticipated that KNMBP would be a useful tool in biomedical research.","MiRNA-disease interaction prediction based on kernel neighborhood similarity and multi-network bidirectional propagation. Background: Studies have shown that miRNAs are functionally associated with the development of many human diseases, but the roles of miRNAs in diseases and their underlying molecular mechanisms have not been fully understood. The research on miRNA-disease interaction has received more and more attention. Compared with the complexity and high cost of biological experiments, computational methods can rapidly and efficiently predict the potential miRNA-disease interaction and can be used as a beneficial supplement to experimental methods. Results: In this paper, we proposed a novel computational model of kernel neighborhood similarity and multi-network bidirectional propagation (KNMBP) for miRNA-disease interaction prediction, especially for new miRNAs and new diseases. First, we integrated multiple data sources of diseases and miRNAs, respectively, to construct a novel disease semantic similarity network and miRNA functional similarity network. Secondly, based on the modified miRNA-disease interactions, we use the kernel neighborhood similarity algorithm to calculate the disease kernel neighborhood similarity and the miRNA kernel neighborhood similarity. Finally, we utilize bidirectional propagation algorithm to predict the miRNA-disease interaction scores based on the integrated disease similarity network and miRNA similarity network. As a result, the AUC value of 5-fold cross validation for all interactions by KNMBP is 0.93126 based on the commonly used dataset, and the AUC values for all interactions, for all miRNAs, for all disease is 0.937950.863630.86937 based on another dataset extracted by ourselves, which are higher than other state-of-the-art methods. In addition, our model has good parameter robustness. The case study further demonstrated the predictive performance of the model for novel miRNA-disease interactions. Conclusions: Our KNMBP algorithm efficiently integrates multiple omics data from miRNAs and diseases to stably and efficiently predict potential miRNA-disease interactions. It is anticipated that KNMBP would be a useful tool in biomedical research."
0,Brain-machine interaction improves mobility,,
0,Abnormal Spontaneous Regional Brain Activity in Young Patients With Anorexia Nervosa Abnormal Spontaneous Regional Brain Activity in Young Patients With Anorexia Nervosa,,
0,Curcumin Blocks Cytotoxicity of Enteroaggregative and Enteropathogenic Escherichia coli by Blocking Pet and EspC Proteolytic Release From Bacterial Outer Membrane,"Pet and EspC are toxins secreted by enteroaggregative (EAEC) and enteropathogenic (EPEC) diarrheagenic Escherichia coli pathotypes, respectively. Both toxins are members of the Serine Protease Autotransporters of Enterobacteriaceae (SPATEs) family. Pet and EspC are important virulence factors that produce cytotoxic and enterotoxic effects on enterocytes. Here, we evaluated the effect of curcumin, a polyphenolic compound obtained from the rhizomes of Curcuma longa L. (Zingiberaceae) on the secretion and cytotoxic effects of Pet and EspC proteins. We found that curcumin prevents Pet and EspC secretion without affecting bacterial growth or the expression of pet and espC. Our results show that curcumin affects the release of these SPATEs from the translocation domain, thereby affecting the pathogenesis of EAEC and EPEC. Curcumin-treated EAEC and EPEC did not induce significant cell damage like the ability to disrupt the actin cytoskeleton, without affecting their characteristic adherence patterns on epithelial cells. A molecular model of docking predicted that curcumin interacts with the determinant residues Asp1018-Asp1019 and Asp1029-Asp1030 of the translocation domain required for the release of Pet and EspC, respectively. Consequently, curcumin blocks Pet and EspC cytotoxicity on epithelial cells by preventing their release from the outer membrane.","Curcumin Blocks Cytotoxicity of Enteroaggregative and Enteropathogenic Escherichia coli by Blocking Pet and EspC Proteolytic Release From Bacterial Outer Membrane. Pet and EspC are toxins secreted by enteroaggregative (EAEC) and enteropathogenic (EPEC) diarrheagenic Escherichia coli pathotypes, respectively. Both toxins are members of the Serine Protease Autotransporters of Enterobacteriaceae (SPATEs) family. Pet and EspC are important virulence factors that produce cytotoxic and enterotoxic effects on enterocytes. Here, we evaluated the effect of curcumin, a polyphenolic compound obtained from the rhizomes of Curcuma longa L. (Zingiberaceae) on the secretion and cytotoxic effects of Pet and EspC proteins. We found that curcumin prevents Pet and EspC secretion without affecting bacterial growth or the expression of pet and espC. Our results show that curcumin affects the release of these SPATEs from the translocation domain, thereby affecting the pathogenesis of EAEC and EPEC. Curcumin-treated EAEC and EPEC did not induce significant cell damage like the ability to disrupt the actin cytoskeleton, without affecting their characteristic adherence patterns on epithelial cells. A molecular model of docking predicted that curcumin interacts with the determinant residues Asp1018-Asp1019 and Asp1029-Asp1030 of the translocation domain required for the release of Pet and EspC, respectively. Consequently, curcumin blocks Pet and EspC cytotoxicity on epithelial cells by preventing their release from the outer membrane."
0,NeoMutate: An ensemble machine learning framework for the prediction of somatic mutations in cancer,"Background: The accurate screening of tumor genomic landscapes for somatic mutations using high-throughput sequencing involves a crucial step in precise clinical diagnosis and targeted therapy. However, the complex inherent features of cancer tissue, especially, tumor genetic intra-heterogeneity coupled with the problem of sequencing and alignment artifacts, makes somatic variant calling a challenging task. Current variant filtering strategies, such as rule-based filtering and consensus voting of different algorithms, have previously helped to increase specificity, although comes at the cost of sensitivity. Methods: In light of this, we have developed the NeoMutate framework which incorporates 7 supervised machine learning (ML) algorithms to exploit the strengths of multiple variant callers, using a non-redundant set of biological and sequence features. We benchmarked NeoMutate by simulating more than 10,000 bona fide cancer-related mutations into three well-characterized Genome in a Bottle (GIAB) reference samples. Results: A robust and exhaustive evaluation of NeoMutate's performance based on 5-fold cross validation experiments, in addition to 3 independent tests, demonstrated a substantially improved variant detection accuracy compared to any of its individual composite variant callers and consensus calling of multiple tools. Conclusions: We show here that integrating multiple tools in an ensemble ML layer optimizes somatic variant detection rates, leading to a potentially improved variant selection framework for the diagnosis and treatment of cancer.","NeoMutate: An ensemble machine learning framework for the prediction of somatic mutations in cancer. Background: The accurate screening of tumor genomic landscapes for somatic mutations using high-throughput sequencing involves a crucial step in precise clinical diagnosis and targeted therapy. However, the complex inherent features of cancer tissue, especially, tumor genetic intra-heterogeneity coupled with the problem of sequencing and alignment artifacts, makes somatic variant calling a challenging task. Current variant filtering strategies, such as rule-based filtering and consensus voting of different algorithms, have previously helped to increase specificity, although comes at the cost of sensitivity. Methods: In light of this, we have developed the NeoMutate framework which incorporates 7 supervised machine learning (ML) algorithms to exploit the strengths of multiple variant callers, using a non-redundant set of biological and sequence features. We benchmarked NeoMutate by simulating more than 10,000 bona fide cancer-related mutations into three well-characterized Genome in a Bottle (GIAB) reference samples. Results: A robust and exhaustive evaluation of NeoMutate's performance based on 5-fold cross validation experiments, in addition to 3 independent tests, demonstrated a substantially improved variant detection accuracy compared to any of its individual composite variant callers and consensus calling of multiple tools. Conclusions: We show here that integrating multiple tools in an ensemble ML layer optimizes somatic variant detection rates, leading to a potentially improved variant selection framework for the diagnosis and treatment of cancer."
0,Novel prognostic clinical factors and biomarkers for outcome prediction in head and neck cancer: a systematic review,,
0,Evaluation of a micro-spectrometer for the real-time assessment of liver graft with mild-to-moderate macrosteatosis: A proof of concept study,,
0,The new age of radiomic risk profiling: perivascular fat at the heart of the matter,,
0,Antioxidant potential of ganoderic acid in Notch-1 protein in neuroblastoma,"Neuroblastoma is a childhood tumor arising from developing a sympathetic nervous system and causes around 10% of pediatric tumors. Despite advancement in the use of sophisticated techniques in molecular biology, neuroblastoma patientâ€™s survivability rate is very less. Notch pathway is significant in upholding cell maintenance and developmental process of organs. Notch-1 proteins are a ligand-activated transmembrane receptor which decides the fate of the cell. Notch signaling leads to transcription of genes which indulged in numerous diseases including tumor progression. Ganoderic acid, a lanosterol triterpene, isolated from fungus Ganoderma lucidum with a wide range of medicinal values. In the present study, various isoforms of the ganoderic acid and natural inhibitors were docked by molecular docking using Maestro 9 in the Notch-1 signaling pathway. The receptor-based molecular docking exposed the best binding interaction of Notch-1 with ganoderic acid A with GScore (âˆ’ 8.088), kcal/mol, Lipophilic EvdW (âˆ’ 1.74), Electro (âˆ’ 1.18), Glide emodel (âˆ’ 89.944) with the active participation of Arg 189, Arg 199, Glu 232 residues. On the other hand natural inhibitor, curcumin has GScore (âˆ’ 7.644), kcal/mol, Lipophilic EvdW (âˆ’ 2.19), Electro (âˆ’ 0.73), Glide emodel (âˆ’ 70.957) with Arg 75 residues involved in docking. The ligand binding affinity of ganoderic acid A in Notch-1 is calculated using MM-GBSA (âˆ’ 76.782), whereas curcumin has (âˆ’ 72.815) kcal/mol. The QikProp analyzed the various drug-likeness parameters such as absorption, distribution, metabolism, excretion, and toxicity (ADME/T) and isoforms of ganoderic acid require some modification to fall under Lipinski rule. The ganoderic acid A and curcumin were the best-docked among different compounds and exhibits downregulation in Notch-1 mRNA expression and inhibits proliferation, viability, and ROS activity in IMR-32 cells.","Antioxidant potential of ganoderic acid in Notch-1 protein in neuroblastoma. Neuroblastoma is a childhood tumor arising from developing a sympathetic nervous system and causes around 10% of pediatric tumors. Despite advancement in the use of sophisticated techniques in molecular biology, neuroblastoma patientâ€™s survivability rate is very less. Notch pathway is significant in upholding cell maintenance and developmental process of organs. Notch-1 proteins are a ligand-activated transmembrane receptor which decides the fate of the cell. Notch signaling leads to transcription of genes which indulged in numerous diseases including tumor progression. Ganoderic acid, a lanosterol triterpene, isolated from fungus Ganoderma lucidum with a wide range of medicinal values. In the present study, various isoforms of the ganoderic acid and natural inhibitors were docked by molecular docking using Maestro 9 in the Notch-1 signaling pathway. The receptor-based molecular docking exposed the best binding interaction of Notch-1 with ganoderic acid A with GScore (âˆ’ 8.088), kcal/mol, Lipophilic EvdW (âˆ’ 1.74), Electro (âˆ’ 1.18), Glide emodel (âˆ’ 89.944) with the active participation of Arg 189, Arg 199, Glu 232 residues. On the other hand natural inhibitor, curcumin has GScore (âˆ’ 7.644), kcal/mol, Lipophilic EvdW (âˆ’ 2.19), Electro (âˆ’ 0.73), Glide emodel (âˆ’ 70.957) with Arg 75 residues involved in docking. The ligand binding affinity of ganoderic acid A in Notch-1 is calculated using MM-GBSA (âˆ’ 76.782), whereas curcumin has (âˆ’ 72.815) kcal/mol. The QikProp analyzed the various drug-likeness parameters such as absorption, distribution, metabolism, excretion, and toxicity (ADME/T) and isoforms of ganoderic acid require some modification to fall under Lipinski rule. The ganoderic acid A and curcumin were the best-docked among different compounds and exhibits downregulation in Notch-1 mRNA expression and inhibits proliferation, viability, and ROS activity in IMR-32 cells."
0,A better AI-based tool for mesothelioma,,
0,"Capecitabine compared with observation in resected biliary tract cancer (BILCAP): a randomised, controlled, multicentre, phase 3 study",,
0,Inherited and De Novo Genetic Risk for Autism Impacts Shared Networks,,
0,Geographical distribution and prevalence of podoconiosis in Rwanda: a cross-sectional country-wide survey,,
0,Prospective validation of a new airway management algorithm and predictive features of intubation difficulty,"BACKGROUND: Some patients have features that indicate possible difficulty with direct laryngoscopy for tracheal intubation. Prediction of the likely outcome and selection of patients for an enhanced management algorithm would reduce the possible harm from failed intubation attempts. METHODS: Adult elective patients were assessed for seven features associated with difficult direct laryngoscopy, ranked in difficulty from 0 to 3. For a patient with at least one Class 3 feature, or two or more features of class 1 or higher, the enhanced management used a channelled videolaryngoscope Airtraq instead of a Macintosh laryngoscope. A long flexible angulated stylet and a flexible fibrescope would be used as the second and third steps. For patients with lesser difficulty scores, a Macintosh laryngoscope was used. Outcomes of enhanced management were analysed. Logistic regression and Random Forest algorithm, using the ranks of the predictive features, were used to predict difficulty during enhanced management. RESULTS: We prospectively studied 16 695 patients. We selected 1501 (9%) for enhanced management, and tracheal intubation was successful in all of them. Of these, 73% were intubated in less than 30 s, and only 4.5% required more than 4 min for intubation. Progression to the second and third steps of enhanced management was predicted by restriction of mouth opening and reduced cervical spine mobility. CONCLUSIONS: An enhanced management algorithm allowed successful tracheal intubation of all patients with anticipated difficult laryngoscopy. The need to combine the use of a stylet and a fibrescope with the Airtraq could be predicted with a high degree of certainty.","Prospective validation of a new airway management algorithm and predictive features of intubation difficulty. BACKGROUND: Some patients have features that indicate possible difficulty with direct laryngoscopy for tracheal intubation. Prediction of the likely outcome and selection of patients for an enhanced management algorithm would reduce the possible harm from failed intubation attempts. METHODS: Adult elective patients were assessed for seven features associated with difficult direct laryngoscopy, ranked in difficulty from 0 to 3. For a patient with at least one Class 3 feature, or two or more features of class 1 or higher, the enhanced management used a channelled videolaryngoscope Airtraq instead of a Macintosh laryngoscope. A long flexible angulated stylet and a flexible fibrescope would be used as the second and third steps. For patients with lesser difficulty scores, a Macintosh laryngoscope was used. Outcomes of enhanced management were analysed. Logistic regression and Random Forest algorithm, using the ranks of the predictive features, were used to predict difficulty during enhanced management. RESULTS: We prospectively studied 16 695 patients. We selected 1501 (9%) for enhanced management, and tracheal intubation was successful in all of them. Of these, 73% were intubated in less than 30 s, and only 4.5% required more than 4 min for intubation. Progression to the second and third steps of enhanced management was predicted by restriction of mouth opening and reduced cervical spine mobility. CONCLUSIONS: An enhanced management algorithm allowed successful tracheal intubation of all patients with anticipated difficult laryngoscopy. The need to combine the use of a stylet and a fibrescope with the Airtraq could be predicted with a high degree of certainty."
0,Selection of reference miRNAs for relative quantification in buffalo (Bubalus bubalis) blastocysts produced by hand-made cloning and in vitro fertilization,"Very low birth rate and a high incidence of abnormalities in offspring born from cloned embryos, which have limited the application of cloning technology on a wide scale, are believed to be because of incomplete or aberrant nuclear reprogramming. MicroRNAs (miRNAs) are involved in regulating a wide range of biological processes including reprogramming and embryonic development. Selection of suitable reference miRNAs is critical for normalization of data for accurate relative quantification of miRNAs by quantitative real-time polymerase chain reaction (qRT-PCR), which is currently the most widely used technique for quantifying miRNAs. This study was aimed at identification of reference miRNAs suitable for normalization of qRT-PCR data from blastocyst-stage buffalo embryos produced by handmade cloning and in vitro fertilization (IVF). RNA isolated from cloned and IVF blastocysts was subjected to next-generation sequencing based on which, 12 highly and most consistently expressed miRNAs, which included miR-92a, miR-423, miR-151, Let-7a, miR-103a, miR-93, miR-16b, miR-25, miR-30e, miR-101, miR-127, and miR-197, were selected as candidates for identification of suitable reference miRNAs using three statistical algorithms namely geNorm, NormFinder, and BestKeeper. Based on consensus of the three algorithms, the combination of miRNAs found to be suitable as reference miRNAs were miR-127 and miR-103 for IVF blastocysts; miR-92a and miR-103 for cloned blastocysts, and miR-103, miR-423, and miR-93 across both IVF and cloned blastocysts. The data of this study can be very useful in miRNA expression analysis of blastocyst-stage cloned and IVF embryos.","Selection of reference miRNAs for relative quantification in buffalo (Bubalus bubalis) blastocysts produced by hand-made cloning and in vitro fertilization. Very low birth rate and a high incidence of abnormalities in offspring born from cloned embryos, which have limited the application of cloning technology on a wide scale, are believed to be because of incomplete or aberrant nuclear reprogramming. MicroRNAs (miRNAs) are involved in regulating a wide range of biological processes including reprogramming and embryonic development. Selection of suitable reference miRNAs is critical for normalization of data for accurate relative quantification of miRNAs by quantitative real-time polymerase chain reaction (qRT-PCR), which is currently the most widely used technique for quantifying miRNAs. This study was aimed at identification of reference miRNAs suitable for normalization of qRT-PCR data from blastocyst-stage buffalo embryos produced by handmade cloning and in vitro fertilization (IVF). RNA isolated from cloned and IVF blastocysts was subjected to next-generation sequencing based on which, 12 highly and most consistently expressed miRNAs, which included miR-92a, miR-423, miR-151, Let-7a, miR-103a, miR-93, miR-16b, miR-25, miR-30e, miR-101, miR-127, and miR-197, were selected as candidates for identification of suitable reference miRNAs using three statistical algorithms namely geNorm, NormFinder, and BestKeeper. Based on consensus of the three algorithms, the combination of miRNAs found to be suitable as reference miRNAs were miR-127 and miR-103 for IVF blastocysts; miR-92a and miR-103 for cloned blastocysts, and miR-103, miR-423, and miR-93 across both IVF and cloned blastocysts. The data of this study can be very useful in miRNA expression analysis of blastocyst-stage cloned and IVF embryos."
0,Incorporating the probability of competing event(s) into the preeclampsia competing risk algorithm,,
0,Addressing Bias in Artificial Intelligence in Health Care,,
0,Grown-up congenital heart disease: Building evidence where it is badly needed,,
0,Identification of a novel class of RIP1/RIP3 dual inhibitors that impede cell death and inflammation in mouse abdominal aortic aneurysm models,"Receptor interacting protein kinase-1 and -3 (RIP1 and RIP3) are essential mediators of cell death processes and participate in inflammatory responses. Our group recently demonstrated that gene deletion of Rip3 or pharmacological inhibition of RIP1 attenuated pathogenesis of abdominal aortic aneurysm (AAA), a life-threatening degenerative vascular disease characterized by depletion of smooth muscle cells (SMCs), inflammation, negative extracellular matrix remodeling, and progressive expansion of aorta. The goal of this study was to develop drug candidates for AAA and other disease conditions involving cell death and inflammation. We screened 1141 kinase inhibitors for their ability to block necroptosis using the RIP1 inhibitor Necrostatin-1s (Nec-1s) as a selection baseline. Positive compounds were further screened for cytotoxicity and virtual binding to RIP3. A cluster of top hits, represented by GSK2593074A (GSKâ€™074), displayed structural similarity to the established RIP3 inhibitor GSKâ€™843. In multiple cell types including mouse SMCs, fibroblasts (L929), bone marrow derived macrophages (BMDM), and human colon epithelial cells (HT29), GSKâ€™074 inhibited necroptosis with an IC50 of ~3 nM. Furthermore, GSKâ€™074, but not Nec-1s, blocked cytokine production by SMCs. Biochemical analyses identified both RIP1 and RIP3 as the biological targets of GSKâ€™074. Unlike GSKâ€™843 which causes profound apoptosis at high doses (>3 ÂµM), GSKâ€™074 showed no detectable cytotoxicity even at 20 ÂµM. Daily intraperitoneal injection of GSKâ€™074 at 0.93 mg/kg significantly attenuated aortic expansion in two mouse models of AAA (calcium phosphate: DMSO 66.06 Â± 9.17% vs GSKâ€™074 27.36 Â± 8.25%, P < 0.05; Angiotensin II: DMSO 85.39 Â± 15.76% vs GSKâ€™074 36.28 Â± 5.76%, P < 0.05). Histologically, GSKâ€™074 treatment diminished cell death and macrophage infiltration in aneurysm-prone aortae. Together, our data suggest that GSKâ€™074 represents a new class of necroptosis inhibitors with dual targeting ability to both RIP1 and RIP3. The high potency and minimum cytotoxicity make GSKâ€™074 a desirable drug candidate of pharmacological therapies to attenuate AAA progression and other necroptosis related diseases.","Identification of a novel class of RIP1/RIP3 dual inhibitors that impede cell death and inflammation in mouse abdominal aortic aneurysm models. Receptor interacting protein kinase-1 and -3 (RIP1 and RIP3) are essential mediators of cell death processes and participate in inflammatory responses. Our group recently demonstrated that gene deletion of Rip3 or pharmacological inhibition of RIP1 attenuated pathogenesis of abdominal aortic aneurysm (AAA), a life-threatening degenerative vascular disease characterized by depletion of smooth muscle cells (SMCs), inflammation, negative extracellular matrix remodeling, and progressive expansion of aorta. The goal of this study was to develop drug candidates for AAA and other disease conditions involving cell death and inflammation. We screened 1141 kinase inhibitors for their ability to block necroptosis using the RIP1 inhibitor Necrostatin-1s (Nec-1s) as a selection baseline. Positive compounds were further screened for cytotoxicity and virtual binding to RIP3. A cluster of top hits, represented by GSK2593074A (GSKâ€™074), displayed structural similarity to the established RIP3 inhibitor GSKâ€™843. In multiple cell types including mouse SMCs, fibroblasts (L929), bone marrow derived macrophages (BMDM), and human colon epithelial cells (HT29), GSKâ€™074 inhibited necroptosis with an IC50 of ~3 nM. Furthermore, GSKâ€™074, but not Nec-1s, blocked cytokine production by SMCs. Biochemical analyses identified both RIP1 and RIP3 as the biological targets of GSKâ€™074. Unlike GSKâ€™843 which causes profound apoptosis at high doses (>3 ÂµM), GSKâ€™074 showed no detectable cytotoxicity even at 20 ÂµM. Daily intraperitoneal injection of GSKâ€™074 at 0.93 mg/kg significantly attenuated aortic expansion in two mouse models of AAA (calcium phosphate: DMSO 66.06 Â± 9.17% vs GSKâ€™074 27.36 Â± 8.25%, P < 0.05; Angiotensin II: DMSO 85.39 Â± 15.76% vs GSKâ€™074 36.28 Â± 5.76%, P < 0.05). Histologically, GSKâ€™074 treatment diminished cell death and macrophage infiltration in aneurysm-prone aortae. Together, our data suggest that GSKâ€™074 represents a new class of necroptosis inhibitors with dual targeting ability to both RIP1 and RIP3. The high potency and minimum cytotoxicity make GSKâ€™074 a desirable drug candidate of pharmacological therapies to attenuate AAA progression and other necroptosis related diseases."
0,Potent and specific MTH1 inhibitors targeting gastric cancer,"Human mutT homolog 1(MTH1), the oxidized dNTP pool sanitizer enzyme, has been reported to be highly expressed in various malignant tumors. However, the oncogenic role of MTH1 in gastric cancer remains to be determined. In the current study, we found that MTH1 was overexpressed in human gastric cancer tissues and cells. Using an in vitro MTH1 inhibitor screening system, the compounds available in our laboratory were screened and the small molecules containing 5-cyano-6-phenylpyrimidine structure were firstly found to show potently and specifically inhibitory effect on MTH1, especially compound MI-743 with IC50 = 91.44 Â± 1.45 nM. Both molecular docking and target engagement experiments proved that MI-743 can directly bind to MTH1. Moreover, MI-743 could not only inhibit cell proliferation in up to 16 cancer cell lines, especially gastric cancer cells HGC-27 and MGC-803, but also significantly induce MTH1-related 8-oxo-dG accumulation and DNA damage. Furthermore, the growth of xenograft tumours derived by injection of MGC-803 cells in nude mice was also significantly inhibited by MI-743 treatment. Importantly, MTH1 knockdown by siRNA in those two gastric cancer cells exhibited the similar findings. Our findings indicate that MTH1 is highly expressed in human gastric cancer tissues and cell lines. Small molecule MI-743 with 5-cyano-6-phenylpyrimidine structure may serve as a novel lead compound targeting the overexpressed MTH1 for gastric cancer treatment.","Potent and specific MTH1 inhibitors targeting gastric cancer. Human mutT homolog 1(MTH1), the oxidized dNTP pool sanitizer enzyme, has been reported to be highly expressed in various malignant tumors. However, the oncogenic role of MTH1 in gastric cancer remains to be determined. In the current study, we found that MTH1 was overexpressed in human gastric cancer tissues and cells. Using an in vitro MTH1 inhibitor screening system, the compounds available in our laboratory were screened and the small molecules containing 5-cyano-6-phenylpyrimidine structure were firstly found to show potently and specifically inhibitory effect on MTH1, especially compound MI-743 with IC50 = 91.44 Â± 1.45 nM. Both molecular docking and target engagement experiments proved that MI-743 can directly bind to MTH1. Moreover, MI-743 could not only inhibit cell proliferation in up to 16 cancer cell lines, especially gastric cancer cells HGC-27 and MGC-803, but also significantly induce MTH1-related 8-oxo-dG accumulation and DNA damage. Furthermore, the growth of xenograft tumours derived by injection of MGC-803 cells in nude mice was also significantly inhibited by MI-743 treatment. Importantly, MTH1 knockdown by siRNA in those two gastric cancer cells exhibited the similar findings. Our findings indicate that MTH1 is highly expressed in human gastric cancer tissues and cell lines. Small molecule MI-743 with 5-cyano-6-phenylpyrimidine structure may serve as a novel lead compound targeting the overexpressed MTH1 for gastric cancer treatment."
0,Neutrophil Gelatinase-Associated Lipocalin for Assessment of Acute Kidney Injury in Cirrhosis: A Prospective Study,,
0,Evaluating the performance of automated sphygmomanometers using a patient simulator,"BACKGROUND AND OBJECTIVE: Automated sphygmomanometers use the oscillometric method to measure blood pressure, which is based on an algorithm that relates the amplitude of the oscillometric waveform pulses and the pressure inside the cuff. Validation uses empirical information from clinical trials conducted by each manufacturer. Consequently, measurement algorithms are not harmonized, being based on distinct arterial waveforms, according to each group of volunteers of the clinical test. In the present study, a patient simulator was used to generate standardized, consistent oscillometric waveform pulses to test the algorithms used in six sphygmomanometers. MATERIALS AND METHODS: Six different upper arm and wrist-based automated sphygmomanometers were tested using a patient simulator comprising four different blood pressure levels, Psys/dia (mmHg): 80/50; 120/80; 150/100; 200/150. The devices were also submitted to conformity assessment. The variance of repeatable measurements was also analyzed. RESULTS: All tested automated sphygmomanometers complied with metrological requirements, presenting results within the range of Â±2 mmHg for static calibration. Systematic discrepancies, greater than 20 mmHg, were observed between sphygmomanometers' results from upper arm and wrist-based models. Differences reaching 12.8 mmHg in diastolic pressure results were observed among upper arm devices. CONCLUSION: These results may have a clinical impact and indicate the need for a standardized algorithm, with a harmonized approach for validation. Moreover, the algorithm of the wrist-based devices is being affected by the use of the brachial artery waveform as reference for its validation, which also reveals that the current approach needs standardization, especially regarding the use of patient simulators.24299305.","Evaluating the performance of automated sphygmomanometers using a patient simulator. BACKGROUND AND OBJECTIVE: Automated sphygmomanometers use the oscillometric method to measure blood pressure, which is based on an algorithm that relates the amplitude of the oscillometric waveform pulses and the pressure inside the cuff. Validation uses empirical information from clinical trials conducted by each manufacturer. Consequently, measurement algorithms are not harmonized, being based on distinct arterial waveforms, according to each group of volunteers of the clinical test. In the present study, a patient simulator was used to generate standardized, consistent oscillometric waveform pulses to test the algorithms used in six sphygmomanometers. MATERIALS AND METHODS: Six different upper arm and wrist-based automated sphygmomanometers were tested using a patient simulator comprising four different blood pressure levels, Psys/dia (mmHg): 80/50; 120/80; 150/100; 200/150. The devices were also submitted to conformity assessment. The variance of repeatable measurements was also analyzed. RESULTS: All tested automated sphygmomanometers complied with metrological requirements, presenting results within the range of Â±2 mmHg for static calibration. Systematic discrepancies, greater than 20 mmHg, were observed between sphygmomanometers' results from upper arm and wrist-based models. Differences reaching 12.8 mmHg in diastolic pressure results were observed among upper arm devices. CONCLUSION: These results may have a clinical impact and indicate the need for a standardized algorithm, with a harmonized approach for validation. Moreover, the algorithm of the wrist-based devices is being affected by the use of the brachial artery waveform as reference for its validation, which also reveals that the current approach needs standardization, especially regarding the use of patient simulators.24299305."
0,"Synthesis and Characterization of 3-(1-((3,4-Dihydroxyphenethyl)amino)ethylidene)-chroman-2,4-dione as a Potential Antitumor Agent","The newly synthesized coumarin derivative with dopamine, 3-(1-((3,4-dihydroxyphenethyl)amino)ethylidene)-chroman-2,4-dione, was completely structurally characterized by X-ray crystallography. It was shown that several types of hydrogen bonds are present, which additionally stabilize the structure. The compound was tested in vitro against different cell lines, healthy human keratinocyte HaCaT, cervical squamous cell carcinoma SiHa, breast carcinoma MCF7, and hepatocellular carcinoma HepG2. Compared to control, the new derivate showed a stronger effect on both healthy and carcinoma cell lines, with the most prominent effect on the breast carcinoma MCF7 cell line. The molecular docking study, obtained for ten different conformations of the new compound, showed its inhibitory nature against CDKS protein. Lower inhibition constant, relative to one of 4-OH-coumarine, proved stronger and more numerous interactions with CDKS protein. These interactions were carefully examined for both parent molecule and derivative and explained from a structural point of view.","Synthesis and Characterization of 3-(1-((3,4-Dihydroxyphenethyl)amino)ethylidene)-chroman-2,4-dione as a Potential Antitumor Agent. The newly synthesized coumarin derivative with dopamine, 3-(1-((3,4-dihydroxyphenethyl)amino)ethylidene)-chroman-2,4-dione, was completely structurally characterized by X-ray crystallography. It was shown that several types of hydrogen bonds are present, which additionally stabilize the structure. The compound was tested in vitro against different cell lines, healthy human keratinocyte HaCaT, cervical squamous cell carcinoma SiHa, breast carcinoma MCF7, and hepatocellular carcinoma HepG2. Compared to control, the new derivate showed a stronger effect on both healthy and carcinoma cell lines, with the most prominent effect on the breast carcinoma MCF7 cell line. The molecular docking study, obtained for ten different conformations of the new compound, showed its inhibitory nature against CDKS protein. Lower inhibition constant, relative to one of 4-OH-coumarine, proved stronger and more numerous interactions with CDKS protein. These interactions were carefully examined for both parent molecule and derivative and explained from a structural point of view."
0,Disrupted apolipoprotein L1-miR193a axis dedifferentiates podocytes through autophagy blockade in an APOL1 risk milieu,"We hypothesized that a functional apolipoprotein LI (APOL1)-miR193a axis (inverse relationship) preserves, but disruption alters, the podocyte molecular phenotype through the modulation of autophagy flux. Podocyte-expressing APOL1G0 (G0-podocytes) showed downregulation but podocyte-expressing APOL1G1 (G1-podocytes) and APOL1G2 (G2-podo-cytes) displayed enhanced miR193a expression. G0-, G1-, and G2-podocytes showed enhanced expression of light chain (LC) 3-II and beclin-1, but a disparate expression of p62 (low in wild-type but high in risk alleles). G0-podocytes showed enhanced, whereas G1- and G2-podocytes displayed decreased, phosphorylation of Unc-51-like autophagy-activating kinase (ULK)1 and class III phosphatidylinositol 3-kinase (PI3KC3). Podocytes overexpressing miR193a (miR193a-podocytes), G1, and G2 showed decreased transcription of PIK3R3 (PI3KC3=s regulatory unit). Since 3-methyladenine (3-MA) enhanced miR193a expression but inhibited PIK3R3 transcription, it appears that 3-MA inhibits autophagy and induces podocyte dedifferentiation via miR193a generation. miR193a-, G1-, and G2-podocytes also showed decreased phosphorylation of mammalian target of rapamycin (mTOR) that could repress lysosome reformation. G1- and G2-podocytes showed enhanced expression of run domain beclin-1interacting and cysteine-rich domain-containing protein (Rubicon); however, its silencing prevented their dedifferentiation. Docking, protein-protein interaction, and immunoprecipitation studies with an-tiautophagy-related gene (ATG)14L, anti-UV radiation resistanceassociated gene (UVRAG), or Rubicon antibodies suggested the formation of ATG14L complex I and UVRAG complex II in G0-podocytes and the formation of Rubicon complex III in G1- and G2-podocytes. These findings suggest that the APOL1 risk alleles favor podocyte dedifferentiation through blockade of multiple autophagy pathways.","Disrupted apolipoprotein L1-miR193a axis dedifferentiates podocytes through autophagy blockade in an APOL1 risk milieu. We hypothesized that a functional apolipoprotein LI (APOL1)-miR193a axis (inverse relationship) preserves, but disruption alters, the podocyte molecular phenotype through the modulation of autophagy flux. Podocyte-expressing APOL1G0 (G0-podocytes) showed downregulation but podocyte-expressing APOL1G1 (G1-podocytes) and APOL1G2 (G2-podo-cytes) displayed enhanced miR193a expression. G0-, G1-, and G2-podocytes showed enhanced expression of light chain (LC) 3-II and beclin-1, but a disparate expression of p62 (low in wild-type but high in risk alleles). G0-podocytes showed enhanced, whereas G1- and G2-podocytes displayed decreased, phosphorylation of Unc-51-like autophagy-activating kinase (ULK)1 and class III phosphatidylinositol 3-kinase (PI3KC3). Podocytes overexpressing miR193a (miR193a-podocytes), G1, and G2 showed decreased transcription of PIK3R3 (PI3KC3=s regulatory unit). Since 3-methyladenine (3-MA) enhanced miR193a expression but inhibited PIK3R3 transcription, it appears that 3-MA inhibits autophagy and induces podocyte dedifferentiation via miR193a generation. miR193a-, G1-, and G2-podocytes also showed decreased phosphorylation of mammalian target of rapamycin (mTOR) that could repress lysosome reformation. G1- and G2-podocytes showed enhanced expression of run domain beclin-1interacting and cysteine-rich domain-containing protein (Rubicon); however, its silencing prevented their dedifferentiation. Docking, protein-protein interaction, and immunoprecipitation studies with an-tiautophagy-related gene (ATG)14L, anti-UV radiation resistanceassociated gene (UVRAG), or Rubicon antibodies suggested the formation of ATG14L complex I and UVRAG complex II in G0-podocytes and the formation of Rubicon complex III in G1- and G2-podocytes. These findings suggest that the APOL1 risk alleles favor podocyte dedifferentiation through blockade of multiple autophagy pathways."
0,Astrocyte function from information processing to cognition and cognitive impairment,,
0,Oracle of Our Time: Machine Learning for Predicting Cardiovascular Events,,
0,Deep learning and medical diagnosis,,
0,Global Dimensions of Plant Virus Diseases: Current Status and Future Perspectives,"Viral diseases provide a major challenge to twenty-first century agriculture worldwide. Climate change and human population pressures are driving rapid alterations in agricultural practices and cropping systems that favor destructive viral disease outbreaks. Such outbreaks are strikingly apparent in subsistence agriculture in food-insecure regions. Agricultural globalization and international trade are spreading viruses and their vectors to new geographical regions with unexpected consequences for food production and natural ecosystems. Due to the varying epidemiological characteristics of diverent viral pathosystems, there is no one-size-fits-all approach toward mitigating negative viral disease impacts on diverse agroecological production systems. Advances in scientific understanding of virus pathosystems, rapid technological innovation, innovative communication strategies, and global scientific networks provide opportunities to build epidemiologic intelligence of virus threats to crop production and global food security. A paradigm shift toward deploying integrated, smart, and eco-friendly strategies is required to advance virus disease management in diverse agricultural cropping systems.","Global Dimensions of Plant Virus Diseases: Current Status and Future Perspectives. Viral diseases provide a major challenge to twenty-first century agriculture worldwide. Climate change and human population pressures are driving rapid alterations in agricultural practices and cropping systems that favor destructive viral disease outbreaks. Such outbreaks are strikingly apparent in subsistence agriculture in food-insecure regions. Agricultural globalization and international trade are spreading viruses and their vectors to new geographical regions with unexpected consequences for food production and natural ecosystems. Due to the varying epidemiological characteristics of diverent viral pathosystems, there is no one-size-fits-all approach toward mitigating negative viral disease impacts on diverse agroecological production systems. Advances in scientific understanding of virus pathosystems, rapid technological innovation, innovative communication strategies, and global scientific networks provide opportunities to build epidemiologic intelligence of virus threats to crop production and global food security. A paradigm shift toward deploying integrated, smart, and eco-friendly strategies is required to advance virus disease management in diverse agricultural cropping systems."
0,Quantitative Super-Resolution Microscopy of the Mammalian Glycocalyx,"The mammalian glycocalyx is a heavily glycosylated extramembrane compartment found on nearly every cell. Despite its relevance in both health and disease, studies of the glycocalyx remain hampered by a paucity of methods to spatially classify its components. We combine metabolic labeling, bioorthogonal chemistry, and super-resolution localization microscopy to image two constituents of cell-surface glycans, N-acetylgalactosamine (GalNAc) and sialic acid, with 10â€“20 nm precision in 2D and 3D. This approach enables two measurements: glycocalyx height and the distribution of individual sugars distal from the membrane. These measurements show that the glycocalyx exhibits nanoscale organization on both cell lines and primary human tumor cells. Additionally, we observe enhanced glycocalyx height in response to epithelial-to-mesenchymal transition and to oncogenic KRAS activation. In the latter case, we trace increased height to an effector gene, GALNT7. These data highlight the power of advanced imaging methods to provide molecular and functional insights into glycocalyx biology. Nearly every cell in the human body is encapsulated by an extramembrane glycosylated compartmentâ€”the glycocalyxâ€”that is the cell's first point of contact with the extracellular environment. MÃ¶ckl et al. combine bioorthogonal chemistry with quantitative super-resolution imaging to investigate glycocalyx nanoscale organization and its relationship to oncogenic cellular transformation.","Quantitative Super-Resolution Microscopy of the Mammalian Glycocalyx. The mammalian glycocalyx is a heavily glycosylated extramembrane compartment found on nearly every cell. Despite its relevance in both health and disease, studies of the glycocalyx remain hampered by a paucity of methods to spatially classify its components. We combine metabolic labeling, bioorthogonal chemistry, and super-resolution localization microscopy to image two constituents of cell-surface glycans, N-acetylgalactosamine (GalNAc) and sialic acid, with 10â€“20 nm precision in 2D and 3D. This approach enables two measurements: glycocalyx height and the distribution of individual sugars distal from the membrane. These measurements show that the glycocalyx exhibits nanoscale organization on both cell lines and primary human tumor cells. Additionally, we observe enhanced glycocalyx height in response to epithelial-to-mesenchymal transition and to oncogenic KRAS activation. In the latter case, we trace increased height to an effector gene, GALNT7. These data highlight the power of advanced imaging methods to provide molecular and functional insights into glycocalyx biology. Nearly every cell in the human body is encapsulated by an extramembrane glycosylated compartmentâ€”the glycocalyxâ€”that is the cell's first point of contact with the extracellular environment. MÃ¶ckl et al. combine bioorthogonal chemistry with quantitative super-resolution imaging to investigate glycocalyx nanoscale organization and its relationship to oncogenic cellular transformation."
0,HIV-1 Neutralizing Antibody Signatures and Application to Epitope-Targeted Vaccine Design,,
0,Molecular docking studies of chloroquine and its derivatives against P23pro-zbd domain of chikungunya virus: Implication in designing of novel therapeutic strategies,"The arthropod-transmitted chikungunya virus has emerged as an epidemic menace that causes debilitating polyarthritis. With this life-threatening impact on humans, the possible treatment requires to cure the viral infectivity. But, devoid of any vaccine against the chikungunya virus (CHIKV), there is a need to develop a novel chemotherapeutic strategy to treat this noxious infection. CHIKV carries highly compact P23pro-zbd structure that possesses potential RNA-binding surface domains which extremely influences the use of RNA template during genome replication at the time of infection and pathogenesis. Therefore, computational approaches were used to explore the novel small molecule inhibitors targeting P23pro-zbd domain. The tertiary structure was modeled and optimized using in silico approaches. The results obtained from PROCHECK (93.1% residues in favored regions), ERRAT (87.480 overall model quality) and ProSA (Z-score: âˆ’11.72) revealed the reliability of the proposed model. Interestingly, a previously reported inhibitor, chloroquine possesses good binding affinities with the target domain. In-depth analysis revealed that chloroquine derivatives such as didesethyl chloroquine hydroxyacetamide, cletoquine, hydroxychloroquine exhibited a better binding affinity. Notably, MD simulation analysis exhibited that Thr1312, Ala1355, Ala1356, Asn1357, Asp1364, Val1366, Cys1367, Ala1401, Gly1403, Ser1443, Tyr1444, Gly1445, Asn1459, and Thr1463 residues are the key amino acid responsible for stable ligand-protein interaction. The results obtained from this study provide new insights and advances the understanding to develop a new approach to consider effective and novel drug against chikungunya. However, a detailed in vivo study is required to explore its drug likeliness against this life-threatening disease.","Molecular docking studies of chloroquine and its derivatives against P23pro-zbd domain of chikungunya virus: Implication in designing of novel therapeutic strategies. The arthropod-transmitted chikungunya virus has emerged as an epidemic menace that causes debilitating polyarthritis. With this life-threatening impact on humans, the possible treatment requires to cure the viral infectivity. But, devoid of any vaccine against the chikungunya virus (CHIKV), there is a need to develop a novel chemotherapeutic strategy to treat this noxious infection. CHIKV carries highly compact P23pro-zbd structure that possesses potential RNA-binding surface domains which extremely influences the use of RNA template during genome replication at the time of infection and pathogenesis. Therefore, computational approaches were used to explore the novel small molecule inhibitors targeting P23pro-zbd domain. The tertiary structure was modeled and optimized using in silico approaches. The results obtained from PROCHECK (93.1% residues in favored regions), ERRAT (87.480 overall model quality) and ProSA (Z-score: âˆ’11.72) revealed the reliability of the proposed model. Interestingly, a previously reported inhibitor, chloroquine possesses good binding affinities with the target domain. In-depth analysis revealed that chloroquine derivatives such as didesethyl chloroquine hydroxyacetamide, cletoquine, hydroxychloroquine exhibited a better binding affinity. Notably, MD simulation analysis exhibited that Thr1312, Ala1355, Ala1356, Asn1357, Asp1364, Val1366, Cys1367, Ala1401, Gly1403, Ser1443, Tyr1444, Gly1445, Asn1459, and Thr1463 residues are the key amino acid responsible for stable ligand-protein interaction. The results obtained from this study provide new insights and advances the understanding to develop a new approach to consider effective and novel drug against chikungunya. However, a detailed in vivo study is required to explore its drug likeliness against this life-threatening disease."
0,The deformable most-likely-point paradigm,,
0,Pulmonary Aptamer Signatures in Children's Interstitial and Diffuse Lung Disease,,
0,Harnessing Minimally Invasive Surgery to Improve Outcomes in Endometrial Cancer Surgery-The Robots Are Coming,,
0,Synergistic enhancement of apoptosis by coralyne and paclitaxel in combination on MDA-MB-231 a triple-negative breast cancer cell line,"Triple-negative breast cancer (TNBC) is the most outrageous subtype of breast cancer. Emphasizing the urge of new approach in cancer therapy, combinational drug therapy may be proven as an effective strategy. In our previous study, we reported that coralyne (COR) with paclitaxel (PTX) efficiently decreases the proliferation of MDA-MB-231 compared with MCF-7 cell line. Thus, we studied the effect of COR and PTX in combination on apoptosis of MDA-MB-231 cell line. In silico results demonstrated that COR intercalates DNA at a minor groove. In vitro approaches revealed that in combination (COR and PTX) increases the efficacy of apoptosis in MDA-MB-231 cell line by a significant increase in G1/S phase arrest, DNA fragmentation, and change in mitochondria membrane potential. The expression of ATM and ATR a serine/threonine-proteinÂ kinase, ataxia telangiectasia and Rad3-related protein were depleted with an increase in time from 24 to 48 hours in concurrent with increased levels of Î³H2AX indicating that DNA damage routes cells to enter apoptosis. This was confirmed by high levels of caspase-3 and cytochrome c. Also, the decrease in the expression levels of matrix metalloproteinase-9 confirmed the antimetastatic efficacy of COR + PTX. The present study indicates that the synergistic effect of COR and PTX can enhance apoptosis in MDA-MB-231 cell line and may be proven as a potential anticancer therapy against TNBC.","Synergistic enhancement of apoptosis by coralyne and paclitaxel in combination on MDA-MB-231 a triple-negative breast cancer cell line. Triple-negative breast cancer (TNBC) is the most outrageous subtype of breast cancer. Emphasizing the urge of new approach in cancer therapy, combinational drug therapy may be proven as an effective strategy. In our previous study, we reported that coralyne (COR) with paclitaxel (PTX) efficiently decreases the proliferation of MDA-MB-231 compared with MCF-7 cell line. Thus, we studied the effect of COR and PTX in combination on apoptosis of MDA-MB-231 cell line. In silico results demonstrated that COR intercalates DNA at a minor groove. In vitro approaches revealed that in combination (COR and PTX) increases the efficacy of apoptosis in MDA-MB-231 cell line by a significant increase in G1/S phase arrest, DNA fragmentation, and change in mitochondria membrane potential. The expression of ATM and ATR a serine/threonine-proteinÂ kinase, ataxia telangiectasia and Rad3-related protein were depleted with an increase in time from 24 to 48 hours in concurrent with increased levels of Î³H2AX indicating that DNA damage routes cells to enter apoptosis. This was confirmed by high levels of caspase-3 and cytochrome c. Also, the decrease in the expression levels of matrix metalloproteinase-9 confirmed the antimetastatic efficacy of COR + PTX. The present study indicates that the synergistic effect of COR and PTX can enhance apoptosis in MDA-MB-231 cell line and may be proven as a potential anticancer therapy against TNBC."
0,Tissue differences revealed by gene expression profiles of various cell lines,"Mechanisms through which tissues are formed and maintained remain unknown but are fundamental aspects in biology. Tissue-specific gene expression is a valuable tool to study such mechanisms. But in many biomedical studies, cell lines, rather than human body tissues, are used to investigate biological mechanisms Whether or not cell lines maintain their tissue-specific characteristics after they are isolated and cultured outside the human body remains to be explored. In this study, we applied a novel computational method to identify core genes that contribute to the differentiation of cell lines from various tissues. Several advanced computational techniques, such as Monte Carlo feature selection method, incremental feature selection method, and support vector machine (SVM) algorithm, were incorporated in the proposed method, which extensively analyzed the gene expression profiles of cell lines from different tissues. As a result, we extracted a group of functional genes that can indicate the differences of cell lines in different tissues and built an optimal SVM classifier for identifying cell lines in different tissues. In addition, a set of rules for classifying cell lines were also reported, which can give a clearer picture of cell lines in different issues although its performance was not better than the optimal SVM classifier. Finally, we compared such genes with the tissue-specific genes identified by the Genotype-tissue Expression project. Results showed that most expression patterns between tissues remained in the derived cell lines despite some uniqueness that some genes show tissue specificity.","Tissue differences revealed by gene expression profiles of various cell lines. Mechanisms through which tissues are formed and maintained remain unknown but are fundamental aspects in biology. Tissue-specific gene expression is a valuable tool to study such mechanisms. But in many biomedical studies, cell lines, rather than human body tissues, are used to investigate biological mechanisms Whether or not cell lines maintain their tissue-specific characteristics after they are isolated and cultured outside the human body remains to be explored. In this study, we applied a novel computational method to identify core genes that contribute to the differentiation of cell lines from various tissues. Several advanced computational techniques, such as Monte Carlo feature selection method, incremental feature selection method, and support vector machine (SVM) algorithm, were incorporated in the proposed method, which extensively analyzed the gene expression profiles of cell lines from different tissues. As a result, we extracted a group of functional genes that can indicate the differences of cell lines in different tissues and built an optimal SVM classifier for identifying cell lines in different tissues. In addition, a set of rules for classifying cell lines were also reported, which can give a clearer picture of cell lines in different issues although its performance was not better than the optimal SVM classifier. Finally, we compared such genes with the tissue-specific genes identified by the Genotype-tissue Expression project. Results showed that most expression patterns between tissues remained in the derived cell lines despite some uniqueness that some genes show tissue specificity."
0,Single-Cell Transcriptomics Uncovers Glial Progenitor Diversity and Cell Fate Determinants during Development and Gliomagenesis,"By applying lineage-targeted, single-cell transcriptomics analysis, Weng and colleagues uncover distinct intermediate glial progenitors in the neonatal brain and their malignant counterparts in murine and human gliomas. Lineage-driving network analysis further identifies Zfp36l1 as a pivotal regulator for glial fate specification and glioma growth.","Single-Cell Transcriptomics Uncovers Glial Progenitor Diversity and Cell Fate Determinants during Development and Gliomagenesis. By applying lineage-targeted, single-cell transcriptomics analysis, Weng and colleagues uncover distinct intermediate glial progenitors in the neonatal brain and their malignant counterparts in murine and human gliomas. Lineage-driving network analysis further identifies Zfp36l1 as a pivotal regulator for glial fate specification and glioma growth."
0,"Vitellaria paradoxa nutshells from seven sub-Saharan countries as potential herbal medicines for treating diabetes based on chemical compositions, HPLC fingerprints and bioactivity evaluation","The aim of the study was to determine the feasibility of the Vitellaria paradoxa nutshell as a new medicinal resource for treating diabetes. A total of forty-one compounds were identified by HPLC-DAD-Q-TOF-MS and phytochemical methods in V. paradoxa nutshell methanol extract. Based on HPLC fingerprints, four characteristic constituents were quantified and the origin of twenty-eight V. paradoxa nutshells from seven sub-Saharan countries was compared, which were classified into three groups with chemometric method. Twenty-eight samples contained high total phenolic content, and exhibited moderate-higher antioxidant activity and strong Î±-glucosidase inhibitory activity. Furthermore, all fractions and isolated compounds were evaluated for their antioxidant and Î±-glucosidase inhibitory activities, and Î±-glucosidase inhibitory action mechanism of four characteristic constituents including protocatechuic acid, 3, 5, 7-trihydroxycoumarin, (2R, 3R)-(+)-taxifolin and quercetin was investigated via molecular docking method, which were all stabilized by hydrogen bonds with Î±-glucosidase. The study provided an effective approach to waste utilization of V. paradoxa nutshell, which would help to resolve waste environmental pollution and provide a basis for developing potential herbal resource for treating diabetes.","Vitellaria paradoxa nutshells from seven sub-Saharan countries as potential herbal medicines for treating diabetes based on chemical compositions, HPLC fingerprints and bioactivity evaluation. The aim of the study was to determine the feasibility of the Vitellaria paradoxa nutshell as a new medicinal resource for treating diabetes. A total of forty-one compounds were identified by HPLC-DAD-Q-TOF-MS and phytochemical methods in V. paradoxa nutshell methanol extract. Based on HPLC fingerprints, four characteristic constituents were quantified and the origin of twenty-eight V. paradoxa nutshells from seven sub-Saharan countries was compared, which were classified into three groups with chemometric method. Twenty-eight samples contained high total phenolic content, and exhibited moderate-higher antioxidant activity and strong Î±-glucosidase inhibitory activity. Furthermore, all fractions and isolated compounds were evaluated for their antioxidant and Î±-glucosidase inhibitory activities, and Î±-glucosidase inhibitory action mechanism of four characteristic constituents including protocatechuic acid, 3, 5, 7-trihydroxycoumarin, (2R, 3R)-(+)-taxifolin and quercetin was investigated via molecular docking method, which were all stabilized by hydrogen bonds with Î±-glucosidase. The study provided an effective approach to waste utilization of V. paradoxa nutshell, which would help to resolve waste environmental pollution and provide a basis for developing potential herbal resource for treating diabetes."
0,Machine learning brings cell imaging promises into focus,,
0,Pyrazinamide drug resistance in RpsA mutant (âˆ†438A) of Mycobacterium tuberculosis: Dynamics of essential motions and free-energy landscape analysis,"Pyrazinamide is an essential first-line antitubercular drug which plays pivotal role in tuberculosis treatment. It is a prodrug that requires amide hydrolysis by mycobacterial pyrazinamidase enzyme for conversion into pyrazinoic acid (POA). POA is known to target ribosomal protein S1 (RpsA), aspartate decarboxylase (PanD), and some other mycobacterial proteins. Spontaneous chromosomal mutations in RpsA have been reported for phenotypic resistance against pyrazinamide. We have constructed and validated 3D models of the native and Î”438A mutant form of RpsA protein. RpsA protein variants were then docked to POA and long range molecular dynamics simulations were carried out. Per residue binding free-energy calculations, free-energy landscape analysis, and essential dynamics analysis were performed to outline the mechanism underlying the high-level PZA resistance conferred by the most frequently occurring deletion mutant of RpsA. Our study revealed the conformational modulation of POA binding site due to the disruptive collective modes of motions and increased conformational flexibility in the mutant than the native form. Residue wise MMPBSA decomposition and protein-drug interaction pattern revealed the difference of energetically favorable binding site in the wild-type (WT) protein in comparison with the mutant. Analysis of size and shape of minimal energy landscape area delineated higher stability of the WT complex than the mutant form. Our study provides mechanistic insights into pyrazinamide resistance in Î”438A RpsA mutant, and the results arising out of this study will pave way for design of novel and effective inhibitors targeting the resistant strains of Mycobacterium tuberculosis.","Pyrazinamide drug resistance in RpsA mutant (âˆ†438A) of Mycobacterium tuberculosis: Dynamics of essential motions and free-energy landscape analysis. Pyrazinamide is an essential first-line antitubercular drug which plays pivotal role in tuberculosis treatment. It is a prodrug that requires amide hydrolysis by mycobacterial pyrazinamidase enzyme for conversion into pyrazinoic acid (POA). POA is known to target ribosomal protein S1 (RpsA), aspartate decarboxylase (PanD), and some other mycobacterial proteins. Spontaneous chromosomal mutations in RpsA have been reported for phenotypic resistance against pyrazinamide. We have constructed and validated 3D models of the native and Î”438A mutant form of RpsA protein. RpsA protein variants were then docked to POA and long range molecular dynamics simulations were carried out. Per residue binding free-energy calculations, free-energy landscape analysis, and essential dynamics analysis were performed to outline the mechanism underlying the high-level PZA resistance conferred by the most frequently occurring deletion mutant of RpsA. Our study revealed the conformational modulation of POA binding site due to the disruptive collective modes of motions and increased conformational flexibility in the mutant than the native form. Residue wise MMPBSA decomposition and protein-drug interaction pattern revealed the difference of energetically favorable binding site in the wild-type (WT) protein in comparison with the mutant. Analysis of size and shape of minimal energy landscape area delineated higher stability of the WT complex than the mutant form. Our study provides mechanistic insights into pyrazinamide resistance in Î”438A RpsA mutant, and the results arising out of this study will pave way for design of novel and effective inhibitors targeting the resistant strains of Mycobacterium tuberculosis."
0,Quality-based UnwRap of SUbdivided Large Arrays (URSULA) for high-resolution MRI data,"In Magnetic Resonance Imaging, mapping of the static magnetic field and the magnetic susceptibility is based on multidimensional phase measurements. Phase data are ambiguous and have to be unwrapped to their true range in order to exhibit a correct representation of underlying features. High-resolution imaging at ultra-high fields, where susceptibility and phase contrast are natural tools, can generate large datasets, which tend to dramatically increase computing time demands for spatial unwrapping algorithms. This article describes a novel method, URSULA, which introduces an artificial volume compartmentalisation that allows large-scale unwrapping problems to be broken down, making URSULA ideally suited for computational parallelisation. In the presented study, URSULA is illustrated with a quality-guided unwrapping approach. Validation is performed on numerical data and an application on a high-resolution measurement, at the clinical field strength of 3T is demonstrated. In conclusion, URSULA allows for a reduction of the problem size, a substantial speed-up and for handling large data sets without sacrificing the overall accuracy of the resulting phase information.","Quality-based UnwRap of SUbdivided Large Arrays (URSULA) for high-resolution MRI data. In Magnetic Resonance Imaging, mapping of the static magnetic field and the magnetic susceptibility is based on multidimensional phase measurements. Phase data are ambiguous and have to be unwrapped to their true range in order to exhibit a correct representation of underlying features. High-resolution imaging at ultra-high fields, where susceptibility and phase contrast are natural tools, can generate large datasets, which tend to dramatically increase computing time demands for spatial unwrapping algorithms. This article describes a novel method, URSULA, which introduces an artificial volume compartmentalisation that allows large-scale unwrapping problems to be broken down, making URSULA ideally suited for computational parallelisation. In the presented study, URSULA is illustrated with a quality-guided unwrapping approach. Validation is performed on numerical data and an application on a high-resolution measurement, at the clinical field strength of 3T is demonstrated. In conclusion, URSULA allows for a reduction of the problem size, a substantial speed-up and for handling large data sets without sacrificing the overall accuracy of the resulting phase information."
0,Electroacupuncture Facilitates the Integration of Neural Stem Cell-Derived Neural Network with Transected Rat Spinal Cord,"In this article, Y.S. Zeng, Y. Ding, and colleagues show that EA treatment can reinforce the survival, neuronal differentiation, and synaptic connections of donor neurons in injured spinal cord by activating the NT-3/TRKC/AKT pathway. Moreover, the combinational therapy fosters host axonal regeneration into the injury/graft site to rebuild the synaptic connections with grafted NN, and improves nerve conduction of the spinal cord as well as locomotor function of paralyzed hindlimbs.","Electroacupuncture Facilitates the Integration of Neural Stem Cell-Derived Neural Network with Transected Rat Spinal Cord. In this article, Y.S. Zeng, Y. Ding, and colleagues show that EA treatment can reinforce the survival, neuronal differentiation, and synaptic connections of donor neurons in injured spinal cord by activating the NT-3/TRKC/AKT pathway. Moreover, the combinational therapy fosters host axonal regeneration into the injury/graft site to rebuild the synaptic connections with grafted NN, and improves nerve conduction of the spinal cord as well as locomotor function of paralyzed hindlimbs."
0,How to diagnose heart failure with preserved ejection fraction: the HFA-PEFF diagnostic algorithm: a consensus recommendation from the Heart Failure Association (HFA) of the European Society of Cardiology (ESC),"Making a firm diagnosis of chronic heart failure with preserved ejection fraction (HFpEF) remains a challenge. We recommend a new stepwise diagnostic process, the 'HFA-PEFF diagnostic algorithm'. Step 1 (P=Pre-test assessment) is typically performed in the ambulatory setting and includes assessment for HF symptoms and signs, typical clinical demographics (obesity, hypertension, diabetes mellitus, elderly, atrial fibrillation), and diagnostic laboratory tests, electrocardiogram, and echocardiography. In the absence of overt non-cardiac causes of breathlessness, HFpEF can be suspected if there is a normal left ventricular ejection fraction, no significant heart valve disease or cardiac ischaemia, and at least one typical risk factor. Elevated natriuretic peptides support, but normal levels do not exclude a diagnosis of HFpEF. The second step (E: Echocardiography and Natriuretic Peptide Score) requires comprehensive echocardiography and is typically performed by a cardiologist. Measures include mitral annular early diastolic velocity (e'), left ventricular (LV) filling pressure estimated using E/e', left atrial volume index, LV mass index, LV relative wall thickness, tricuspid regurgitation velocity, LV global longitudinal systolic strain, and serum natriuretic peptide levels. Major (2 points) and Minor (1 point) criteria were defined from these measures. A score >/=5 points implies definite HFpEF; </=1 point makes HFpEF unlikely. An intermediate score (2-4 points) implies diagnostic uncertainty, in which case Step 3 (F1: Functional testing) is recommended with echocardiographic or invasive haemodynamic exercise stress tests. Step 4 (F2: Final aetiology) is recommended to establish a possible specific cause of HFpEF or alternative explanations. Further research is needed for a better classification of HFpEF.","How to diagnose heart failure with preserved ejection fraction: the HFA-PEFF diagnostic algorithm: a consensus recommendation from the Heart Failure Association (HFA) of the European Society of Cardiology (ESC). Making a firm diagnosis of chronic heart failure with preserved ejection fraction (HFpEF) remains a challenge. We recommend a new stepwise diagnostic process, the 'HFA-PEFF diagnostic algorithm'. Step 1 (P=Pre-test assessment) is typically performed in the ambulatory setting and includes assessment for HF symptoms and signs, typical clinical demographics (obesity, hypertension, diabetes mellitus, elderly, atrial fibrillation), and diagnostic laboratory tests, electrocardiogram, and echocardiography. In the absence of overt non-cardiac causes of breathlessness, HFpEF can be suspected if there is a normal left ventricular ejection fraction, no significant heart valve disease or cardiac ischaemia, and at least one typical risk factor. Elevated natriuretic peptides support, but normal levels do not exclude a diagnosis of HFpEF. The second step (E: Echocardiography and Natriuretic Peptide Score) requires comprehensive echocardiography and is typically performed by a cardiologist. Measures include mitral annular early diastolic velocity (e'), left ventricular (LV) filling pressure estimated using E/e', left atrial volume index, LV mass index, LV relative wall thickness, tricuspid regurgitation velocity, LV global longitudinal systolic strain, and serum natriuretic peptide levels. Major (2 points) and Minor (1 point) criteria were defined from these measures. A score >/=5 points implies definite HFpEF; </=1 point makes HFpEF unlikely. An intermediate score (2-4 points) implies diagnostic uncertainty, in which case Step 3 (F1: Functional testing) is recommended with echocardiographic or invasive haemodynamic exercise stress tests. Step 4 (F2: Final aetiology) is recommended to establish a possible specific cause of HFpEF or alternative explanations. Further research is needed for a better classification of HFpEF."
0,Phase I/II Trial of a Combination of Anti-CD3/CD7 Immunotoxins for Steroid-Refractory Acute Graft-versus-Host Disease,"Effective therapies for treating patients with steroid-refractory acute graft-versus-host-disease (SR-aGVHD), particularly strategies that reduce the duration of immunosuppression following remission, are urgently needed. The investigated immunotoxin combination consists of a mixture of anti-CD3 and anti-CD7 antibodies separately conjugated to recombinant ricin A (CD3/CD7-IT), which induces in vivo depletion of T cells and natural killer (NK) cells and suppresses T cell receptor activation. We conducted a phase I/II trial to examine the safety and efficacy of CD3/CD7-IT in 20 patients with SR-aGVHD; 17 of these patients (85%) had severe SR-aGVHD, and all 20 patients had visceral organ involvement, including 18 (90%) with gastrointestinal (GI) involvement and 5 (25%) with liver involvement. A validated 2-biomarker algorithm classified the majority of patients (11 of 20) as high risk. On day 28 after the start of CD3/CD7-IT therapy, the overall response rate was 60% (12 of 20), with 10 patients (50%) achieving a complete response. The 6-month overall survival rate was 60% (12 of 20), including 64% (7 of 11) classified as high risk by biomarkers. The 1-week course of treatment with CD3/CD7-IT caused profound but transient depletion of T cells and NK cells, followed by rapid recovery of the immune system with a diverse TCR VÎ² repertoire, and preservation of Epstein-Barr virus- and cytomegalovirus-specific T cell clones. Furthermore, our results indicate that CD3/CD7-IT appeared to be safe and well tolerated, with a relatively low prevalence of manageable and reversible adverse events, primarily worsening of hypoalbuminemia, microangiopathy, and thrombocytopenia. These encouraging results suggest that CD3/CD7-IT may improve patient outcomes in patients with SR-aGVHD.","Phase I/II Trial of a Combination of Anti-CD3/CD7 Immunotoxins for Steroid-Refractory Acute Graft-versus-Host Disease. Effective therapies for treating patients with steroid-refractory acute graft-versus-host-disease (SR-aGVHD), particularly strategies that reduce the duration of immunosuppression following remission, are urgently needed. The investigated immunotoxin combination consists of a mixture of anti-CD3 and anti-CD7 antibodies separately conjugated to recombinant ricin A (CD3/CD7-IT), which induces in vivo depletion of T cells and natural killer (NK) cells and suppresses T cell receptor activation. We conducted a phase I/II trial to examine the safety and efficacy of CD3/CD7-IT in 20 patients with SR-aGVHD; 17 of these patients (85%) had severe SR-aGVHD, and all 20 patients had visceral organ involvement, including 18 (90%) with gastrointestinal (GI) involvement and 5 (25%) with liver involvement. A validated 2-biomarker algorithm classified the majority of patients (11 of 20) as high risk. On day 28 after the start of CD3/CD7-IT therapy, the overall response rate was 60% (12 of 20), with 10 patients (50%) achieving a complete response. The 6-month overall survival rate was 60% (12 of 20), including 64% (7 of 11) classified as high risk by biomarkers. The 1-week course of treatment with CD3/CD7-IT caused profound but transient depletion of T cells and NK cells, followed by rapid recovery of the immune system with a diverse TCR VÎ² repertoire, and preservation of Epstein-Barr virus- and cytomegalovirus-specific T cell clones. Furthermore, our results indicate that CD3/CD7-IT appeared to be safe and well tolerated, with a relatively low prevalence of manageable and reversible adverse events, primarily worsening of hypoalbuminemia, microangiopathy, and thrombocytopenia. These encouraging results suggest that CD3/CD7-IT may improve patient outcomes in patients with SR-aGVHD."
0,A Comprehensive Review of Overactive Bladder Pathophysiology: On the Way to Tailored Treatment,,
0,Artificial intelligence for the electrocardiogram,,
0,IDH1-R132H acts as a tumor suppressor in glioma via epigenetic up-regulation of the DNA damage response,"Patients with glioma whose tumors carry a mutation in isocitrate dehydrogenase 1 (IDH1(R132H)) are younger at diagnosis and live longer. IDH1 mutations co-occur with other molecular lesions, such as 1p/19q codeletion, inactivating mutations in the tumor suppressor protein 53 (TP53) gene, and loss-of-function mutations in alpha thalassemia/mental retardation syndrome X-linked gene (ATRX). All adult low-grade gliomas (LGGs) harboring ATRX loss also express the IDH1(R132H) mutation. The current molecular classification of LGGs is based, partly, on the distribution of these mutations. We developed a genetically engineered mouse model harboring IDH1(R132H), TP53 and ATRX inactivating mutations, and activated NRAS G12V. Previously, we established that ATRX deficiency, in the context of wild-type IDH1, induces genomic instability, impairs nonhomologous end-joining DNA repair, and increases sensitivity to DNA-damaging therapies. In this study, using our mouse model and primary patient-derived glioma cultures with IDH1 mutations, we investigated the function of IDH1(R132H) in the context of TP53 and ATRX loss. We discovered that IDH1(R132H) expression in the genetic context of ATRX and TP53 gene inactivation (i) increases median survival in the absence of treatment, (ii) enhances DNA damage response (DDR) via epigenetic up-regulation of the ataxia-telangiectasia-mutated (ATM) signaling pathway, and (iii) elicits tumor radioresistance. Accordingly, pharmacological inhibition of ATM or checkpoint kinases 1 and 2, essential kinases in the DDR, restored the tumors' radiosensitivity. Translation of these findings to patients with IDH1(132H) glioma harboring TP53 and ATRX loss could improve the therapeutic efficacy of radiotherapy and, consequently, patient survival.","IDH1-R132H acts as a tumor suppressor in glioma via epigenetic up-regulation of the DNA damage response. Patients with glioma whose tumors carry a mutation in isocitrate dehydrogenase 1 (IDH1(R132H)) are younger at diagnosis and live longer. IDH1 mutations co-occur with other molecular lesions, such as 1p/19q codeletion, inactivating mutations in the tumor suppressor protein 53 (TP53) gene, and loss-of-function mutations in alpha thalassemia/mental retardation syndrome X-linked gene (ATRX). All adult low-grade gliomas (LGGs) harboring ATRX loss also express the IDH1(R132H) mutation. The current molecular classification of LGGs is based, partly, on the distribution of these mutations. We developed a genetically engineered mouse model harboring IDH1(R132H), TP53 and ATRX inactivating mutations, and activated NRAS G12V. Previously, we established that ATRX deficiency, in the context of wild-type IDH1, induces genomic instability, impairs nonhomologous end-joining DNA repair, and increases sensitivity to DNA-damaging therapies. In this study, using our mouse model and primary patient-derived glioma cultures with IDH1 mutations, we investigated the function of IDH1(R132H) in the context of TP53 and ATRX loss. We discovered that IDH1(R132H) expression in the genetic context of ATRX and TP53 gene inactivation (i) increases median survival in the absence of treatment, (ii) enhances DNA damage response (DDR) via epigenetic up-regulation of the ataxia-telangiectasia-mutated (ATM) signaling pathway, and (iii) elicits tumor radioresistance. Accordingly, pharmacological inhibition of ATM or checkpoint kinases 1 and 2, essential kinases in the DDR, restored the tumors' radiosensitivity. Translation of these findings to patients with IDH1(132H) glioma harboring TP53 and ATRX loss could improve the therapeutic efficacy of radiotherapy and, consequently, patient survival."
0,Validation of the United Kingdom copy-number alteration classifier in 3239 children with B-cell precursor ALL,"Genetic abnormalities provide vital diagnostic and prognostic information in pediatric acute lymphoblastic leukemia (ALL) and are increasingly used to assign patients to risk groups. We recently proposed a novel classifier based on the copy-number alteration (CNA) profile of the 8 most commonly deleted genes in B-cell precursor ALL. This classifier defined 3 CNA subgroups in consecutive UK trials and was able to discriminate patients with intermediate-risk cytogenetics. In this study, we sought to validate the United Kingdom ALL (UKALL)â€“CNA classifier and reevaluate the interaction with cytogenetic risk groups using individual patient data from 3239 cases collected from 12 groups within the International BFM Study Group. The classifier was validated and defined 3 risk groups with distinct event-free survival (EFS) rates: good (88%), intermediate (76%), and poor (68%) (P, .001). There was no evidence of heterogeneity, even within trials that used minimal residual disease to guide therapy. By integrating CNA and cytogenetic data, we replicated our original key observation that patients with intermediate-risk cytogenetics can be stratified into 2 prognostic subgroups. Group A had an EFS rate of 86% (similar to patients with good-risk cytogenetics), while group B patients had a significantly inferior rate (73%, P, .001). Finally, we revised the overall genetic classification by defining 4 risk groups with distinct EFS rates: very good (91%), good (81%), intermediate (73%), and poor (54%), P, .001. In conclusion, the UKALL-CNA classifier is a robust prognostic tool that can be deployed in different trial settings and used to refine established cytogenetic risk groups.","Validation of the United Kingdom copy-number alteration classifier in 3239 children with B-cell precursor ALL. Genetic abnormalities provide vital diagnostic and prognostic information in pediatric acute lymphoblastic leukemia (ALL) and are increasingly used to assign patients to risk groups. We recently proposed a novel classifier based on the copy-number alteration (CNA) profile of the 8 most commonly deleted genes in B-cell precursor ALL. This classifier defined 3 CNA subgroups in consecutive UK trials and was able to discriminate patients with intermediate-risk cytogenetics. In this study, we sought to validate the United Kingdom ALL (UKALL)â€“CNA classifier and reevaluate the interaction with cytogenetic risk groups using individual patient data from 3239 cases collected from 12 groups within the International BFM Study Group. The classifier was validated and defined 3 risk groups with distinct event-free survival (EFS) rates: good (88%), intermediate (76%), and poor (68%) (P, .001). There was no evidence of heterogeneity, even within trials that used minimal residual disease to guide therapy. By integrating CNA and cytogenetic data, we replicated our original key observation that patients with intermediate-risk cytogenetics can be stratified into 2 prognostic subgroups. Group A had an EFS rate of 86% (similar to patients with good-risk cytogenetics), while group B patients had a significantly inferior rate (73%, P, .001). Finally, we revised the overall genetic classification by defining 4 risk groups with distinct EFS rates: very good (91%), good (81%), intermediate (73%), and poor (54%), P, .001. In conclusion, the UKALL-CNA classifier is a robust prognostic tool that can be deployed in different trial settings and used to refine established cytogenetic risk groups."
0,The DNA methylation profile of non-coding RNAs improves prognosis prediction for pancreatic adenocarcinoma,"Background: Compelling lines of evidence indicate that DNA methylation of non-coding RNAs (ncRNAs) plays critical roles in various tumour progression. In addition, the differential methylation of ncRNAs can predict prognosis of patients. However, little is known about the clear relationship between DNA methylation profile of ncRNAs and the prognosis of pancreatic adenocarcinoma (PAC) patients. Methods: The data of DNA methylation, RNA-seq, miRNA-seq and clinical features of PAC patients were collected from TCGA database. The DNA methylation profile was obtained using the Infinium HumanMethylation450 BeadChip array. LASSO regression was performed to construct two methylation-based classifiers. The risk score of methylation-based classifiers was calculated for each patient, and the accuracy of the classifiers in predicting overall survival (OS) was examined by ROC curve analysis. In addition, Cox regression models were utilized to assess whether clinical variables and the classifiers were independent prognostic factors for OS. The targets of miRNA and the genes co-expressed with lncRNA were identified with DIANA microT-CDS and the Multi-Experiment Matrix (MEM), respectively. Moreover, DAVID Bioinformatics Resources were applied to analyse the functional enrichment of these targets and co-expressed genes. Results: A total of 4004 CpG sites of miRNA and 11,259 CpG sites of lncRNA were screened. Among these CpG sites, 8 CpG sites of miRNA and 7 CpG sites of lncRNA were found with regression coefficients. By multiplying the sum of methylation degrees of the selected CpGs with these coefficients, two methylation-based classifiers were constructed. The classifiers have shown good performance in predicting the survival rate of PAC patients at varying follow-up times. Interestingly, both of these two classifiers were predominant and independent factors for OS. Furthermore, functional enrichment analysis demonstrated that aberrantly methylated miRNAs and lncRNAs are related to calcium ion transmembrane transport and MAPK, Ras and calcium signalling pathways. Conclusion: In the present study, we identified two methylation-based classifiers of ncRNA associated with OS in PAC patients through a comprehensive analysis of miRNA and lncRNA profiles. We are the first group to demonstrate a relationship between the aberrant DNA methylation of ncRNAs and the prognosis of PAC, and this relationship would contribute to individualized PAC therapy.","The DNA methylation profile of non-coding RNAs improves prognosis prediction for pancreatic adenocarcinoma. Background: Compelling lines of evidence indicate that DNA methylation of non-coding RNAs (ncRNAs) plays critical roles in various tumour progression. In addition, the differential methylation of ncRNAs can predict prognosis of patients. However, little is known about the clear relationship between DNA methylation profile of ncRNAs and the prognosis of pancreatic adenocarcinoma (PAC) patients. Methods: The data of DNA methylation, RNA-seq, miRNA-seq and clinical features of PAC patients were collected from TCGA database. The DNA methylation profile was obtained using the Infinium HumanMethylation450 BeadChip array. LASSO regression was performed to construct two methylation-based classifiers. The risk score of methylation-based classifiers was calculated for each patient, and the accuracy of the classifiers in predicting overall survival (OS) was examined by ROC curve analysis. In addition, Cox regression models were utilized to assess whether clinical variables and the classifiers were independent prognostic factors for OS. The targets of miRNA and the genes co-expressed with lncRNA were identified with DIANA microT-CDS and the Multi-Experiment Matrix (MEM), respectively. Moreover, DAVID Bioinformatics Resources were applied to analyse the functional enrichment of these targets and co-expressed genes. Results: A total of 4004 CpG sites of miRNA and 11,259 CpG sites of lncRNA were screened. Among these CpG sites, 8 CpG sites of miRNA and 7 CpG sites of lncRNA were found with regression coefficients. By multiplying the sum of methylation degrees of the selected CpGs with these coefficients, two methylation-based classifiers were constructed. The classifiers have shown good performance in predicting the survival rate of PAC patients at varying follow-up times. Interestingly, both of these two classifiers were predominant and independent factors for OS. Furthermore, functional enrichment analysis demonstrated that aberrantly methylated miRNAs and lncRNAs are related to calcium ion transmembrane transport and MAPK, Ras and calcium signalling pathways. Conclusion: In the present study, we identified two methylation-based classifiers of ncRNA associated with OS in PAC patients through a comprehensive analysis of miRNA and lncRNA profiles. We are the first group to demonstrate a relationship between the aberrant DNA methylation of ncRNAs and the prognosis of PAC, and this relationship would contribute to individualized PAC therapy."
0,Establishment and validation of a novel survival prediction scoring algorithm for patients with non-small-cell lung cancer spinal metastasis,"Background: This study was to develop an algorithm capable of predicting the survival of patients with NSCLC spinal metastasis for individualized therapy. Methods: We identified 176 consecutive patients with NSCLC spinal metastasis between 2006 and 2017. Twenty-four features, including age, gender, smoking, KPS, paralysis, histological subtype, tumor stage, surgery, EGFR status, CEA, CA125, CA19-9, NSE, SCC, CYFRA21-1, calcium, AKP, albumin, the number of spinal, extra-spinal bone and visceral metastasis, time to metastasis, pathological fracture, and primary or secondary metastasis, were retrospectively analyzed. Features associated with survival in the multivariate analyses were included in a scoring model, which was prospectively validated in another 63 patients (NCT03363685). Results: The median follow-up period was 12.00Â months (interquartile range 6.00â€“23.40Â months). One hundred forty-seven patients died during follow-up, with a median survival of 13.6Â months being observed. Multivariate analysis revealed that the following features were associated with survival: age, smoking, CA125, SCC, KPS, and EGFR status. A scoring system based on these features was created to stratify patients into low-risk (0â€“3), intermediate-risk (4â€“6) and high-risk (7â€“10) groups, whose estimated median survival times 29.10, 10.40 and 3.90Â months, respectively. The Harrellâ€™s c-index was 0.72. Model validation supported this modelâ€™s validity and reproducibility. Conclusions: In patients with NSCLC spinal metastasis, survival was associated with age, smoking, CA125, SCC, KPS, and EGFR status. A validated scoring system based on these features was devised that can predict the survival times of those patients. This scoring system provides a basis for applying the NOMS framework and for facilitating individual treatment.","Establishment and validation of a novel survival prediction scoring algorithm for patients with non-small-cell lung cancer spinal metastasis. Background: This study was to develop an algorithm capable of predicting the survival of patients with NSCLC spinal metastasis for individualized therapy. Methods: We identified 176 consecutive patients with NSCLC spinal metastasis between 2006 and 2017. Twenty-four features, including age, gender, smoking, KPS, paralysis, histological subtype, tumor stage, surgery, EGFR status, CEA, CA125, CA19-9, NSE, SCC, CYFRA21-1, calcium, AKP, albumin, the number of spinal, extra-spinal bone and visceral metastasis, time to metastasis, pathological fracture, and primary or secondary metastasis, were retrospectively analyzed. Features associated with survival in the multivariate analyses were included in a scoring model, which was prospectively validated in another 63 patients (NCT03363685). Results: The median follow-up period was 12.00Â months (interquartile range 6.00â€“23.40Â months). One hundred forty-seven patients died during follow-up, with a median survival of 13.6Â months being observed. Multivariate analysis revealed that the following features were associated with survival: age, smoking, CA125, SCC, KPS, and EGFR status. A scoring system based on these features was created to stratify patients into low-risk (0â€“3), intermediate-risk (4â€“6) and high-risk (7â€“10) groups, whose estimated median survival times 29.10, 10.40 and 3.90Â months, respectively. The Harrellâ€™s c-index was 0.72. Model validation supported this modelâ€™s validity and reproducibility. Conclusions: In patients with NSCLC spinal metastasis, survival was associated with age, smoking, CA125, SCC, KPS, and EGFR status. A validated scoring system based on these features was devised that can predict the survival times of those patients. This scoring system provides a basis for applying the NOMS framework and for facilitating individual treatment."
0,Algorithmic approach to management of acute ocular chemical injuries-I's and E's of Management,"Ocular chemical injuries are associated with significant morbidity leading to vision loss and ocular surface damage. Appropriate management and intervention in the acute stage dictates the final outcome as well as the prognosis for visual rehabilitative procedures in chronic stage. Classifying the parameters to be addressed in the acute stage and providing an algorithmic approach for managing the alterations in each of them will facilitate the primary goal of ensuring epithelialization of the ocular surface. Broadly categorizing them into the I's and E's (inciting agent, inflammation, epithelial defect, ischemia, exposure and intraocular pressure) and treating each will directly and/or indirectly influence re-epithelialization of the ocular surface, which in turn will reduce or prevent the various detrimental sequelae of ocular chemical injury.","Algorithmic approach to management of acute ocular chemical injuries-I's and E's of Management. Ocular chemical injuries are associated with significant morbidity leading to vision loss and ocular surface damage. Appropriate management and intervention in the acute stage dictates the final outcome as well as the prognosis for visual rehabilitative procedures in chronic stage. Classifying the parameters to be addressed in the acute stage and providing an algorithmic approach for managing the alterations in each of them will facilitate the primary goal of ensuring epithelialization of the ocular surface. Broadly categorizing them into the I's and E's (inciting agent, inflammation, epithelial defect, ischemia, exposure and intraocular pressure) and treating each will directly and/or indirectly influence re-epithelialization of the ocular surface, which in turn will reduce or prevent the various detrimental sequelae of ocular chemical injury."
0,Precise temporal memories are supported by the lateral entorhinal cortex in humans,,
0,Molecular mechanisms of lineage decisions in metabolite-specific T cells,"Mucosal-associated invariant T cells (MAIT cells) recognize the microbial metabolite 5-(2-oxopropylideneamino)-6-d-ribitylaminouracil (5-OP-RU) presented by the MHC class Ib molecule, MR1. MAIT cells acquire effector functions during thymic development, but the mechanisms involved are unclear. Here we used single-cell RNA-sequencing to characterize the developmental path of 5-OP-RU-specific thymocytes. In addition to the known MAIT1 and MAIT17 effector subsets selected on bone-marrow-derived hematopoietic cells, we identified 5-OP-RU-specific thymocytes that were selected on thymic epithelial cells and differentiated into CD44âˆ’ naive T cells. MAIT cell positive selection required signaling through the adapter, SAP, that controlled the expression of the transcription factor, ZBTB16. Pseudotemporal ordering of single cells revealed transcriptional trajectories of 5-OP-RU-specific thymocytes selected on either thymic epithelial cells or hematopoietic cells. The resulting model illustrates T cell lineage decisions.","Molecular mechanisms of lineage decisions in metabolite-specific T cells. Mucosal-associated invariant T cells (MAIT cells) recognize the microbial metabolite 5-(2-oxopropylideneamino)-6-d-ribitylaminouracil (5-OP-RU) presented by the MHC class Ib molecule, MR1. MAIT cells acquire effector functions during thymic development, but the mechanisms involved are unclear. Here we used single-cell RNA-sequencing to characterize the developmental path of 5-OP-RU-specific thymocytes. In addition to the known MAIT1 and MAIT17 effector subsets selected on bone-marrow-derived hematopoietic cells, we identified 5-OP-RU-specific thymocytes that were selected on thymic epithelial cells and differentiated into CD44âˆ’ naive T cells. MAIT cell positive selection required signaling through the adapter, SAP, that controlled the expression of the transcription factor, ZBTB16. Pseudotemporal ordering of single cells revealed transcriptional trajectories of 5-OP-RU-specific thymocytes selected on either thymic epithelial cells or hematopoietic cells. The resulting model illustrates T cell lineage decisions."
0,Roles of axon guidance molecules in neuronal wiring in the developing spinal cord,,
0,Heterotypic docking compatibility of human connexin37 with other vascular connexins,"Human vascular connexins (Cx37, Cx40, Cx43, and Cx45) can form various types of gap junction channels to synchronize vasodilation/constriction to control local circulation. Most of our knowledge on heterotypic gap junctions of these vascular connexins was from studies on rodent connexins. In human vasculature, the same four homolog connexins exist, but whether these human connexins can form heterotypic GJs as those of rodents have not been fully studied. Here we used in vitro expression system to study the coupling status and GJ channel properties of human heterotypic Cx37/Cx40, Cx37/Cx43, and Cx37/Cx45 GJs. Our results showed that Cx37/Cx43 and Cx37/Cx45 GJs, but not Cx37/Cx40 GJs, were functional and each with unique rectifying channel properties. The failure of docking between Cx37 and Cx40 could be rescued by designed Cx40 variants. Characterization of the heterotypic Cx37/Cx43 and Cx37/Cx45 GJs may help us in understanding the intercellular communication at the myoendothelial junction.","Heterotypic docking compatibility of human connexin37 with other vascular connexins. Human vascular connexins (Cx37, Cx40, Cx43, and Cx45) can form various types of gap junction channels to synchronize vasodilation/constriction to control local circulation. Most of our knowledge on heterotypic gap junctions of these vascular connexins was from studies on rodent connexins. In human vasculature, the same four homolog connexins exist, but whether these human connexins can form heterotypic GJs as those of rodents have not been fully studied. Here we used in vitro expression system to study the coupling status and GJ channel properties of human heterotypic Cx37/Cx40, Cx37/Cx43, and Cx37/Cx45 GJs. Our results showed that Cx37/Cx43 and Cx37/Cx45 GJs, but not Cx37/Cx40 GJs, were functional and each with unique rectifying channel properties. The failure of docking between Cx37 and Cx40 could be rescued by designed Cx40 variants. Characterization of the heterotypic Cx37/Cx43 and Cx37/Cx45 GJs may help us in understanding the intercellular communication at the myoendothelial junction."
0,An in silico pharmacological approach toward the discovery of potent inhibitors to combat drug resistance HIV-1 protease variants,"Protease inhibitors (PIs) are crucial drugs in highly active antiretroviral therapy for human immunodeficiency virus-1 (HIV-1) infections. However, resistance owing to mutations challenge the long-term efficacy in the medication of HIV-1-infected individuals. Lopinavir (LPV) and darunavir (DRV), two second-generation drugs are the most potent among PIs, hustling the drug resistance when mutations occur in the active and nonactive site of the protease (PR). Herein, we strive for compounds that can stifle the function of wild-type (WT) HIV-1 PR along with four major single mutants (I54M, V82T, I84V, and L90M) instigating resistance to the PIs using in silico approach. Six common compounds are retrieved from six databases using combined pharmacophore-based and structure-based virtual screening methodology. LPV and DRV are docked and the binding free energy is calculated to set the cut-off value for selecting compounds. Further, to gain insight into the stability of the complexes the molecular dynamics simulation (MDS) is carried out, which uncovers two lead molecules namely NCI-524545 and ZINC12866729. Both the lead molecules connect with WT and mutant HIV-1 PRs through strong and stable hydrogen bond interactions when compared with LPV and DRV throughout the trajectory analysis. Interestingly, NCI-524545 and ZINC12866729 exhibit direct interactions with I50/50â€² by replacing the conserved water molecule as evidenced by MDS, which indicates the credible potency of these compounds. Hence, weÂ concluded that NCI-524545 and ZINC12866729 have great puissant to restrain the role of drug resistance HIV-1 PR variants, which can also show better activity through in vivo and in vitro conditions.","An in silico pharmacological approach toward the discovery of potent inhibitors to combat drug resistance HIV-1 protease variants. Protease inhibitors (PIs) are crucial drugs in highly active antiretroviral therapy for human immunodeficiency virus-1 (HIV-1) infections. However, resistance owing to mutations challenge the long-term efficacy in the medication of HIV-1-infected individuals. Lopinavir (LPV) and darunavir (DRV), two second-generation drugs are the most potent among PIs, hustling the drug resistance when mutations occur in the active and nonactive site of the protease (PR). Herein, we strive for compounds that can stifle the function of wild-type (WT) HIV-1 PR along with four major single mutants (I54M, V82T, I84V, and L90M) instigating resistance to the PIs using in silico approach. Six common compounds are retrieved from six databases using combined pharmacophore-based and structure-based virtual screening methodology. LPV and DRV are docked and the binding free energy is calculated to set the cut-off value for selecting compounds. Further, to gain insight into the stability of the complexes the molecular dynamics simulation (MDS) is carried out, which uncovers two lead molecules namely NCI-524545 and ZINC12866729. Both the lead molecules connect with WT and mutant HIV-1 PRs through strong and stable hydrogen bond interactions when compared with LPV and DRV throughout the trajectory analysis. Interestingly, NCI-524545 and ZINC12866729 exhibit direct interactions with I50/50â€² by replacing the conserved water molecule as evidenced by MDS, which indicates the credible potency of these compounds. Hence, weÂ concluded that NCI-524545 and ZINC12866729 have great puissant to restrain the role of drug resistance HIV-1 PR variants, which can also show better activity through in vivo and in vitro conditions."
0,How much is spent on mental health research: developing a system for categorising grant funding in the UK,,
0,Dolutegravir-Based or Low-Dose Efavirenz-Based Regimen for the Treatment of HIV-1,,
0,"Laparoscopic supracervical hysterectomy versus endometrial ablation for women with heavy menstrual bleeding (HEALTH): a parallel-group, open-label, randomised controlled trial","Background: Heavy menstrual bleeding affects 25% of women in the UK, many of whom require surgery to treat it. Hysterectomy is effective but has more complications than endometrial ablation, which is less invasive but ultimately leads to hysterectomy in 20% of women. We compared laparoscopic supracervical hysterectomy with endometrial ablation in women seeking surgical treatment for heavy menstrual bleeding. Methods: In this parallel-group, multicentre, open-label, randomised controlled trial in 31 hospitals in the UK, women younger than 50 years who were referred to a gynaecologist for surgical treatment of heavy menstrual bleeding and who were eligible for endometrial ablation were randomly allocated (1:1) to either laparoscopic supracervical hysterectomy or second generation endometrial ablation. Women were randomly assigned by either an interactive voice response telephone system or an internet-based application with a minimisation algorithm based on centre and age group (<40 years vs â‰¥40 years). Laparoscopic supracervical hysterectomy involves laparoscopic (keyhole) surgery to remove the upper part of the uterus (the body) containing the endometrium. Endometrial ablation aims to treat heavy menstrual bleeding by destroying the endometrium, which is responsible for heavy periods. The co-primary clinical outcomes were patient satisfaction and condition-specific quality of life, measured with the menorrhagia multi-attribute quality of life scale (MMAS), assessed at 15 months after randomisation. Our analysis was based on the intention-to-treat principle. The trial was registered with the ISRCTN registry, number ISRCTN49013893. Findings: Between May 21, 2014, and March 28, 2017, we enrolled and randomly assigned 660 women (330 in each group). 616 (93%) of 660 women were operated on within the study period, 588 (95%) of whom received the allocated procedure and 28 (5%) of whom had an alternative surgery. At 15 months after randomisation, more women allocated to laparoscopic supracervical hysterectomy were satisfied with their operation compared with those in the endometrial ablation group (270 [97%] of 278 women vs 244 [87%] of 280 women; adjusted percentage difference 9Â·8, 95% CI 5Â·1â€“14Â·5; adjusted odds ratio [OR] 2Â·53, 95% CI 1Â·83â€“3Â·48; p<0Â·0001). Women randomly assigned to laparoscopic supracervical hysterectomy were also more likely to have the best possible MMAS score of 100 than women assigned to endometrial ablation (180 [69%] of 262 women vs 146 [54%] of 268 women; adjusted percentage difference 13Â·3, 95% CI 3Â·8â€“22Â·8; adjusted OR 1Â·87, 95% CI 1Â·31â€“2Â·67; p=0Â·00058). 14 (5%) of 309 women in the laparoscopic supracervical hysterectomy group and 11 (4%) of 307 women in the endometrial ablation group had at least one serious adverse event (adjusted OR 1Â·30, 95% CI 0Â·56â€“3Â·02; p=0Â·54). Interpretation: Laparoscopic supracervical hysterectomy is superior to endometrial ablation in terms of clinical effectiveness and has a similar proportion of complications, but takes longer to perform and is associated with a longer recovery. Funding: UK National Institute for Health Research Health Technology Assessment Programme.","Laparoscopic supracervical hysterectomy versus endometrial ablation for women with heavy menstrual bleeding (HEALTH): a parallel-group, open-label, randomised controlled trial. Background: Heavy menstrual bleeding affects 25% of women in the UK, many of whom require surgery to treat it. Hysterectomy is effective but has more complications than endometrial ablation, which is less invasive but ultimately leads to hysterectomy in 20% of women. We compared laparoscopic supracervical hysterectomy with endometrial ablation in women seeking surgical treatment for heavy menstrual bleeding. Methods: In this parallel-group, multicentre, open-label, randomised controlled trial in 31 hospitals in the UK, women younger than 50 years who were referred to a gynaecologist for surgical treatment of heavy menstrual bleeding and who were eligible for endometrial ablation were randomly allocated (1:1) to either laparoscopic supracervical hysterectomy or second generation endometrial ablation. Women were randomly assigned by either an interactive voice response telephone system or an internet-based application with a minimisation algorithm based on centre and age group (<40 years vs â‰¥40 years). Laparoscopic supracervical hysterectomy involves laparoscopic (keyhole) surgery to remove the upper part of the uterus (the body) containing the endometrium. Endometrial ablation aims to treat heavy menstrual bleeding by destroying the endometrium, which is responsible for heavy periods. The co-primary clinical outcomes were patient satisfaction and condition-specific quality of life, measured with the menorrhagia multi-attribute quality of life scale (MMAS), assessed at 15 months after randomisation. Our analysis was based on the intention-to-treat principle. The trial was registered with the ISRCTN registry, number ISRCTN49013893. Findings: Between May 21, 2014, and March 28, 2017, we enrolled and randomly assigned 660 women (330 in each group). 616 (93%) of 660 women were operated on within the study period, 588 (95%) of whom received the allocated procedure and 28 (5%) of whom had an alternative surgery. At 15 months after randomisation, more women allocated to laparoscopic supracervical hysterectomy were satisfied with their operation compared with those in the endometrial ablation group (270 [97%] of 278 women vs 244 [87%] of 280 women; adjusted percentage difference 9Â·8, 95% CI 5Â·1â€“14Â·5; adjusted odds ratio [OR] 2Â·53, 95% CI 1Â·83â€“3Â·48; p<0Â·0001). Women randomly assigned to laparoscopic supracervical hysterectomy were also more likely to have the best possible MMAS score of 100 than women assigned to endometrial ablation (180 [69%] of 262 women vs 146 [54%] of 268 women; adjusted percentage difference 13Â·3, 95% CI 3Â·8â€“22Â·8; adjusted OR 1Â·87, 95% CI 1Â·31â€“2Â·67; p=0Â·00058). 14 (5%) of 309 women in the laparoscopic supracervical hysterectomy group and 11 (4%) of 307 women in the endometrial ablation group had at least one serious adverse event (adjusted OR 1Â·30, 95% CI 0Â·56â€“3Â·02; p=0Â·54). Interpretation: Laparoscopic supracervical hysterectomy is superior to endometrial ablation in terms of clinical effectiveness and has a similar proportion of complications, but takes longer to perform and is associated with a longer recovery. Funding: UK National Institute for Health Research Health Technology Assessment Programme."
0,Current approaches to identify sections within clinical narratives from electronic health records: a systematic review,"BACKGROUND: The identification of sections in narrative content of Electronic Health Records (EHR) has demonstrated to improve the performance of clinical extraction tasks; however, there is not yet a shared understanding of the concept and its existing methods. The objective is to report the results of a systematic review concerning approaches aimed at identifying sections in narrative content of EHR, using both automatic or semi-automatic methods. METHODS: This review includes articles from the databases: SCOPUS, Web of Science and PubMed (from January 1994 to September 2018). The selection of studies was done using predefined eligibility criteria and applying the PRISMA recommendations. Search criteria were elaborated by using an iterative and collaborative keyword enrichment. RESULTS: Following the eligibility criteria, 39 studies were selected for analysis. The section identification approaches proposed by these studies vary greatly depending on the kind of narrative, the type of section, and the application. We observed that 57% of them proposed formal methods for identifying sections and 43% adapted a previously created method. Seventy-eight percent were intended for English texts and 41% for discharge summaries. Studies that are able to identify explicit (with headings) and implicit sections correspond to 46%. Regarding the level of granularity, 54% of the studies are able to identify sections, but not subsections. From the technical point of view, the methods can be classified into rule-based methods (59%), machine learning methods (22%) and a combination of both (19%). Hybrid methods showed better results than those relying on pure machine learning approaches, but lower than rule-based methods; however, their scope was more ambitious than the latter ones. Despite all the promising performance results, very few studies reported tests under a formal setup. Almost all the studies relied on custom dictionaries; however, they used them in conjunction with a controlled terminology, most commonly the UMLSâ“‡ metathesaurus. CONCLUSIONS: Identification of sections in EHR narratives is gaining popularity for improving clinical extraction projects. This study enabled the community working on clinical NLP to gain a formal analysis of this task, including the most successful ways to perform it.","Current approaches to identify sections within clinical narratives from electronic health records: a systematic review. BACKGROUND: The identification of sections in narrative content of Electronic Health Records (EHR) has demonstrated to improve the performance of clinical extraction tasks; however, there is not yet a shared understanding of the concept and its existing methods. The objective is to report the results of a systematic review concerning approaches aimed at identifying sections in narrative content of EHR, using both automatic or semi-automatic methods. METHODS: This review includes articles from the databases: SCOPUS, Web of Science and PubMed (from January 1994 to September 2018). The selection of studies was done using predefined eligibility criteria and applying the PRISMA recommendations. Search criteria were elaborated by using an iterative and collaborative keyword enrichment. RESULTS: Following the eligibility criteria, 39 studies were selected for analysis. The section identification approaches proposed by these studies vary greatly depending on the kind of narrative, the type of section, and the application. We observed that 57% of them proposed formal methods for identifying sections and 43% adapted a previously created method. Seventy-eight percent were intended for English texts and 41% for discharge summaries. Studies that are able to identify explicit (with headings) and implicit sections correspond to 46%. Regarding the level of granularity, 54% of the studies are able to identify sections, but not subsections. From the technical point of view, the methods can be classified into rule-based methods (59%), machine learning methods (22%) and a combination of both (19%). Hybrid methods showed better results than those relying on pure machine learning approaches, but lower than rule-based methods; however, their scope was more ambitious than the latter ones. Despite all the promising performance results, very few studies reported tests under a formal setup. Almost all the studies relied on custom dictionaries; however, they used them in conjunction with a controlled terminology, most commonly the UMLSâ“‡ metathesaurus. CONCLUSIONS: Identification of sections in EHR narratives is gaining popularity for improving clinical extraction projects. This study enabled the community working on clinical NLP to gain a formal analysis of this task, including the most successful ways to perform it."
0,Identifying Extrinsic versus Intrinsic Drivers of Variation in Cell Behavior in Human iPSC Lines from Healthy Donors,"Large cohorts of human induced pluripotent stem cells (iPSCs) from healthy donors are a potentially powerful tool for investigating the relationship between genetic variants and cellular behavior. Here, we integrate high content imaging of cell shape, proliferation, and other phenotypes with gene expression and DNA sequence datasets from over 100 human iPSC lines. By applying a dimensionality reduction approach, Probabilistic Estimation of Expression Residuals (PEER), we extracted factors that captured the effects of intrinsic (genetic concordance between different cell lines from the same donor) and extrinsic (cell responses to different fibronectin concentrations) conditions. We identify genes that correlate in expression with intrinsic and extrinsic PEER factors and associate outlier cell behavior with genes containing rare deleterious non-synonymous SNVs. Our study, thus, establishes a strategy for examining the genetic basis of inter-individual variability in cell behavior. Cell behavior reflects both the intrinsic state of the cell and extrinsic signals it receives from its microenvironment. By integrating genomic, gene expression, and cell biology datasets from a large number of human iPSCs from healthy donors, Vigilante et al. show how genetic variation contributes to phenotypic variation.","Identifying Extrinsic versus Intrinsic Drivers of Variation in Cell Behavior in Human iPSC Lines from Healthy Donors. Large cohorts of human induced pluripotent stem cells (iPSCs) from healthy donors are a potentially powerful tool for investigating the relationship between genetic variants and cellular behavior. Here, we integrate high content imaging of cell shape, proliferation, and other phenotypes with gene expression and DNA sequence datasets from over 100 human iPSC lines. By applying a dimensionality reduction approach, Probabilistic Estimation of Expression Residuals (PEER), we extracted factors that captured the effects of intrinsic (genetic concordance between different cell lines from the same donor) and extrinsic (cell responses to different fibronectin concentrations) conditions. We identify genes that correlate in expression with intrinsic and extrinsic PEER factors and associate outlier cell behavior with genes containing rare deleterious non-synonymous SNVs. Our study, thus, establishes a strategy for examining the genetic basis of inter-individual variability in cell behavior. Cell behavior reflects both the intrinsic state of the cell and extrinsic signals it receives from its microenvironment. By integrating genomic, gene expression, and cell biology datasets from a large number of human iPSCs from healthy donors, Vigilante et al. show how genetic variation contributes to phenotypic variation."
0,Improved cell composition deconvolution method of bulk gene expression profiles to quantify subsets of immune cells,"Background: To facilitate the investigation of the pathogenic roles played by various immune cells in complex tissues such as tumors, a few computational methods for deconvoluting bulk gene expression profiles to predict cell composition have been created. However, available methods were usually developed along with a set of reference gene expression profiles consisting of imbalanced replicates across different cell types. Therefore, the objective of this study was to create a new deconvolution method equipped with a new set of reference gene expression profiles that incorporate more microarray replicates of the immune cells that have been frequently implicated in the poor prognosis of cancers, such as T helper cells, regulatory T cells and macrophage M1/M2 cells. Methods: Our deconvolution method was developed by choosing Ïµ-support vector regression (Ïµ-SVR) as the core algorithm assigned with a loss function subject to the L1-norm penalty. To construct the reference gene expression signature matrix for regression, a subset of differentially expressed genes were chosen from 148 microarray-based gene expression profiles for 9 types of immune cells by using ANOVA and minimizing condition number. Agreement analyses including mean absolute percentage errors and Bland-Altman plots were carried out to compare the performances of our method and CIBERSORT. Results: In silico cell mixtures, simulated bulk tissues, and real human samples with known immune-cell fractions were used as the test datasets for benchmarking. Our method outperformed CIBERSORT in the benchmarks using in silico breast tissue-immune cell mixtures in the proportions of 30:70 and 50:50, and in the benchmark using 164 human PBMC samples. Our results suggest that the performance of our method was at least comparable to that of a state-of-the-art tool, CIBERSORT. Conclusions: We developed a new cell composition deconvolution method and the implementation was entirely based on the publicly available R and Python packages. In addition, we compiled a new set of reference gene expression profiles, which might allow for a more robust prediction of the immune cell fractions from the expression profiles of cell mixtures. The source code of our method could be downloaded from https://github.com/holiday01/deconvolution-to-estimate-immune-cell-subsets.","Improved cell composition deconvolution method of bulk gene expression profiles to quantify subsets of immune cells. Background: To facilitate the investigation of the pathogenic roles played by various immune cells in complex tissues such as tumors, a few computational methods for deconvoluting bulk gene expression profiles to predict cell composition have been created. However, available methods were usually developed along with a set of reference gene expression profiles consisting of imbalanced replicates across different cell types. Therefore, the objective of this study was to create a new deconvolution method equipped with a new set of reference gene expression profiles that incorporate more microarray replicates of the immune cells that have been frequently implicated in the poor prognosis of cancers, such as T helper cells, regulatory T cells and macrophage M1/M2 cells. Methods: Our deconvolution method was developed by choosing Ïµ-support vector regression (Ïµ-SVR) as the core algorithm assigned with a loss function subject to the L1-norm penalty. To construct the reference gene expression signature matrix for regression, a subset of differentially expressed genes were chosen from 148 microarray-based gene expression profiles for 9 types of immune cells by using ANOVA and minimizing condition number. Agreement analyses including mean absolute percentage errors and Bland-Altman plots were carried out to compare the performances of our method and CIBERSORT. Results: In silico cell mixtures, simulated bulk tissues, and real human samples with known immune-cell fractions were used as the test datasets for benchmarking. Our method outperformed CIBERSORT in the benchmarks using in silico breast tissue-immune cell mixtures in the proportions of 30:70 and 50:50, and in the benchmark using 164 human PBMC samples. Our results suggest that the performance of our method was at least comparable to that of a state-of-the-art tool, CIBERSORT. Conclusions: We developed a new cell composition deconvolution method and the implementation was entirely based on the publicly available R and Python packages. In addition, we compiled a new set of reference gene expression profiles, which might allow for a more robust prediction of the immune cell fractions from the expression profiles of cell mixtures. The source code of our method could be downloaded from https://github.com/holiday01/deconvolution-to-estimate-immune-cell-subsets."
0,EBV microRNA-BHRF1-2-5p targets the 39UTR of immune checkpoint ligands PD-L1 and PD-L2,"Epstein-Barr virus-positive (EBV1) diffuse large B-cell lymphomas (DLBCLs) express high levels of programmed death ligand 1 (PD-L1) and PD-L2. MicroRNA (miR) regulation is an important mechanism for the fine-tuning of gene expression via 39-untranslated region (39UTR) targeting, and we have previously demonstrated strong EBV miR expression in EBV1 DLBCL. Whereas the EBV latent membrane protein-1 (LMP1) is known to induce PD-L1/L2, a potential counterregulatory role of EBV miR in the fine-tuning of PD-L1/L2 expression remains to be established. To examine this, a novel in vitro model of EBV1 DLBCL was developed, using the viral strain EBV WIL, which unlike common laboratory strains retains intact noncoding regions where several EBV miRs reside. This enabled interrogation of the relationship among EBV latency genes, cell of origin (COO), PD-L1, PD-L2, and EBV miRs. The model successfully recapitulated the full spectrum of B-cell differentiation, with 4 discrete COO phases: early and late germinal center B cells (GCBs) and early and late activated B cells (ABCs). Interestingly, PD-L1/L2 levels increased markedly during transition from late GCB to early ABC phase, after LMP1 upregulation. EBV miR-BamHI fragment H rightward open reading frame 1 (BHRF1)-2-5p clustered apart from other EBV miRs, rising during late GCB phase. Bioinformatic prediction, together with functional validation, confirmed EBV miR-BHRF1-2-5p bound to PD-L1 and PD-L2 39UTRs to reduce PD-L1/L2 surface protein expression. Results indicate a novel mechanism by which EBV miR-BHRF1-2-5p plays a context-dependent counterregulatory role to fine-tune the expression of the LMP1-driven amplification of these inhibitory checkpoint ligands. Further identification of immune checkpoint-targeting miRs may enable potential novel RNA-based therapies to emerge.","EBV microRNA-BHRF1-2-5p targets the 39UTR of immune checkpoint ligands PD-L1 and PD-L2. Epstein-Barr virus-positive (EBV1) diffuse large B-cell lymphomas (DLBCLs) express high levels of programmed death ligand 1 (PD-L1) and PD-L2. MicroRNA (miR) regulation is an important mechanism for the fine-tuning of gene expression via 39-untranslated region (39UTR) targeting, and we have previously demonstrated strong EBV miR expression in EBV1 DLBCL. Whereas the EBV latent membrane protein-1 (LMP1) is known to induce PD-L1/L2, a potential counterregulatory role of EBV miR in the fine-tuning of PD-L1/L2 expression remains to be established. To examine this, a novel in vitro model of EBV1 DLBCL was developed, using the viral strain EBV WIL, which unlike common laboratory strains retains intact noncoding regions where several EBV miRs reside. This enabled interrogation of the relationship among EBV latency genes, cell of origin (COO), PD-L1, PD-L2, and EBV miRs. The model successfully recapitulated the full spectrum of B-cell differentiation, with 4 discrete COO phases: early and late germinal center B cells (GCBs) and early and late activated B cells (ABCs). Interestingly, PD-L1/L2 levels increased markedly during transition from late GCB to early ABC phase, after LMP1 upregulation. EBV miR-BamHI fragment H rightward open reading frame 1 (BHRF1)-2-5p clustered apart from other EBV miRs, rising during late GCB phase. Bioinformatic prediction, together with functional validation, confirmed EBV miR-BHRF1-2-5p bound to PD-L1 and PD-L2 39UTRs to reduce PD-L1/L2 surface protein expression. Results indicate a novel mechanism by which EBV miR-BHRF1-2-5p plays a context-dependent counterregulatory role to fine-tune the expression of the LMP1-driven amplification of these inhibitory checkpoint ligands. Further identification of immune checkpoint-targeting miRs may enable potential novel RNA-based therapies to emerge."
0,Multiple-correlation similarity for block-matching based fast CT to ultrasound registration in liver interventions,"In this work we present a fast approach to perform registration of computed tomography to ultrasound volumes for image guided intervention applications. The method is based on a combination of block-matching and outlier rejection. The block-matching uses a correlation based multimodal similarity metric, where the intensity and the gradient of the computed tomography images along with the ultrasound volumes are the input images to find correspondences between blocks in the computed tomography and the ultrasound volumes. A variance and octree based feature point-set selection method is used for selecting distinct and evenly spread point locations for block-matching. Geometric consistency and smoothness criteria are imposed in an outlier rejection step to refine the block-matching results. The block-matching results after outlier rejection are used to determine the affine transformation between the computed tomography and the ultrasound volumes. Various experiments are carried out to assess the optimal performance and the influence of parameters on accuracy and computational time of the registration. A leave-one-patient-out cross-validation registration error of 3.6 mm is achieved over 29 datasets, acquired from 17 patients.","Multiple-correlation similarity for block-matching based fast CT to ultrasound registration in liver interventions. In this work we present a fast approach to perform registration of computed tomography to ultrasound volumes for image guided intervention applications. The method is based on a combination of block-matching and outlier rejection. The block-matching uses a correlation based multimodal similarity metric, where the intensity and the gradient of the computed tomography images along with the ultrasound volumes are the input images to find correspondences between blocks in the computed tomography and the ultrasound volumes. A variance and octree based feature point-set selection method is used for selecting distinct and evenly spread point locations for block-matching. Geometric consistency and smoothness criteria are imposed in an outlier rejection step to refine the block-matching results. The block-matching results after outlier rejection are used to determine the affine transformation between the computed tomography and the ultrasound volumes. Various experiments are carried out to assess the optimal performance and the influence of parameters on accuracy and computational time of the registration. A leave-one-patient-out cross-validation registration error of 3.6 mm is achieved over 29 datasets, acquired from 17 patients."
0,Hepatovirus 3ABC proteases and evolution of mitochondrial antiviral signaling protein (MAVS),,
0,Development of MAP4 Kinase Inhibitors as Motor Neuron-Protecting Agents,"Disease-causing mutations in many neurodegenerative disorders lead to proteinopathies that trigger endoplasmic reticulum (ER) stress. However, few therapeutic options exist for patients with these diseases. Using an in vitro screening platform to identify compounds that protect human motor neurons from ER stress-mediated degeneration, we discovered that compounds targeting the mitogen-activated protein kinase kinase kinase kinase (MAP4K) family are neuroprotective. The kinase inhibitor URMC-099 (compound 1) stood out as a promising lead compound for further optimization. We coupled structure-based compound design with functional activity testing in neurons subjected to ER stress to develop a series of analogs with improved MAP4K inhibition and concomitant increases in potency and efficacy. Further structural modifications were performed to enhance the pharmacokinetic profiles of the compound 1 derivatives. Prostetin/12k emerged as an exceptionally potent, metabolically stable, and blood-brain barrier-penetrant compound that is well suited for future testing in animal models of neurodegeneration.","Development of MAP4 Kinase Inhibitors as Motor Neuron-Protecting Agents. Disease-causing mutations in many neurodegenerative disorders lead to proteinopathies that trigger endoplasmic reticulum (ER) stress. However, few therapeutic options exist for patients with these diseases. Using an in vitro screening platform to identify compounds that protect human motor neurons from ER stress-mediated degeneration, we discovered that compounds targeting the mitogen-activated protein kinase kinase kinase kinase (MAP4K) family are neuroprotective. The kinase inhibitor URMC-099 (compound 1) stood out as a promising lead compound for further optimization. We coupled structure-based compound design with functional activity testing in neurons subjected to ER stress to develop a series of analogs with improved MAP4K inhibition and concomitant increases in potency and efficacy. Further structural modifications were performed to enhance the pharmacokinetic profiles of the compound 1 derivatives. Prostetin/12k emerged as an exceptionally potent, metabolically stable, and blood-brain barrier-penetrant compound that is well suited for future testing in animal models of neurodegeneration."
0,Crystal Structure of the Human Cannabinoid Receptor CB2,The structure of the human cannabinoid receptor CB2 reveals how small molecules affect CB2 differently than CB1 and point to principles that could inform rational and selective drug design.,Crystal Structure of the Human Cannabinoid Receptor CB2. The structure of the human cannabinoid receptor CB2 reveals how small molecules affect CB2 differently than CB1 and point to principles that could inform rational and selective drug design.
0,Cortical pain processing in the rat anterior cingulate cortex and primary somatosensory cortex,"Pain is a complex multidimensional experience encompassing sensory-discriminative, affective-motivational and cognitive-emotional components mediated by different neural mechanisms. Investigations of neurophysiological signals from simultaneous recordings of two or more cortical circuits may reveal important circuit mechanisms on cortical pain processing. The anterior cingulate cortex (ACC) and primary somatosensory cortex (S1) represent two most important cortical circuits related to sensory and affective processing of pain. Here, we recorded in vivo extracellular activity of the ACC and S1 simultaneously from male adult Sprague-Dale rats (n = 5), while repetitive noxious laser stimulations were delivered to animalÃµs hindpaw during pain experiments. We identified spontaneous pain-like events based on stereotyped pain behaviors in rats. We further conducted systematic analyses of spike and local field potential (LFP) recordings from both ACC and S1 during evoked and spontaneous pain episodes. From LFP recordings, we found stronger phase-amplitude coupling (theta phase vs. gamma amplitude) in the S1 than the ACC (n = 10 sessions), in both evoked (p = 0.058) and spontaneous pain-like behaviors (p = 0.017, paired signed rank test). In addition, pain-modulated ACC and S1 neuronal firing correlated with the amplitude of stimulus-induced event-related potentials (ERPs) during evoked pain episodes. We further designed statistical and machine learning methods to detect pain signals by integrating ACC and S1 ensemble spikes and LFPs. Together, these results reveal differential coding roles between the ACC and S1 in cortical pain processing, as well as point to distinct neural mechanisms between evoked and putative spontaneous pain at both LFP and cellular levels.","Cortical pain processing in the rat anterior cingulate cortex and primary somatosensory cortex. Pain is a complex multidimensional experience encompassing sensory-discriminative, affective-motivational and cognitive-emotional components mediated by different neural mechanisms. Investigations of neurophysiological signals from simultaneous recordings of two or more cortical circuits may reveal important circuit mechanisms on cortical pain processing. The anterior cingulate cortex (ACC) and primary somatosensory cortex (S1) represent two most important cortical circuits related to sensory and affective processing of pain. Here, we recorded in vivo extracellular activity of the ACC and S1 simultaneously from male adult Sprague-Dale rats (n = 5), while repetitive noxious laser stimulations were delivered to animalÃµs hindpaw during pain experiments. We identified spontaneous pain-like events based on stereotyped pain behaviors in rats. We further conducted systematic analyses of spike and local field potential (LFP) recordings from both ACC and S1 during evoked and spontaneous pain episodes. From LFP recordings, we found stronger phase-amplitude coupling (theta phase vs. gamma amplitude) in the S1 than the ACC (n = 10 sessions), in both evoked (p = 0.058) and spontaneous pain-like behaviors (p = 0.017, paired signed rank test). In addition, pain-modulated ACC and S1 neuronal firing correlated with the amplitude of stimulus-induced event-related potentials (ERPs) during evoked pain episodes. We further designed statistical and machine learning methods to detect pain signals by integrating ACC and S1 ensemble spikes and LFPs. Together, these results reveal differential coding roles between the ACC and S1 in cortical pain processing, as well as point to distinct neural mechanisms between evoked and putative spontaneous pain at both LFP and cellular levels."
0,A comparison of machine learning classifiers for dementia with Lewy bodies using miRNA expression data,"BACKGROUND: Dementia with Lewy bodies (DLB) is the second most common subtype of neurodegenerative dementia in humans following Alzheimer's disease (AD). Present clinical diagnosis of DLB has high specificity and low sensitivity and finding potential biomarkers of prodromal DLB is still challenging. MicroRNAs (miRNAs) have recently received a lot of attention as a source of novel biomarkers. METHODS: In this study, using serum miRNA expression of 478 Japanese individuals, we investigated potential miRNA biomarkers and constructed an optimal risk prediction model based on several machine learning methods: penalized regression, random forest, support vector machine, and gradient boosting decision tree. RESULTS: The final risk prediction model, constructed via a gradient boosting decision tree using 180 miRNAs and two clinical features, achieved an accuracy of 0.829 on an independent test set. We further predicted candidate target genes from the miRNAs. Gene set enrichment analysis of the miRNA target genes revealed 6 functional genes included in the DHA signaling pathway associated with DLB pathology. Two of them were further supported by gene-based association studies using a large number of single nucleotide polymorphism markers (BCL2L1: Pâ€‰=â€‰0.012, PIK3R2: Pâ€‰=â€‰0.021). CONCLUSIONS: Our proposed prediction model provides an effective tool for DLB classification. Also, a gene-based association test of rare variants revealed that BCL2L1 and PIK3R2 were statistically significantly associated with DLB.","A comparison of machine learning classifiers for dementia with Lewy bodies using miRNA expression data. BACKGROUND: Dementia with Lewy bodies (DLB) is the second most common subtype of neurodegenerative dementia in humans following Alzheimer's disease (AD). Present clinical diagnosis of DLB has high specificity and low sensitivity and finding potential biomarkers of prodromal DLB is still challenging. MicroRNAs (miRNAs) have recently received a lot of attention as a source of novel biomarkers. METHODS: In this study, using serum miRNA expression of 478 Japanese individuals, we investigated potential miRNA biomarkers and constructed an optimal risk prediction model based on several machine learning methods: penalized regression, random forest, support vector machine, and gradient boosting decision tree. RESULTS: The final risk prediction model, constructed via a gradient boosting decision tree using 180 miRNAs and two clinical features, achieved an accuracy of 0.829 on an independent test set. We further predicted candidate target genes from the miRNAs. Gene set enrichment analysis of the miRNA target genes revealed 6 functional genes included in the DHA signaling pathway associated with DLB pathology. Two of them were further supported by gene-based association studies using a large number of single nucleotide polymorphism markers (BCL2L1: Pâ€‰=â€‰0.012, PIK3R2: Pâ€‰=â€‰0.021). CONCLUSIONS: Our proposed prediction model provides an effective tool for DLB classification. Also, a gene-based association test of rare variants revealed that BCL2L1 and PIK3R2 were statistically significantly associated with DLB."
1,The RSNA Pediatric Bone Age Machine Learning Challenge,,
1,Scoring of Coronary Artery Disease Characteristics on Coronary CT Angiograms by Using Machine Learning,"Background Coronary CT angiography contains prognostic information but the best method to extract these data remains unknown. Purpose To use machine learning to develop a model of vessel features to discriminate between patients with and without subsequent death or cardiovascular events. Performance was compared with that of conventional scores. Materials and Methods Coronary CT angiography was analyzed by radiologists into four features for each of 16 coronary segments. Four machine learning model types were explored. Five conventional vessel scores were computed for comparison including the Coronary Artery Disease Reporting and Data System (CAD-RADS) score. The National Death Index was retrospectively queried from January 2004 through December 2015. Outcomes were all-cause mortality, coronary heart disease deaths, and coronary deaths or nonfatal myocardial infarctions. Score performance was assessed by using area under the receiver operating characteristic curve (AUC). Results Between February 2004 and November 2009, 6892 patients (4452 men [mean age +/- standard deviation, 51 years +/- 11] and 2440 women [mean age, 57 years +/- 12]) underwent coronary CT angiography (median follow-up, 9.0 years; interquartile range, 8.2-9.8 years). There were 380 deaths of all causes, 70 patients died of coronary artery disease, and 43 patients reported nonfatal myocardial infarctions. For all-cause mortality, the AUC was 0.77 (95% confidence interval: 0.76, 0.77) for machine learning (k-nearest neighbors) versus 0.72 (95% confidence interval: 0.72, 0.72) for CAD-RADS (P < .001). For coronary artery heart disease deaths, AUC was 0.85 (95% confidence interval: 0.84, 0.85) for machine learning versus 0.79 (95% confidence interval: 0.78, 0.80) for CAD-RADS (P < .001). When deciding whether to start statins, if the choice is made to tolerate treating 45 patients to be sure to include one patient who will later die of coronary disease, the use of the machine learning score ensures that 93% of patients with events will be administered the drug; if CAD-RADS is used, only 69% will be treated. Conclusion Compared with Coronary Artery Disease Reporting and Data System and other scores, machine learning methods better discriminated patients who subsequently experienced an adverse event from those who did not. (c) RSNA, 2019 Online supplemental material is available for this article. See also the editorial by Schoepf and Tesche in this issue.","Scoring of Coronary Artery Disease Characteristics on Coronary CT Angiograms by Using Machine Learning. Background Coronary CT angiography contains prognostic information but the best method to extract these data remains unknown. Purpose To use machine learning to develop a model of vessel features to discriminate between patients with and without subsequent death or cardiovascular events. Performance was compared with that of conventional scores. Materials and Methods Coronary CT angiography was analyzed by radiologists into four features for each of 16 coronary segments. Four machine learning model types were explored. Five conventional vessel scores were computed for comparison including the Coronary Artery Disease Reporting and Data System (CAD-RADS) score. The National Death Index was retrospectively queried from January 2004 through December 2015. Outcomes were all-cause mortality, coronary heart disease deaths, and coronary deaths or nonfatal myocardial infarctions. Score performance was assessed by using area under the receiver operating characteristic curve (AUC). Results Between February 2004 and November 2009, 6892 patients (4452 men [mean age +/- standard deviation, 51 years +/- 11] and 2440 women [mean age, 57 years +/- 12]) underwent coronary CT angiography (median follow-up, 9.0 years; interquartile range, 8.2-9.8 years). There were 380 deaths of all causes, 70 patients died of coronary artery disease, and 43 patients reported nonfatal myocardial infarctions. For all-cause mortality, the AUC was 0.77 (95% confidence interval: 0.76, 0.77) for machine learning (k-nearest neighbors) versus 0.72 (95% confidence interval: 0.72, 0.72) for CAD-RADS (P < .001). For coronary artery heart disease deaths, AUC was 0.85 (95% confidence interval: 0.84, 0.85) for machine learning versus 0.79 (95% confidence interval: 0.78, 0.80) for CAD-RADS (P < .001). When deciding whether to start statins, if the choice is made to tolerate treating 45 patients to be sure to include one patient who will later die of coronary disease, the use of the machine learning score ensures that 93% of patients with events will be administered the drug; if CAD-RADS is used, only 69% will be treated. Conclusion Compared with Coronary Artery Disease Reporting and Data System and other scores, machine learning methods better discriminated patients who subsequently experienced an adverse event from those who did not. (c) RSNA, 2019 Online supplemental material is available for this article. See also the editorial by Schoepf and Tesche in this issue."
1,Evaluation and accurate diagnoses of pediatric diseases using artificial intelligence,"Artificial intelligence (AI)-based methods have emerged as powerful tools to transform medical care. Although machine learning classifiers (MLCs) have already demonstrated strong performance in image-based diagnoses, analysis of diverse and massive electronic health record (EHR) data remains challenging. Here, we show that MLCs can query EHRs in a manner similar to the hypothetico-deductive reasoning used by physicians and unearth associations that previous statistical methods have not found. Our model applies an automated natural language processing system using deep learning techniques to extract clinically relevant information from EHRs. In total, 101.6 million data points from 1,362,559 pediatric patient visits presenting to a major referral center were analyzed to train and validate the framework. Our model demonstrates high diagnostic accuracy across multiple organ systems and is comparable to experienced pediatricians in diagnosing common childhood diseases. Our study provides a proof of concept for implementing an AI-based system as a means to aid physicians in tackling large amounts of data, augmenting diagnostic evaluations, and to provide clinical decision support in cases of diagnostic uncertainty or complexity. Although this impact may be most evident in areas where healthcare providers are in relative shortage, the benefits of such an AI system are likely to be universal.","Evaluation and accurate diagnoses of pediatric diseases using artificial intelligence. Artificial intelligence (AI)-based methods have emerged as powerful tools to transform medical care. Although machine learning classifiers (MLCs) have already demonstrated strong performance in image-based diagnoses, analysis of diverse and massive electronic health record (EHR) data remains challenging. Here, we show that MLCs can query EHRs in a manner similar to the hypothetico-deductive reasoning used by physicians and unearth associations that previous statistical methods have not found. Our model applies an automated natural language processing system using deep learning techniques to extract clinically relevant information from EHRs. In total, 101.6 million data points from 1,362,559 pediatric patient visits presenting to a major referral center were analyzed to train and validate the framework. Our model demonstrates high diagnostic accuracy across multiple organ systems and is comparable to experienced pediatricians in diagnosing common childhood diseases. Our study provides a proof of concept for implementing an AI-based system as a means to aid physicians in tackling large amounts of data, augmenting diagnostic evaluations, and to provide clinical decision support in cases of diagnostic uncertainty or complexity. Although this impact may be most evident in areas where healthcare providers are in relative shortage, the benefits of such an AI system are likely to be universal."
1,Predicting hospital-acquired pneumonia among schizophrenic patients: a machine learning approach,"BACKGROUND: Medications are frequently used for treating schizophrenia, however, anti-psychotic drug use is known to lead to cases of pneumonia. The purpose of our study is to build a model for predicting hospital-acquired pneumonia among schizophrenic patients by adopting machine learning techniques. METHODS: Data related to a total of 185 schizophrenic in-patients at a Taiwanese district mental hospital diagnosed with pneumonia between 2013 ~â€‰2018 were gathered. Eleven predictors, including gender, age, clozapine use, drug-drug interaction, dosage, duration of medication, coughing, change of leukocyte count, change of neutrophil count, change of blood sugar level, change of body weight, were used to predict the onset of pneumonia. Seven machine learning algorithms, including classification and regression tree, decision tree, k-nearest neighbors, naÃ¯ve Bayes, random forest, support vector machine, and logistic regression were utilized to build predictive models used in this study. Accuracy, area under receiver operating characteristic curve, sensitivity, specificity, and kappa were used to measure overall model performance. RESULTS: Among the seven adopted machine learning algorithms, random forest and decision tree exhibited the optimal predictive accuracy versus the remaining algorithms. Further, six most important risk factors, including, dosage, clozapine use, duration of medication, change of neutrophil count, change of leukocyte count, and drug-drug interaction, were also identified. CONCLUSIONS: Although schizophrenic patients remain susceptible to the threat of pneumonia whenever treated with anti-psychotic drugs, our predictive model may serve as a useful support tool for physicians treating such patients.","Predicting hospital-acquired pneumonia among schizophrenic patients: a machine learning approach. BACKGROUND: Medications are frequently used for treating schizophrenia, however, anti-psychotic drug use is known to lead to cases of pneumonia. The purpose of our study is to build a model for predicting hospital-acquired pneumonia among schizophrenic patients by adopting machine learning techniques. METHODS: Data related to a total of 185 schizophrenic in-patients at a Taiwanese district mental hospital diagnosed with pneumonia between 2013 ~â€‰2018 were gathered. Eleven predictors, including gender, age, clozapine use, drug-drug interaction, dosage, duration of medication, coughing, change of leukocyte count, change of neutrophil count, change of blood sugar level, change of body weight, were used to predict the onset of pneumonia. Seven machine learning algorithms, including classification and regression tree, decision tree, k-nearest neighbors, naÃ¯ve Bayes, random forest, support vector machine, and logistic regression were utilized to build predictive models used in this study. Accuracy, area under receiver operating characteristic curve, sensitivity, specificity, and kappa were used to measure overall model performance. RESULTS: Among the seven adopted machine learning algorithms, random forest and decision tree exhibited the optimal predictive accuracy versus the remaining algorithms. Further, six most important risk factors, including, dosage, clozapine use, duration of medication, change of neutrophil count, change of leukocyte count, and drug-drug interaction, were also identified. CONCLUSIONS: Although schizophrenic patients remain susceptible to the threat of pneumonia whenever treated with anti-psychotic drugs, our predictive model may serve as a useful support tool for physicians treating such patients."
1,A machine learning model to predict hepatocellular carcinoma response to transcatheter arterial chemoembolization,"Purpose: To evaluate a fully automated machine learning algorithm that uses pretherapeutic quantitative CT image features and clinical factors to predict hepatocellular carcinoma (HCC) response to transcatheter arterial chemoembolization (TACE). Materials and Methods: Outcome information from 105 patients receiving first-line treatment with TACE was evaluated retrospectively. The primary clinical endpoint was time to progression (TTP) based on follow-up CT radiologic criteria (modified Response Evaluation Criteria in Solid Tumors). A 14-week cutoff was used to classify patients as TACE-susceptible (TTP 14 weeks) or TACE-refractory (TTP, 14 weeks). Response to TACE was predicted using a random forest classifier with the Barcelona Clinic Liver Cancer (BCLC) stage and quantitative image features as input, as well as the BCLC stage alone as a control. Results: The modelâ€™s response prediction accuracy rate was 74.2% (95% confidence interval [CI]: 64%, 82%) using a combination of the BCLC stage plus quantitative image features versus 62.9% (95% CI: 52%, 72%) using the BCLC stage alone. Shape image features of the tumor and background liver were the dominant features correlated to the TTP as selected by the Boruta method and were used to predict the outcome. Conclusion: This preliminary study demonstrated that quantitative image features obtained prior to therapy can improve the accuracy of predicting response of HCC to TACE. This approach is likely to provide useful information for aiding in selection of patients with HCC for TACE.","A machine learning model to predict hepatocellular carcinoma response to transcatheter arterial chemoembolization. Purpose: To evaluate a fully automated machine learning algorithm that uses pretherapeutic quantitative CT image features and clinical factors to predict hepatocellular carcinoma (HCC) response to transcatheter arterial chemoembolization (TACE). Materials and Methods: Outcome information from 105 patients receiving first-line treatment with TACE was evaluated retrospectively. The primary clinical endpoint was time to progression (TTP) based on follow-up CT radiologic criteria (modified Response Evaluation Criteria in Solid Tumors). A 14-week cutoff was used to classify patients as TACE-susceptible (TTP 14 weeks) or TACE-refractory (TTP, 14 weeks). Response to TACE was predicted using a random forest classifier with the Barcelona Clinic Liver Cancer (BCLC) stage and quantitative image features as input, as well as the BCLC stage alone as a control. Results: The modelâ€™s response prediction accuracy rate was 74.2% (95% confidence interval [CI]: 64%, 82%) using a combination of the BCLC stage plus quantitative image features versus 62.9% (95% CI: 52%, 72%) using the BCLC stage alone. Shape image features of the tumor and background liver were the dominant features correlated to the TTP as selected by the Boruta method and were used to predict the outcome. Conclusion: This preliminary study demonstrated that quantitative image features obtained prior to therapy can improve the accuracy of predicting response of HCC to TACE. This approach is likely to provide useful information for aiding in selection of patients with HCC for TACE."
1,OBELISK-Net: Fewer layers to solve 3D multi-organ segmentation with sparse deformable convolutions,,
1,Comparison of Artificial Intelligence Techniques to Evaluate Performance of a Classifier for Automatic Grading of Prostate Cancer From Digitized Histopathologic Images,"Importance: Proper evaluation of the performance of artificial intelligence techniques in the analysis of digitized medical images is paramount for the adoption of such techniques by the medical community and regulatory agencies. Objectives: To compare several cross-validation (CV) approaches to evaluate the performance of a classifier for automatic grading of prostate cancer in digitized histopathologic images and compare the performance of the classifier when trained using data from 1 expert and multiple experts. Design, Setting, and Participants: This quality improvement study used tissue microarray data (333 cores) from 231 patients who underwent radical prostatectomy at the Vancouver General Hospital between June 27, 1997, and June 7, 2011. Digitized images of tissue cores were annotated by 6 pathologists for 4 classes (benign and Gleason grades 3, 4, and 5) between December 12, 2016, and October 5, 2017. Patches of 192 Âµm2 were extracted from these images. There was no overlap between patches. A deep learning classifier based on convolutional neural networks was trained to predict a class label from among the 4 classes (benign and Gleason grades 3, 4, and 5) for each image patch. The classification performance was evaluated in leave-patches-out CV, leave-cores-out CV, and leave-patients-out 20-fold CV. The analysis was performed between November 15, 2018, and January 1, 2019. Main Outcomes and Measures: The classifier performance was evaluated by its accuracy, sensitivity, and specificity in detection of cancer (benign vs cancer) and in low-grade vs high-grade differentiation (Gleason grade 3 vs grades 4-5). The statistical significance analysis was performed using the McNemar test. The agreement level between pathologists and the classifier was quantified using a quadratic-weighted Îº statistic. Results: On 333 tissue microarray cores from 231 participants with prostate cancer (mean [SD] age, 63.2 [6.3] years), 20-fold leave-patches-out CV resulted in mean (SD) accuracy of 97.8% (1.2%), sensitivity of 98.5% (1.0%), and specificity of 97.5% (1.2%) for classifying benign patches vs cancerous patches. By contrast, 20-fold leave-patients-out CV resulted in mean (SD) accuracy of 85.8% (4.3%), sensitivity of 86.3% (4.1%), and specificity of 85.5% (7.2%). Similarly, 20-fold leave-cores-out CV resulted in mean (SD) accuracy of 86.7% (3.7%), sensitivity of 87.2% (4.0%), and specificity of 87.7% (5.5%). Results of McNemar tests showed that the leave-patches-out CV accuracy, sensitivity, and specificity were significantly higher than those for both leave-patients-out CV and leave-cores-out CV. Similar results were observed for classifying low-grade cancer vs high-grade cancer. When trained on a single expert, the overall agreement in grading between pathologists and the classifier ranged from 0.38 to 0.58; when trained using the majority vote among all experts, it was 0.60. Conclusions and Relevance: Results of this study suggest that in prostate cancer classification from histopathologic images, patch-wise CV and single-expert training and evaluation may lead to a biased estimation of classifier's performance. To allow reproducibility and facilitate comparison between automatic classification methods, studies in the field should evaluate their performance using patient-based CV and multiexpert data. Some of these conclusions may be generalizable to other histopathologic applications and to other applications of machine learning in medicine.","Comparison of Artificial Intelligence Techniques to Evaluate Performance of a Classifier for Automatic Grading of Prostate Cancer From Digitized Histopathologic Images. Importance: Proper evaluation of the performance of artificial intelligence techniques in the analysis of digitized medical images is paramount for the adoption of such techniques by the medical community and regulatory agencies. Objectives: To compare several cross-validation (CV) approaches to evaluate the performance of a classifier for automatic grading of prostate cancer in digitized histopathologic images and compare the performance of the classifier when trained using data from 1 expert and multiple experts. Design, Setting, and Participants: This quality improvement study used tissue microarray data (333 cores) from 231 patients who underwent radical prostatectomy at the Vancouver General Hospital between June 27, 1997, and June 7, 2011. Digitized images of tissue cores were annotated by 6 pathologists for 4 classes (benign and Gleason grades 3, 4, and 5) between December 12, 2016, and October 5, 2017. Patches of 192 Âµm2 were extracted from these images. There was no overlap between patches. A deep learning classifier based on convolutional neural networks was trained to predict a class label from among the 4 classes (benign and Gleason grades 3, 4, and 5) for each image patch. The classification performance was evaluated in leave-patches-out CV, leave-cores-out CV, and leave-patients-out 20-fold CV. The analysis was performed between November 15, 2018, and January 1, 2019. Main Outcomes and Measures: The classifier performance was evaluated by its accuracy, sensitivity, and specificity in detection of cancer (benign vs cancer) and in low-grade vs high-grade differentiation (Gleason grade 3 vs grades 4-5). The statistical significance analysis was performed using the McNemar test. The agreement level between pathologists and the classifier was quantified using a quadratic-weighted Îº statistic. Results: On 333 tissue microarray cores from 231 participants with prostate cancer (mean [SD] age, 63.2 [6.3] years), 20-fold leave-patches-out CV resulted in mean (SD) accuracy of 97.8% (1.2%), sensitivity of 98.5% (1.0%), and specificity of 97.5% (1.2%) for classifying benign patches vs cancerous patches. By contrast, 20-fold leave-patients-out CV resulted in mean (SD) accuracy of 85.8% (4.3%), sensitivity of 86.3% (4.1%), and specificity of 85.5% (7.2%). Similarly, 20-fold leave-cores-out CV resulted in mean (SD) accuracy of 86.7% (3.7%), sensitivity of 87.2% (4.0%), and specificity of 87.7% (5.5%). Results of McNemar tests showed that the leave-patches-out CV accuracy, sensitivity, and specificity were significantly higher than those for both leave-patients-out CV and leave-cores-out CV. Similar results were observed for classifying low-grade cancer vs high-grade cancer. When trained on a single expert, the overall agreement in grading between pathologists and the classifier ranged from 0.38 to 0.58; when trained using the majority vote among all experts, it was 0.60. Conclusions and Relevance: Results of this study suggest that in prostate cancer classification from histopathologic images, patch-wise CV and single-expert training and evaluation may lead to a biased estimation of classifier's performance. To allow reproducibility and facilitate comparison between automatic classification methods, studies in the field should evaluate their performance using patient-based CV and multiexpert data. Some of these conclusions may be generalizable to other histopathologic applications and to other applications of machine learning in medicine."
1,Quantitative error prediction of medical image registration using regression forests,,
1,Detection of familial hypercholesterolaemia: external validation of the FAMCAT clinical case-finding algorithm to identify patients in primary care,"BACKGROUND: The vast majority of individuals with familial hypercholesterolaemia in the general population remain unidentified worldwide. Recognising patients most likely to have the condition, to enable targeted specialist assessment and treatment, could prevent major coronary morbidity and mortality. We aimed to evaluate a clinical case-finding algorithm, the familial hypercholesterolaemia case ascertainment tool (FAMCAT), and compare it with currently recommended methods for detection of familial hypercholesterolaemia in primary care. METHODS: In this external validation study, FAMCAT regression equations were applied to a retrospective cohort of patients aged 16 years or older with cholesterol assessed, who were randomly selected from 1500 primary care practices across the UK contributing to the QResearch database. In the main analysis, we assessed the ability of FAMCAT to detect familial hypercholesterolaemia (ie, its discrimination) and compared it with that of other established clinical case-finding approaches recommended internationally (Simon Broome, Dutch Lipid Clinic Network, Make Early Diagnosis to Prevent Early Deaths [MEDPED] and cholesterol concentrations higher than the 99th percentile of the general population in the UK). We assessed discrimination by area under the receiver operating curve (AUROC; ranging from 0.5, indicating pure chance, to 1, indicating perfect discrimination). Using a probability threshold of more than 1 in 500 (prevalence of familial hypercholesterolaemia), we also assessed sensitivity, specificity, positive predictive values, and negative predictive values in the main analysis. FINDINGS: A sample of 750 000 patients who registered in 1500 UK primary care practices that contribute anonymised data to the QResearch database between Jan 1, 1999, and Sept 1, 2017, was randomly selected, of which 747 000 patients were assessed. FAMCAT showed a high degree of discrimination (AUROC 0.832, 95% CI 0.820-0.845), which was higher than that of Simon Broome criteria (0.694, 0.681-0.703), Dutch Lipid Clinic Network criteria (0.724, 0.710-0.738), MEDPED criteria (0.624, 0.609-0.638), and screening cholesterol concentrations higher than the 99th percentile (0.581, 0.570-0.591). Using a 1 in 500 probability threshold, FAMCAT achieved a sensitivity of 84% (1028 predicted vs 1219 observed cases) and specificity of 60% (443 949 predicted vs 745 781 observed non-cases), with a corresponding positive predictive value of 0.84% and a negative predictive value of 99.2%. INTERPRETATION: FAMCAT identifies familial hypercholesterolaemia with greater accuracy than currently recommended approaches and could be considered for clinical case finding of patients with the highest likelihood of having hypercholesterolaemia in primary care. FUNDING: UK National Institute for Health Research School for Primary Care Research.","Detection of familial hypercholesterolaemia: external validation of the FAMCAT clinical case-finding algorithm to identify patients in primary care. BACKGROUND: The vast majority of individuals with familial hypercholesterolaemia in the general population remain unidentified worldwide. Recognising patients most likely to have the condition, to enable targeted specialist assessment and treatment, could prevent major coronary morbidity and mortality. We aimed to evaluate a clinical case-finding algorithm, the familial hypercholesterolaemia case ascertainment tool (FAMCAT), and compare it with currently recommended methods for detection of familial hypercholesterolaemia in primary care. METHODS: In this external validation study, FAMCAT regression equations were applied to a retrospective cohort of patients aged 16 years or older with cholesterol assessed, who were randomly selected from 1500 primary care practices across the UK contributing to the QResearch database. In the main analysis, we assessed the ability of FAMCAT to detect familial hypercholesterolaemia (ie, its discrimination) and compared it with that of other established clinical case-finding approaches recommended internationally (Simon Broome, Dutch Lipid Clinic Network, Make Early Diagnosis to Prevent Early Deaths [MEDPED] and cholesterol concentrations higher than the 99th percentile of the general population in the UK). We assessed discrimination by area under the receiver operating curve (AUROC; ranging from 0.5, indicating pure chance, to 1, indicating perfect discrimination). Using a probability threshold of more than 1 in 500 (prevalence of familial hypercholesterolaemia), we also assessed sensitivity, specificity, positive predictive values, and negative predictive values in the main analysis. FINDINGS: A sample of 750 000 patients who registered in 1500 UK primary care practices that contribute anonymised data to the QResearch database between Jan 1, 1999, and Sept 1, 2017, was randomly selected, of which 747 000 patients were assessed. FAMCAT showed a high degree of discrimination (AUROC 0.832, 95% CI 0.820-0.845), which was higher than that of Simon Broome criteria (0.694, 0.681-0.703), Dutch Lipid Clinic Network criteria (0.724, 0.710-0.738), MEDPED criteria (0.624, 0.609-0.638), and screening cholesterol concentrations higher than the 99th percentile (0.581, 0.570-0.591). Using a 1 in 500 probability threshold, FAMCAT achieved a sensitivity of 84% (1028 predicted vs 1219 observed cases) and specificity of 60% (443 949 predicted vs 745 781 observed non-cases), with a corresponding positive predictive value of 0.84% and a negative predictive value of 99.2%. INTERPRETATION: FAMCAT identifies familial hypercholesterolaemia with greater accuracy than currently recommended approaches and could be considered for clinical case finding of patients with the highest likelihood of having hypercholesterolaemia in primary care. FUNDING: UK National Institute for Health Research School for Primary Care Research."
1,A temporal visualization of chronic obstructive pulmonary disease progression using deep learning and unstructured clinical notes,"BACKGROUND: Chronic obstructive pulmonary disease (COPD) is a progressive lung disease that is classified into stages based on disease severity. We aimed to characterize the time to progression prior to death in patients with COPD and to generate a temporal visualization that describes signs and symptoms during different stages of COPD progression. METHODS: We present a two-step approach for visualizing COPD progression at the level of unstructured clinical notes. We included 15,500 COPD patients who both received care within Partners Healthcare's network and died between 2011 and 2017. We first propose a four-layer deep learning model that utilizes a specially configured recurrent neural network to capture irregular time lapse segments. Using those irregular time lapse segments, we created a temporal visualization (the COPD atlas) to demonstrate COPD progression, which consisted of representative sentences at each time window prior to death based on a fraction of theme words produced by a latent Dirichlet allocation model. We evaluated our approach on an annotated corpus of COPD patients' unstructured pulmonary, radiology, and cardiology notes. RESULTS: Experiments compared to the baselines showed that our proposed approach improved interpretability as well as the accuracy of estimating COPD progression. CONCLUSIONS: Our experiments demonstrated that the proposed deep-learning approach to handling temporal variation in COPD progression is feasible and can be used to generate a graphical representation of disease progression using information extracted from clinical notes.","A temporal visualization of chronic obstructive pulmonary disease progression using deep learning and unstructured clinical notes. BACKGROUND: Chronic obstructive pulmonary disease (COPD) is a progressive lung disease that is classified into stages based on disease severity. We aimed to characterize the time to progression prior to death in patients with COPD and to generate a temporal visualization that describes signs and symptoms during different stages of COPD progression. METHODS: We present a two-step approach for visualizing COPD progression at the level of unstructured clinical notes. We included 15,500 COPD patients who both received care within Partners Healthcare's network and died between 2011 and 2017. We first propose a four-layer deep learning model that utilizes a specially configured recurrent neural network to capture irregular time lapse segments. Using those irregular time lapse segments, we created a temporal visualization (the COPD atlas) to demonstrate COPD progression, which consisted of representative sentences at each time window prior to death based on a fraction of theme words produced by a latent Dirichlet allocation model. We evaluated our approach on an annotated corpus of COPD patients' unstructured pulmonary, radiology, and cardiology notes. RESULTS: Experiments compared to the baselines showed that our proposed approach improved interpretability as well as the accuracy of estimating COPD progression. CONCLUSIONS: Our experiments demonstrated that the proposed deep-learning approach to handling temporal variation in COPD progression is feasible and can be used to generate a graphical representation of disease progression using information extracted from clinical notes."
1,Identification of Factors Associated With Variation in US County-Level Obesity Prevalence Rates Using Epidemiologic vs Machine Learning Models,"Importance: Obesity is a leading cause of high health care expenditures, disability, and premature mortality. Previous studies have documented geographic disparities in obesity prevalence. Objective: To identify county-level factors associated with obesity using traditional epidemiologic and machine learning methods. Design, Setting, and Participants: Cross-sectional study using linear regression models and machine learning models to evaluate the associations between county-level obesity and county-level demographic, socioeconomic, health care, and environmental factors from summarized statistical data extracted from the 2018 Robert Wood Johnson Foundation County Health Rankings and merged with US Census data from each of 3138 US counties. The explanatory power of the linear multivariate regression and the top performing machine learning model were compared using mean R2 measured in 30-fold cross validation. Exposures: County-level demographic factors (population; rural status; census region; and race/ethnicity, sex, and age composition), socioeconomic factors (median income, unemployment rate, and percentage of population with some college education), health care factors (rate of uninsured adults and primary care physicians), and environmental factors (access to healthy foods and access to exercise opportunities). Main Outcomes and Measures: County-level obesity prevalence in 2018, its association with each county-level factor, and the percentage of variation in county-level obesity prevalence explained by linear multivariate and gradient boosting machine regression measured with R2. Results: Among the 3138 counties studied, the mean (range) obesity prevalence was 31.5% (12.8%-47.8%). In multivariate regressions, demographic factors explained 44.9% of variation in obesity prevalence; socioeconomic factors, 33.0%; environmental factors, 15.5%; and health care factors, 9.1%. The county-level factors with the strongest association with obesity were census region, median household income, and percentage of population with some college education. R2 values of univariate regressions of obesity prevalence were 0.238 for census region, 0.218 for median household income, and 0.160 for percentage of population with some college education. Multivariate linear regression and gradient boosting machine regression (the best-performing machine learning model) of obesity prevalence using all county-level demographic, socioeconomic, health care, and environmental factors had R2 values of 0.58 and 0.66, respectively (Pâ€‰<â€‰.001). Conclusions and Relevance: Obesity prevalence varies significantly between counties. County-level demographic, socioeconomic, health care, and environmental factors explain the majority of variation in county-level obesity prevalence. Using machine learning models may explain significantly more of the variation in obesity prevalence..","Identification of Factors Associated With Variation in US County-Level Obesity Prevalence Rates Using Epidemiologic vs Machine Learning Models. Importance: Obesity is a leading cause of high health care expenditures, disability, and premature mortality. Previous studies have documented geographic disparities in obesity prevalence. Objective: To identify county-level factors associated with obesity using traditional epidemiologic and machine learning methods. Design, Setting, and Participants: Cross-sectional study using linear regression models and machine learning models to evaluate the associations between county-level obesity and county-level demographic, socioeconomic, health care, and environmental factors from summarized statistical data extracted from the 2018 Robert Wood Johnson Foundation County Health Rankings and merged with US Census data from each of 3138 US counties. The explanatory power of the linear multivariate regression and the top performing machine learning model were compared using mean R2 measured in 30-fold cross validation. Exposures: County-level demographic factors (population; rural status; census region; and race/ethnicity, sex, and age composition), socioeconomic factors (median income, unemployment rate, and percentage of population with some college education), health care factors (rate of uninsured adults and primary care physicians), and environmental factors (access to healthy foods and access to exercise opportunities). Main Outcomes and Measures: County-level obesity prevalence in 2018, its association with each county-level factor, and the percentage of variation in county-level obesity prevalence explained by linear multivariate and gradient boosting machine regression measured with R2. Results: Among the 3138 counties studied, the mean (range) obesity prevalence was 31.5% (12.8%-47.8%). In multivariate regressions, demographic factors explained 44.9% of variation in obesity prevalence; socioeconomic factors, 33.0%; environmental factors, 15.5%; and health care factors, 9.1%. The county-level factors with the strongest association with obesity were census region, median household income, and percentage of population with some college education. R2 values of univariate regressions of obesity prevalence were 0.238 for census region, 0.218 for median household income, and 0.160 for percentage of population with some college education. Multivariate linear regression and gradient boosting machine regression (the best-performing machine learning model) of obesity prevalence using all county-level demographic, socioeconomic, health care, and environmental factors had R2 values of 0.58 and 0.66, respectively (Pâ€‰<â€‰.001). Conclusions and Relevance: Obesity prevalence varies significantly between counties. County-level demographic, socioeconomic, health care, and environmental factors explain the majority of variation in county-level obesity prevalence. Using machine learning models may explain significantly more of the variation in obesity prevalence.."
1,Preoperative Radiomic Approach to Evaluate Tumor-Infiltrating CD8+ T Cells in Hepatocellular Carcinoma Patients Using Contrast-Enhanced Computed Tomography,"Background: To help identify potential hepatocellular carcinoma (HCC) candidates for immunotherapies, we aimed to develop and validate a radiomics-based biomarker (Rad score) to predict the infiltration of tumor-infiltrating CD8+ T cells in HCC patients, and to evaluate the correlation of Rad score with tumor immune characteristics. Methods: Overall, 142 HCC patients (n = 100 and n = 42 in the training and validation sets, respectively) were subjected to radiomic feature extraction. Imaging features and immunochemistry data of patients in the training set were subjected to elastic-net regularized regression analysis to predict the level of CD8+ T cell infiltration. Results: A Rad score for CD8+ T-cell infiltration, which contained seven variables, was developed and was validated in the validation set (area under the curve [AUC]: training set 0.751, 95% confidence interval [CI] 0.656â€“0.846; validation set 0.705, 95% CI 0.547â€“0.863). The decision curve indicated the clinical usefulness of the Rad score. A higher Rad score correlated with superior overall and disease-free survival outcomes (p = 0.012 and 0.0088, respectively). Using the pathological slides, we found that the Rad score positively correlated with the percentage of tumor-infiltrating lymphocytes (TILs; Spearman rho = 0.51, p < 0.0001). Moreover, the Rad score could also discriminate inflamed tumors from immune-desert and immune-excluded tumors (Kruskalâ€“Wallis, p < 0.0001), and higher Rad scores could be found in patients with positive programmed cell death ligand 1 expression in tumor/immune cells, as well as those with positive programmed cell death protein 1 expression. Conclusion: The newly developed Rad score was a powerful predictor of CD8+ T-cell infiltration, which could be useful in identifying potential HCC patients who can benefit from immunotherapies when validated in large-scale prospective cohorts.","Preoperative Radiomic Approach to Evaluate Tumor-Infiltrating CD8+ T Cells in Hepatocellular Carcinoma Patients Using Contrast-Enhanced Computed Tomography. Background: To help identify potential hepatocellular carcinoma (HCC) candidates for immunotherapies, we aimed to develop and validate a radiomics-based biomarker (Rad score) to predict the infiltration of tumor-infiltrating CD8+ T cells in HCC patients, and to evaluate the correlation of Rad score with tumor immune characteristics. Methods: Overall, 142 HCC patients (n = 100 and n = 42 in the training and validation sets, respectively) were subjected to radiomic feature extraction. Imaging features and immunochemistry data of patients in the training set were subjected to elastic-net regularized regression analysis to predict the level of CD8+ T cell infiltration. Results: A Rad score for CD8+ T-cell infiltration, which contained seven variables, was developed and was validated in the validation set (area under the curve [AUC]: training set 0.751, 95% confidence interval [CI] 0.656â€“0.846; validation set 0.705, 95% CI 0.547â€“0.863). The decision curve indicated the clinical usefulness of the Rad score. A higher Rad score correlated with superior overall and disease-free survival outcomes (p = 0.012 and 0.0088, respectively). Using the pathological slides, we found that the Rad score positively correlated with the percentage of tumor-infiltrating lymphocytes (TILs; Spearman rho = 0.51, p < 0.0001). Moreover, the Rad score could also discriminate inflamed tumors from immune-desert and immune-excluded tumors (Kruskalâ€“Wallis, p < 0.0001), and higher Rad scores could be found in patients with positive programmed cell death ligand 1 expression in tumor/immune cells, as well as those with positive programmed cell death protein 1 expression. Conclusion: The newly developed Rad score was a powerful predictor of CD8+ T-cell infiltration, which could be useful in identifying potential HCC patients who can benefit from immunotherapies when validated in large-scale prospective cohorts."
1,Machine Learning Identification of Surgical and Operative Factors Associated with Surgical Expertise in Virtual Reality Simulation,"Importance: Despite advances in the assessment of technical skills in surgery, a clear understanding of the composites of technical expertise is lacking. Surgical simulation allows for the quantitation of psychomotor skills, generating data sets that can be analyzed using machine learning algorithms. Objective: To identify surgical and operative factors selected by a machine learning algorithm to accurately classify participants by level of expertise in a virtual reality surgical procedure. Design, Setting, and Participants: Fifty participants from a single university were recruited between March 1, 2015, and May 31, 2016, to participate in a case series study at McGill University Neurosurgical Simulation and Artificial Intelligence Learning Centre. Data were collected at a single time point and no follow-up data were collected. Individuals were classified a priori as expert (neurosurgery staff), seniors (neurosurgical fellows and senior residents), juniors (neurosurgical junior residents), and medical students, all of whom participated in 250 simulated tumor resections. Exposures: All individuals participated in a virtual reality neurosurgical tumor resection scenario. Each scenario was repeated 5 times. Main Outcomes and Measures: Through an iterative process, performance metrics associated with instrument movement and force, resection of tissues, and bleeding generated from the raw simulator data output were selected by K-nearest neighbor, naive Bayes, discriminant analysis, and support vector machine algorithms to most accurately determine group membership. Results: A total of 50 individuals (9 women and 41 men; mean [SD] age, 33.6 [9.5] years; 14 neurosurgeons, 4 fellows, 10 senior residents, 10 junior residents, and 12 medical students) participated. Neurosurgeons were in practice between 1 and 25 years, with 9 (64%) involving a predominantly cranial practice. The K-nearest neighbor algorithm had an accuracy of 90% (45 of 50), the naive Bayes algorithm had an accuracy of 84% (42 of 50), the discriminant analysis algorithm had an accuracy of 78% (39 of 50), and the support vector machine algorithm had an accuracy of 76% (38 of 50). The K-nearest neighbor algorithm used 6 performance metrics to classify participants, the naive Bayes algorithm used 9 performance metrics, the discriminant analysis algorithm used 8 performance metrics, and the support vector machine algorithm used 8 performance metrics. Two neurosurgeons, 1 fellow or senior resident, 1 junior resident, and 1 medical student were misclassified. Conclusions and Relevance: In a virtual reality neurosurgical tumor resection study, a machine learning algorithm successfully classified participants into 4 levels of expertise with 90% accuracy. These findings suggest that algorithms may be capable of classifying surgical expertise with greater granularity and precision than has been previously demonstrated in surgery..","Machine Learning Identification of Surgical and Operative Factors Associated with Surgical Expertise in Virtual Reality Simulation. Importance: Despite advances in the assessment of technical skills in surgery, a clear understanding of the composites of technical expertise is lacking. Surgical simulation allows for the quantitation of psychomotor skills, generating data sets that can be analyzed using machine learning algorithms. Objective: To identify surgical and operative factors selected by a machine learning algorithm to accurately classify participants by level of expertise in a virtual reality surgical procedure. Design, Setting, and Participants: Fifty participants from a single university were recruited between March 1, 2015, and May 31, 2016, to participate in a case series study at McGill University Neurosurgical Simulation and Artificial Intelligence Learning Centre. Data were collected at a single time point and no follow-up data were collected. Individuals were classified a priori as expert (neurosurgery staff), seniors (neurosurgical fellows and senior residents), juniors (neurosurgical junior residents), and medical students, all of whom participated in 250 simulated tumor resections. Exposures: All individuals participated in a virtual reality neurosurgical tumor resection scenario. Each scenario was repeated 5 times. Main Outcomes and Measures: Through an iterative process, performance metrics associated with instrument movement and force, resection of tissues, and bleeding generated from the raw simulator data output were selected by K-nearest neighbor, naive Bayes, discriminant analysis, and support vector machine algorithms to most accurately determine group membership. Results: A total of 50 individuals (9 women and 41 men; mean [SD] age, 33.6 [9.5] years; 14 neurosurgeons, 4 fellows, 10 senior residents, 10 junior residents, and 12 medical students) participated. Neurosurgeons were in practice between 1 and 25 years, with 9 (64%) involving a predominantly cranial practice. The K-nearest neighbor algorithm had an accuracy of 90% (45 of 50), the naive Bayes algorithm had an accuracy of 84% (42 of 50), the discriminant analysis algorithm had an accuracy of 78% (39 of 50), and the support vector machine algorithm had an accuracy of 76% (38 of 50). The K-nearest neighbor algorithm used 6 performance metrics to classify participants, the naive Bayes algorithm used 9 performance metrics, the discriminant analysis algorithm used 8 performance metrics, and the support vector machine algorithm used 8 performance metrics. Two neurosurgeons, 1 fellow or senior resident, 1 junior resident, and 1 medical student were misclassified. Conclusions and Relevance: In a virtual reality neurosurgical tumor resection study, a machine learning algorithm successfully classified participants into 4 levels of expertise with 90% accuracy. These findings suggest that algorithms may be capable of classifying surgical expertise with greater granularity and precision than has been previously demonstrated in surgery.."
1,Assessment of Convolutional Neural Networks for Automated Classification of Chest Radiographs,"Purpose To assess the ability of convolutional neural networks (CNNs) to enable high-performance automated binary classification of chest radiographs. Materials and Methods In a retrospective study, 216 431 frontal chest radiographs obtained between 1998 and 2012 were procured, along with associated text reports and a prospective label from the attending radiologist. This data set was used to train CNNs to classify chest radiographs as normal or abnormal before evaluation on a held-out set of 533 images hand-labeled by expert radiologists. The effects of development set size, training set size, initialization strategy, and network architecture on end performance were assessed by using standard binary classification metrics; detailed error analysis, including visualization of CNN activations, was also performed. Results Average area under the receiver operating characteristic curve (AUC) was 0.96 for a CNN trained with 200 000 images. This AUC value was greater than that observed when the same model was trained with 2000 images (AUC = 0.84, P < .005) but was not significantly different from that observed when the model was trained with 20 000 images (AUC = 0.95, P > .05). Averaging the CNN output score with the binary prospective label yielded the best-performing classifier, with an AUC of 0.98 (P < .005). Analysis of specific radiographs revealed that the model was heavily influenced by clinically relevant spatial regions but did not reliably generalize beyond thoracic disease. Conclusion CNNs trained with a modestly sized collection of prospectively labeled chest radiographs achieved high diagnostic performance in the classification of chest radiographs as normal or abnormal; this function may be useful for automated prioritization of abnormal chest radiographs. (c) RSNA, 2018 Online supplemental material is available for this article. See also the editorial by van Ginneken in this issue.","Assessment of Convolutional Neural Networks for Automated Classification of Chest Radiographs. Purpose To assess the ability of convolutional neural networks (CNNs) to enable high-performance automated binary classification of chest radiographs. Materials and Methods In a retrospective study, 216 431 frontal chest radiographs obtained between 1998 and 2012 were procured, along with associated text reports and a prospective label from the attending radiologist. This data set was used to train CNNs to classify chest radiographs as normal or abnormal before evaluation on a held-out set of 533 images hand-labeled by expert radiologists. The effects of development set size, training set size, initialization strategy, and network architecture on end performance were assessed by using standard binary classification metrics; detailed error analysis, including visualization of CNN activations, was also performed. Results Average area under the receiver operating characteristic curve (AUC) was 0.96 for a CNN trained with 200 000 images. This AUC value was greater than that observed when the same model was trained with 2000 images (AUC = 0.84, P < .005) but was not significantly different from that observed when the model was trained with 20 000 images (AUC = 0.95, P > .05). Averaging the CNN output score with the binary prospective label yielded the best-performing classifier, with an AUC of 0.98 (P < .005). Analysis of specific radiographs revealed that the model was heavily influenced by clinically relevant spatial regions but did not reliably generalize beyond thoracic disease. Conclusion CNNs trained with a modestly sized collection of prospectively labeled chest radiographs achieved high diagnostic performance in the classification of chest radiographs as normal or abnormal; this function may be useful for automated prioritization of abnormal chest radiographs. (c) RSNA, 2018 Online supplemental material is available for this article. See also the editorial by van Ginneken in this issue."
1,Assessment of a Deep Learning Model Based on Electronic Health Record Data to Forecast Clinical Outcomes in Patients With Rheumatoid Arthritis,"Importance: Knowing the future condition of a patient would enable a physician to customize current therapeutic options to prevent disease worsening, but predicting that future condition requires sophisticated modeling and information. If artificial intelligence models were capable of forecasting future patient outcomes, they could be used to aid practitioners and patients in prognosticating outcomes or simulating potential outcomes under different treatment scenarios. Objective: To assess the ability of an artificial intelligence system to prognosticate the state of disease activity of patients with rheumatoid arthritis (RA) at their next clinical visit. Design, Setting, and Participants: This prognostic study included 820 patients with RA from rheumatology clinics at 2 distinct health care systems with different electronic health record platforms: a university hospital (UH) and a public safety-net hospital (SNH). The UH and SNH had substantially different patient populations and treatment patterns. The UH has records on approximately 1 million total patients starting in January 2012. The UH data for this study were accessed on July 1, 2017. The SNH has records on 65â€¯000 unique individuals starting in January 2013. The SNH data for the study were collected on February 27, 2018. Exposures: Structured data were extracted from the electronic health record, including exposures (medications), patient demographics, laboratories, and prior measures of disease activity. A longitudinal deep learning model was used to predict disease activity for patients with RA at their next rheumatology clinic visit and to evaluate interhospital performance and model interoperability strategies. Main Outcomes and Measures: Model performance was quantified using the area under the receiver operating characteristic curve (AUROC). Disease activity in RA was measured using a composite index score. Results: A total of 578 UH patients (mean [SD] age, 57 [15] years; 477 [82.5%] female; 296 [51.2%] white) and 242 SNH patients (mean [SD] age, 60 [15] years; 195 [80.6%] female; 30 [12.4%] white) were included in the study. Patients at the UH compared with those at the SNH were seen more frequently (median time between visits, 100 vs 180 days) and were more frequently prescribed higher-class medications (biologics) (364 [63.0%] vs 70 [28.9%]). At the UH, the model reached an AUROC of 0.91 (95% CI, 0.86-0.96) in a test cohort of 116 patients. The UH-trained model had an AUROC of 0.74 (95% CI, 0.65-0.83) in the SNH test cohort (nâ€‰=â€‰117) despite marked differences in the patient populations. In both settings, baseline prediction using each patients' most recent disease activity score had statistically random performance. Conclusions and Relevance: The findings suggest that building accurate models to forecast complex disease outcomes using electronic health record data is possible and these models can be shared across hospitals with diverse patient populations.","Assessment of a Deep Learning Model Based on Electronic Health Record Data to Forecast Clinical Outcomes in Patients With Rheumatoid Arthritis. Importance: Knowing the future condition of a patient would enable a physician to customize current therapeutic options to prevent disease worsening, but predicting that future condition requires sophisticated modeling and information. If artificial intelligence models were capable of forecasting future patient outcomes, they could be used to aid practitioners and patients in prognosticating outcomes or simulating potential outcomes under different treatment scenarios. Objective: To assess the ability of an artificial intelligence system to prognosticate the state of disease activity of patients with rheumatoid arthritis (RA) at their next clinical visit. Design, Setting, and Participants: This prognostic study included 820 patients with RA from rheumatology clinics at 2 distinct health care systems with different electronic health record platforms: a university hospital (UH) and a public safety-net hospital (SNH). The UH and SNH had substantially different patient populations and treatment patterns. The UH has records on approximately 1 million total patients starting in January 2012. The UH data for this study were accessed on July 1, 2017. The SNH has records on 65â€¯000 unique individuals starting in January 2013. The SNH data for the study were collected on February 27, 2018. Exposures: Structured data were extracted from the electronic health record, including exposures (medications), patient demographics, laboratories, and prior measures of disease activity. A longitudinal deep learning model was used to predict disease activity for patients with RA at their next rheumatology clinic visit and to evaluate interhospital performance and model interoperability strategies. Main Outcomes and Measures: Model performance was quantified using the area under the receiver operating characteristic curve (AUROC). Disease activity in RA was measured using a composite index score. Results: A total of 578 UH patients (mean [SD] age, 57 [15] years; 477 [82.5%] female; 296 [51.2%] white) and 242 SNH patients (mean [SD] age, 60 [15] years; 195 [80.6%] female; 30 [12.4%] white) were included in the study. Patients at the UH compared with those at the SNH were seen more frequently (median time between visits, 100 vs 180 days) and were more frequently prescribed higher-class medications (biologics) (364 [63.0%] vs 70 [28.9%]). At the UH, the model reached an AUROC of 0.91 (95% CI, 0.86-0.96) in a test cohort of 116 patients. The UH-trained model had an AUROC of 0.74 (95% CI, 0.65-0.83) in the SNH test cohort (nâ€‰=â€‰117) despite marked differences in the patient populations. In both settings, baseline prediction using each patients' most recent disease activity score had statistically random performance. Conclusions and Relevance: The findings suggest that building accurate models to forecast complex disease outcomes using electronic health record data is possible and these models can be shared across hospitals with diverse patient populations."
1,f-AnoGAN: Fast unsupervised anomaly detection with generative adversarial networks,,
1,Machine learning based automated dynamic quantification of left heart chamber volumes,"Aims: Studies have demonstrated the ability of a new automated algorithm for volumetric analysis of 3D echocardiographic (3DE) datasets to provide accurate and reproducible measurements of left ventricular and left atrial (LV, LA) volumes at end-systole and end-diastole. Recently, this methodology was expanded using a machine learning (ML) approach to automatically measure chamber volumes throughout the cardiac cycle, resulting in LV and LA volume-time curves. We aimed to validate ejection and filling parameters obtained from these curves by comparing them to independent well-validated reference techniques. Methods and results: We studied 20 patients referred for cardiac magnetic resonance (CMR) examinations, who underwent 3DE imaging the same day. Volume-time curves were obtained for both LV and LA chambers using the ML algorithm (Philips HeartModel), and independently conventional 3DE volumetric analysis (TomTec), and CMR images (slice-by-slice, frame-by-frame manual tracing). Automatically derived LV and LA volumes and ejection/filling parameters were compared against both reference techniques. Minor manual correction of the automatically detected LV and LA borders was needed in 4/20 and 5/20 cases, respectively. Time required to generate volume-time curves was 35 Â± 17 s using ML algorithm, 3.6 Â± 0.9 min using conventional 3DE analysis, and 96 Â± 14 min using CMR. Volume-time curves obtained by all three techniques were similar in shape and magnitude. In both comparisons, ejection/filling parameters showed no significant inter-technique differences. Bland-Altman analysis confirmed small biases, despite wide limits of agreement. Conclusion: The automated ML algorithm can quickly measure dynamic LV and LA volumes and accurately analyse ejection/filling parameters. Incorporation of this algorithm into the clinical workflow may increase the utilization of 3DE imaging.","Machine learning based automated dynamic quantification of left heart chamber volumes. Aims: Studies have demonstrated the ability of a new automated algorithm for volumetric analysis of 3D echocardiographic (3DE) datasets to provide accurate and reproducible measurements of left ventricular and left atrial (LV, LA) volumes at end-systole and end-diastole. Recently, this methodology was expanded using a machine learning (ML) approach to automatically measure chamber volumes throughout the cardiac cycle, resulting in LV and LA volume-time curves. We aimed to validate ejection and filling parameters obtained from these curves by comparing them to independent well-validated reference techniques. Methods and results: We studied 20 patients referred for cardiac magnetic resonance (CMR) examinations, who underwent 3DE imaging the same day. Volume-time curves were obtained for both LV and LA chambers using the ML algorithm (Philips HeartModel), and independently conventional 3DE volumetric analysis (TomTec), and CMR images (slice-by-slice, frame-by-frame manual tracing). Automatically derived LV and LA volumes and ejection/filling parameters were compared against both reference techniques. Minor manual correction of the automatically detected LV and LA borders was needed in 4/20 and 5/20 cases, respectively. Time required to generate volume-time curves was 35 Â± 17 s using ML algorithm, 3.6 Â± 0.9 min using conventional 3DE analysis, and 96 Â± 14 min using CMR. Volume-time curves obtained by all three techniques were similar in shape and magnitude. In both comparisons, ejection/filling parameters showed no significant inter-technique differences. Bland-Altman analysis confirmed small biases, despite wide limits of agreement. Conclusion: The automated ML algorithm can quickly measure dynamic LV and LA volumes and accurately analyse ejection/filling parameters. Incorporation of this algorithm into the clinical workflow may increase the utilization of 3DE imaging."
1,Discovery of Distinct Immune Phenotypes Using Machine Learning in Pulmonary Arterial Hypertension,"RATIONALE: Accumulating evidence implicates inflammation in pulmonary arterial hypertension (PAH) and therapies targeting immunity are under investigation, although it remains unknown if distinct immune phenotypes exist. OBJECTIVE: Identify PAH immune phenotypes based on unsupervised analysis of blood proteomic profiles. METHODS AND RESULTS: In a prospective observational study of group 1 PAH patients evaluated at Stanford University (discovery cohort; n=281) and University of Sheffield (validation cohort; n=104) between 2008 and 2014, we measured a circulating proteomic panel of 48 cytokines, chemokines, and factors using multiplex immunoassay. Unsupervised machine learning (consensus clustering) was applied in both cohorts independently to classify patients into proteomic immune clusters, without guidance from clinical features. To identify central proteins in each cluster, we performed partial correlation network analysis. Clinical characteristics and outcomes were subsequently compared across clusters. Four PAH clusters with distinct proteomic immune profiles were identified in the discovery cohort. Cluster 2 (n=109) had low cytokine levels similar to controls. Other clusters had unique sets of upregulated proteins central to immune networks-cluster 1 (n=58; TRAIL [tumor necrosis factor-related apoptosis-inducing ligand], CCL5 [C-C motif chemokine ligand 5], CCL7, CCL4, MIF [macrophage migration inhibitory factor]), cluster 3 (n=77; IL [interleukin]-12, IL-17, IL-10, IL-7, VEGF [vascular endothelial growth factor]), and cluster 4 (n=37; IL-8, IL-4, PDGF-beta [platelet-derived growth factor beta], IL-6, CCL11). Demographics, PAH clinical subtypes, comorbidities, and medications were similar across clusters. Noninvasive and hemodynamic surrogates of clinical risk identified cluster 1 as high-risk and cluster 3 as low-risk groups. Five-year transplant-free survival rates were unfavorable for cluster 1 (47.6%; 95% CI, 35.4%-64.1%) and favorable for cluster 3 (82.4%; 95% CI, 72.0%-94.3%; across-cluster P<0.001). Findings were replicated in the validation cohort, where machine learning classified 4 immune clusters with comparable proteomic, clinical, and prognostic features. CONCLUSIONS: Blood cytokine profiles distinguish PAH immune phenotypes with differing clinical risk that are independent of World Health Organization group 1 subtypes. These phenotypes could inform mechanistic studies of disease pathobiology and provide a framework to examine patient responses to emerging therapies targeting immunity.","Discovery of Distinct Immune Phenotypes Using Machine Learning in Pulmonary Arterial Hypertension. RATIONALE: Accumulating evidence implicates inflammation in pulmonary arterial hypertension (PAH) and therapies targeting immunity are under investigation, although it remains unknown if distinct immune phenotypes exist. OBJECTIVE: Identify PAH immune phenotypes based on unsupervised analysis of blood proteomic profiles. METHODS AND RESULTS: In a prospective observational study of group 1 PAH patients evaluated at Stanford University (discovery cohort; n=281) and University of Sheffield (validation cohort; n=104) between 2008 and 2014, we measured a circulating proteomic panel of 48 cytokines, chemokines, and factors using multiplex immunoassay. Unsupervised machine learning (consensus clustering) was applied in both cohorts independently to classify patients into proteomic immune clusters, without guidance from clinical features. To identify central proteins in each cluster, we performed partial correlation network analysis. Clinical characteristics and outcomes were subsequently compared across clusters. Four PAH clusters with distinct proteomic immune profiles were identified in the discovery cohort. Cluster 2 (n=109) had low cytokine levels similar to controls. Other clusters had unique sets of upregulated proteins central to immune networks-cluster 1 (n=58; TRAIL [tumor necrosis factor-related apoptosis-inducing ligand], CCL5 [C-C motif chemokine ligand 5], CCL7, CCL4, MIF [macrophage migration inhibitory factor]), cluster 3 (n=77; IL [interleukin]-12, IL-17, IL-10, IL-7, VEGF [vascular endothelial growth factor]), and cluster 4 (n=37; IL-8, IL-4, PDGF-beta [platelet-derived growth factor beta], IL-6, CCL11). Demographics, PAH clinical subtypes, comorbidities, and medications were similar across clusters. Noninvasive and hemodynamic surrogates of clinical risk identified cluster 1 as high-risk and cluster 3 as low-risk groups. Five-year transplant-free survival rates were unfavorable for cluster 1 (47.6%; 95% CI, 35.4%-64.1%) and favorable for cluster 3 (82.4%; 95% CI, 72.0%-94.3%; across-cluster P<0.001). Findings were replicated in the validation cohort, where machine learning classified 4 immune clusters with comparable proteomic, clinical, and prognostic features. CONCLUSIONS: Blood cytokine profiles distinguish PAH immune phenotypes with differing clinical risk that are independent of World Health Organization group 1 subtypes. These phenotypes could inform mechanistic studies of disease pathobiology and provide a framework to examine patient responses to emerging therapies targeting immunity."
1,Using artificial intelligence to reduce diagnostic workload without compromising detection of urinary tract infections,"BACKGROUND: A substantial proportion of microbiological screening in diagnostic laboratories is due to suspected urinary tract infections (UTIs), yet approximately two thirds of urine samples typically yield negative culture results. By reducing the number of query samples to be cultured and enabling diagnostic services to concentrate on those in which there are true microbial infections, a significant improvement in efficiency of the service is possible. METHODOLOGY: Screening process for urine samples prior to culture was modelled in a single clinical microbiology laboratory covering three hospitals and community services across Bristol and Bath, UK. Retrospective analysis of all urine microscopy, culture, and sensitivity reports over one year was used to compare two methods of classification: a heuristic model using a combination of white blood cell count and bacterial count, and a machine learning approach testing three algorithms (Random Forest, Neural Network, Extreme Gradient Boosting) whilst factoring in independent variables including demographics, historical urine culture results, and clinical details provided with the specimen. RESULTS: A total of 212,554 urine reports were analysed. Initial findings demonstrated the potential for using machine learning algorithms, which outperformed the heuristic model in terms of relative workload reduction achieved at a classification sensitivity >â€‰95%. Upon further analysis of classification sensitivity of subpopulations, we concluded that samples from pregnant patients and children (age 11 or younger) require independent evaluation. First the removal of pregnant patients and children from the classification process was investigated but this diminished the workload reduction achieved. The optimal solution was found to be three Extreme Gradient Boosting algorithms, trained independently for the classification of pregnant patients, children, and then all other patients. When combined, this system granted a relative workload reduction of 41% and a sensitivity of 95% for each of the stratified patient groups. CONCLUSION: Based on the considerable time and cost savings achieved, without compromising the diagnostic performance, the heuristic model was successfully implemented in routine clinical practice in the diagnostic laboratory at Severn Pathology, Bristol. Our work shows the potential application of supervised machine learning models in improving service efficiency at a time when demand often surpasses resources of public healthcare providers.","Using artificial intelligence to reduce diagnostic workload without compromising detection of urinary tract infections. BACKGROUND: A substantial proportion of microbiological screening in diagnostic laboratories is due to suspected urinary tract infections (UTIs), yet approximately two thirds of urine samples typically yield negative culture results. By reducing the number of query samples to be cultured and enabling diagnostic services to concentrate on those in which there are true microbial infections, a significant improvement in efficiency of the service is possible. METHODOLOGY: Screening process for urine samples prior to culture was modelled in a single clinical microbiology laboratory covering three hospitals and community services across Bristol and Bath, UK. Retrospective analysis of all urine microscopy, culture, and sensitivity reports over one year was used to compare two methods of classification: a heuristic model using a combination of white blood cell count and bacterial count, and a machine learning approach testing three algorithms (Random Forest, Neural Network, Extreme Gradient Boosting) whilst factoring in independent variables including demographics, historical urine culture results, and clinical details provided with the specimen. RESULTS: A total of 212,554 urine reports were analysed. Initial findings demonstrated the potential for using machine learning algorithms, which outperformed the heuristic model in terms of relative workload reduction achieved at a classification sensitivity >â€‰95%. Upon further analysis of classification sensitivity of subpopulations, we concluded that samples from pregnant patients and children (age 11 or younger) require independent evaluation. First the removal of pregnant patients and children from the classification process was investigated but this diminished the workload reduction achieved. The optimal solution was found to be three Extreme Gradient Boosting algorithms, trained independently for the classification of pregnant patients, children, and then all other patients. When combined, this system granted a relative workload reduction of 41% and a sensitivity of 95% for each of the stratified patient groups. CONCLUSION: Based on the considerable time and cost savings achieved, without compromising the diagnostic performance, the heuristic model was successfully implemented in routine clinical practice in the diagnostic laboratory at Severn Pathology, Bristol. Our work shows the potential application of supervised machine learning models in improving service efficiency at a time when demand often surpasses resources of public healthcare providers."
1,Deep learning for automated segmentation of liver lesions at ct in patients with colorectal cancer liver metastases,"Purpose: To evaluate the performance, agreement, and efficiency of a fully convolutional network (FCN) for liver lesion detection and segmentation at CT examinations in patients with colorectal liver metastases (CLMs). Materials and Methods: This retrospective study evaluated an automated method using an FCN that was trained, validated, and tested with 115, 15, and 26 contrast materialâ€“enhanced CT examinations containing 261, 22, and 105 lesions, respectively. Manual detection and segmentation by a radiologist was the reference standard. Performance of fully automated and user-corrected segmentations was compared with that of manual segmentations. The interuser agreement and interaction time of manual and user-corrected segmentations were assessed. Analyses included sensitivity and positive predictive value of detection, segmentation accuracy, Cohen k, BlandAltman analyses, and analysis of variance. Results: In the test cohort, for lesion size smaller than 10 mm (n = 30), 10â€“20 mm (n = 35), and larger than 20 mm (n = 40), the detection sensitivity of the automated method was 10%, 71%, and 85%; positive predictive value was 25%, 83%, and 94%; Dice similarity coefficient was 0.14, 0.53, and 0.68; maximum symmetric surface distance was 5.2, 6.0, and 10.4 mm; and average symmetric surface distance was 2.7, 1.7, and 2.8 mm, respectively. For manual and user-corrected segmentation, k values were 0.42 (95% confidence interval: 0.24, 0.63) and 0.52 (95% confidence interval: 0.36, 0.72); normalized interreader agreement for lesion volume was âˆ’0.10 Â± 0.07 (95% confidence interval) and âˆ’0.10 Â± 0.08; and mean interaction time was 7.7 minutes Â± 2.4 (standard deviation) and 4.8 minutes Â± 2.1 (P <.001), respectively. Conclusion: Automated detection and segmentation of CLM by using deep learning with convolutional neural networks, when manually corrected, improved efficiency but did not substantially change agreement on volumetric measurements.","Deep learning for automated segmentation of liver lesions at ct in patients with colorectal cancer liver metastases. Purpose: To evaluate the performance, agreement, and efficiency of a fully convolutional network (FCN) for liver lesion detection and segmentation at CT examinations in patients with colorectal liver metastases (CLMs). Materials and Methods: This retrospective study evaluated an automated method using an FCN that was trained, validated, and tested with 115, 15, and 26 contrast materialâ€“enhanced CT examinations containing 261, 22, and 105 lesions, respectively. Manual detection and segmentation by a radiologist was the reference standard. Performance of fully automated and user-corrected segmentations was compared with that of manual segmentations. The interuser agreement and interaction time of manual and user-corrected segmentations were assessed. Analyses included sensitivity and positive predictive value of detection, segmentation accuracy, Cohen k, BlandAltman analyses, and analysis of variance. Results: In the test cohort, for lesion size smaller than 10 mm (n = 30), 10â€“20 mm (n = 35), and larger than 20 mm (n = 40), the detection sensitivity of the automated method was 10%, 71%, and 85%; positive predictive value was 25%, 83%, and 94%; Dice similarity coefficient was 0.14, 0.53, and 0.68; maximum symmetric surface distance was 5.2, 6.0, and 10.4 mm; and average symmetric surface distance was 2.7, 1.7, and 2.8 mm, respectively. For manual and user-corrected segmentation, k values were 0.42 (95% confidence interval: 0.24, 0.63) and 0.52 (95% confidence interval: 0.36, 0.72); normalized interreader agreement for lesion volume was âˆ’0.10 Â± 0.07 (95% confidence interval) and âˆ’0.10 Â± 0.08; and mean interaction time was 7.7 minutes Â± 2.4 (standard deviation) and 4.8 minutes Â± 2.1 (P <.001), respectively. Conclusion: Automated detection and segmentation of CLM by using deep learning with convolutional neural networks, when manually corrected, improved efficiency but did not substantially change agreement on volumetric measurements."
1,Predicting the early risk of chronic kidney disease in patients with diabetes using real-world data,"Diagnostic procedures, therapeutic recommendations, and medical risk stratifications are based on dedicated, strictly controlled clinical trials. However, a plethora of real-world medical data exists, whereupon the increase in data volume comes at the expense of completeness, uniformity, and control. Here, a case-by-case comparison shows that the predictive power of our real world data-based model for diabetes-related chronic kidney disease outperforms published algorithms, which were derived from clinical study data.","Predicting the early risk of chronic kidney disease in patients with diabetes using real-world data. Diagnostic procedures, therapeutic recommendations, and medical risk stratifications are based on dedicated, strictly controlled clinical trials. However, a plethora of real-world medical data exists, whereupon the increase in data volume comes at the expense of completeness, uniformity, and control. Here, a case-by-case comparison shows that the predictive power of our real world data-based model for diabetes-related chronic kidney disease outperforms published algorithms, which were derived from clinical study data."
1,Combination of active transfer learning and natural language processing to improve liver volumetry using surrogate metrics with deep learning,"Purpose: To determine if weakly supervised learning with surrogate metrics and active transfer learning can hasten clinical deployment of deep learning models. Materials and Methods: By leveraging Liver Tumor Segmentation (LiTS) challenge 2017 public data (n = 131 studies), natural language processing of reports, and an active learning method, a model was trained to segment livers on 239 retrospectively collected portal venous phase abdominal CT studies obtained between January 1, 2014, and December 31, 2016. Absolute volume differences between predicted and originally reported liver volumes were used to guide active learning and assess accuracy. Overall survival based on liver volumes predicted by this model (n = 34 patients) versus radiology reports and Model for End-Stage Liver Disease with sodium (MELD-Na) scores was assessed. Differences in absolute liver volume were compared by using the paired Student t test, Bland-Altman analysis, and intraclass correlation; survival analysis was performed with the Kaplan-Meier method and a Mantel-Cox test. Results: Data from patients with poor liver volume prediction (n = 10) with a model trained only with publicly available data were incorporated into an active learning method that trained a new model (LiTS data plus over-and underestimated active learning cases [LiTS-OU]) that performed significantly better on a held-out institutional test set (absolute volume difference of 231 vs 176 mL, P =.0005). In overall survival analysis, predicted liver volumes using the best active learning-trained model (LiTS-OU) were at least comparable with liver volumes extracted from radiology reports and MELD-Na scores in predicting survival. Conclusion: Active transfer learning using surrogate metrics facilitated deployment of deep learning models for clinically meaningful liver segmentation at a major liver transplant center.","Combination of active transfer learning and natural language processing to improve liver volumetry using surrogate metrics with deep learning. Purpose: To determine if weakly supervised learning with surrogate metrics and active transfer learning can hasten clinical deployment of deep learning models. Materials and Methods: By leveraging Liver Tumor Segmentation (LiTS) challenge 2017 public data (n = 131 studies), natural language processing of reports, and an active learning method, a model was trained to segment livers on 239 retrospectively collected portal venous phase abdominal CT studies obtained between January 1, 2014, and December 31, 2016. Absolute volume differences between predicted and originally reported liver volumes were used to guide active learning and assess accuracy. Overall survival based on liver volumes predicted by this model (n = 34 patients) versus radiology reports and Model for End-Stage Liver Disease with sodium (MELD-Na) scores was assessed. Differences in absolute liver volume were compared by using the paired Student t test, Bland-Altman analysis, and intraclass correlation; survival analysis was performed with the Kaplan-Meier method and a Mantel-Cox test. Results: Data from patients with poor liver volume prediction (n = 10) with a model trained only with publicly available data were incorporated into an active learning method that trained a new model (LiTS data plus over-and underestimated active learning cases [LiTS-OU]) that performed significantly better on a held-out institutional test set (absolute volume difference of 231 vs 176 mL, P =.0005). In overall survival analysis, predicted liver volumes using the best active learning-trained model (LiTS-OU) were at least comparable with liver volumes extracted from radiology reports and MELD-Na scores in predicting survival. Conclusion: Active transfer learning using surrogate metrics facilitated deployment of deep learning models for clinically meaningful liver segmentation at a major liver transplant center."
1,Improving low-dose pediatric abdominal CT by using convolutional neural networks,"Purpose: To evaluate the efficacy of convolutional neural networks (CNNs) to improve the image quality of low-dose pediatric abdominal CT images. Materials and Methods: Images from 11 pediatric abdominal CT examinations acquired between June and July 2018 were reconstructed with filtered back projection (FBP) and an iterative reconstruction (IR) algorithm. A residual CNN was trained using the FBP image as the input and the difference between FBP and IR as the target such that the network was able to predict the residual image and simulate the IR. CNN-based postprocessing was applied to 20 low-dose pediatric image datasets acquired between December 2016 and December 2017 on a scanner limited to reconstructing FBP images. The FBP and CNN images were evaluated based on objective image noise and subjective image review by two pediatric radiologists. For each of five features, readers rated images on a five-point Likert scale and also indicated their preferred series. Readers also indicated their â€œoverall preferenceâ€ for CNN versus FBP. Preference and Likert scores were analyzed for individual and combined readers. Interreader agreement was assessed. Results: The CT number remained unchanged between FBP and CNN images. Image noise was reduced by 31% for CNN images (P <.001). CNN was preferred for overall image quality for individual and combined readers. For combined Likert scores, at least one of the two score types (Likert or binary preference) indicated a significant favoring of CNN over FBP for low contrast, image noise, artifacts, and high contrast, whereas the reverse was true for spatial resolution. Conclusion: FBP images can be improved in image space by a well-trained CNN, which may afford a reduction in dose or improvement in image quality on scanners limited to FBP reconstruction.","Improving low-dose pediatric abdominal CT by using convolutional neural networks. Purpose: To evaluate the efficacy of convolutional neural networks (CNNs) to improve the image quality of low-dose pediatric abdominal CT images. Materials and Methods: Images from 11 pediatric abdominal CT examinations acquired between June and July 2018 were reconstructed with filtered back projection (FBP) and an iterative reconstruction (IR) algorithm. A residual CNN was trained using the FBP image as the input and the difference between FBP and IR as the target such that the network was able to predict the residual image and simulate the IR. CNN-based postprocessing was applied to 20 low-dose pediatric image datasets acquired between December 2016 and December 2017 on a scanner limited to reconstructing FBP images. The FBP and CNN images were evaluated based on objective image noise and subjective image review by two pediatric radiologists. For each of five features, readers rated images on a five-point Likert scale and also indicated their preferred series. Readers also indicated their â€œoverall preferenceâ€ for CNN versus FBP. Preference and Likert scores were analyzed for individual and combined readers. Interreader agreement was assessed. Results: The CT number remained unchanged between FBP and CNN images. Image noise was reduced by 31% for CNN images (P <.001). CNN was preferred for overall image quality for individual and combined readers. For combined Likert scores, at least one of the two score types (Likert or binary preference) indicated a significant favoring of CNN over FBP for low contrast, image noise, artifacts, and high contrast, whereas the reverse was true for spatial resolution. Conclusion: FBP images can be improved in image space by a well-trained CNN, which may afford a reduction in dose or improvement in image quality on scanners limited to FBP reconstruction."
1,Importance of medical data preprocessing in predictive modeling and risk factor discovery for the frailty syndrome,"BACKGROUND: Increasing life expectancy results in more elderly people struggling with age related diseases and functional conditions. This poses huge challenges towards establishing new approaches for maintaining health at a higher age. An important aspect for age related deterioration of the general patient condition is frailty. The frailty syndrome is associated with a high risk for falls, hospitalization, disability, and finally increased mortality. Using predictive data mining enables the discovery of potential risk factors and can be used as clinical decision support system, which provides the medical doctor with information on the probable clinical patient outcome. This enables the professional to react promptly and to avert likely adverse events in advance. METHODS: Medical data of 474 study participants containing 284 health related parameters, including questionnaire answers, blood parameters and vital parameters from the Toledo Study for Healthy Aging (TSHA) was used. Binary classification models were built in order to distinguish between frail and non-frail study subjects. RESULTS: Using the available TSHA data and the discovered potential predictors, it was possible to design, develop and evaluate a variety of different predictive models for the frailty syndrome. The best performing model was the support vector machine (SVM, 78.31%). Moreover, a methodology was developed, making it possible to explore and to use incomplete medical data and further identify potential predictors and enable interpretability. CONCLUSIONS: This work demonstrates that it is feasible to use incomplete, imbalanced medical data for the development of a predictive model for the frailty syndrome. Moreover, potential predictive factors have been discovered, which were clinically approved by the clinicians. Future work will improve prediction accuracy, especially with regard to separating the group of frail patients into frail and pre-frail ones and analyze the differences among them.","Importance of medical data preprocessing in predictive modeling and risk factor discovery for the frailty syndrome. BACKGROUND: Increasing life expectancy results in more elderly people struggling with age related diseases and functional conditions. This poses huge challenges towards establishing new approaches for maintaining health at a higher age. An important aspect for age related deterioration of the general patient condition is frailty. The frailty syndrome is associated with a high risk for falls, hospitalization, disability, and finally increased mortality. Using predictive data mining enables the discovery of potential risk factors and can be used as clinical decision support system, which provides the medical doctor with information on the probable clinical patient outcome. This enables the professional to react promptly and to avert likely adverse events in advance. METHODS: Medical data of 474 study participants containing 284 health related parameters, including questionnaire answers, blood parameters and vital parameters from the Toledo Study for Healthy Aging (TSHA) was used. Binary classification models were built in order to distinguish between frail and non-frail study subjects. RESULTS: Using the available TSHA data and the discovered potential predictors, it was possible to design, develop and evaluate a variety of different predictive models for the frailty syndrome. The best performing model was the support vector machine (SVM, 78.31%). Moreover, a methodology was developed, making it possible to explore and to use incomplete medical data and further identify potential predictors and enable interpretability. CONCLUSIONS: This work demonstrates that it is feasible to use incomplete, imbalanced medical data for the development of a predictive model for the frailty syndrome. Moreover, potential predictive factors have been discovered, which were clinically approved by the clinicians. Future work will improve prediction accuracy, especially with regard to separating the group of frail patients into frail and pre-frail ones and analyze the differences among them."
1,Detection of medical text semantic similarity based on convolutional neural network,"BACKGROUND: Imaging examinations, such as ultrasonography, magnetic resonance imaging and computed tomography scans, play key roles in healthcare settings. To assess and improve the quality of imaging diagnosis, we need to manually find and compare the pre-existing reports of imaging and pathology examinations which contain overlapping exam body sites from electrical medical records (EMRs). The process of retrieving those reports is time-consuming. In this paper, we propose a convolutional neural network (CNN) based method which can better utilize semantic information contained in report texts to accelerate the retrieving process. METHODS: We included 16,354 imaging and pathology report-pairs from 1926 patients who admitted to Shanghai Tongren Hospital and had ultrasonic examinations between 1st May 2017 and 31st July 2017. We adapted the CNN model to calculate the similarities among the report-pairs to identify target report-pairs with overlapping body sites, and compared the performance with other six conventional models, including keyword mapping, latent semantic analysis (LSA), latent Dirichlet allocation (LDA), Doc2Vec, Siamese long short term memory (LSTM) and a model based on named entity recognition (NER). We also utilized graph embedding method to enhance the word representation by capturing the semantic relations information from medical ontologies. Additionally, we used LIME algorithm to identify which features (or words) are decisive for the prediction results and improved the model interpretability. RESULTS: Experiment results showed that our CNN model gained significant improvement compared to all other conventional models on area under the receiver operating characteristic (AUROC), precision, recall and F1-score in our test dataset. The AUROC of our CNN models gained approximately 3-7% improvement. The AUROC of CNN model with graph-embedding and ontology based medical concept vectors was 0.8% higher than the model with randomly initialized vectors and 1.5% higher than the one with pre-trained word vectors. CONCLUSION: Our study demonstrates that CNN model with pre-trained medical concept vectors could accurately identify target report-pairs with overlapping body sites and potentially accelerate the retrieving process for imaging diagnosis quality measurement.","Detection of medical text semantic similarity based on convolutional neural network. BACKGROUND: Imaging examinations, such as ultrasonography, magnetic resonance imaging and computed tomography scans, play key roles in healthcare settings. To assess and improve the quality of imaging diagnosis, we need to manually find and compare the pre-existing reports of imaging and pathology examinations which contain overlapping exam body sites from electrical medical records (EMRs). The process of retrieving those reports is time-consuming. In this paper, we propose a convolutional neural network (CNN) based method which can better utilize semantic information contained in report texts to accelerate the retrieving process. METHODS: We included 16,354 imaging and pathology report-pairs from 1926 patients who admitted to Shanghai Tongren Hospital and had ultrasonic examinations between 1st May 2017 and 31st July 2017. We adapted the CNN model to calculate the similarities among the report-pairs to identify target report-pairs with overlapping body sites, and compared the performance with other six conventional models, including keyword mapping, latent semantic analysis (LSA), latent Dirichlet allocation (LDA), Doc2Vec, Siamese long short term memory (LSTM) and a model based on named entity recognition (NER). We also utilized graph embedding method to enhance the word representation by capturing the semantic relations information from medical ontologies. Additionally, we used LIME algorithm to identify which features (or words) are decisive for the prediction results and improved the model interpretability. RESULTS: Experiment results showed that our CNN model gained significant improvement compared to all other conventional models on area under the receiver operating characteristic (AUROC), precision, recall and F1-score in our test dataset. The AUROC of our CNN models gained approximately 3-7% improvement. The AUROC of CNN model with graph-embedding and ontology based medical concept vectors was 0.8% higher than the model with randomly initialized vectors and 1.5% higher than the one with pre-trained word vectors. CONCLUSION: Our study demonstrates that CNN model with pre-trained medical concept vectors could accurately identify target report-pairs with overlapping body sites and potentially accelerate the retrieving process for imaging diagnosis quality measurement."
1,Breast pectoral muscle segmentation in mammograms using a modified holistically-nested edge detection network,,
1,An artificial intelligence-enabled ECG algorithm for the identification of patients with atrial fibrillation during sinus rhythm: a retrospective analysis of outcome prediction,"BACKGROUND: Atrial fibrillation is frequently asymptomatic and thus underdetected but is associated with stroke, heart failure, and death. Existing screening methods require prolonged monitoring and are limited by cost and low yield. We aimed to develop a rapid, inexpensive, point-of-care means of identifying patients with atrial fibrillation using machine learning. METHODS: We developed an artificial intelligence (AI)-enabled electrocardiograph (ECG) using a convolutional neural network to detect the electrocardiographic signature of atrial fibrillation present during normal sinus rhythm using standard 10-second, 12-lead ECGs. We included all patients aged 18 years or older with at least one digital, normal sinus rhythm, standard 10-second, 12-lead ECG acquired in the supine position at the Mayo Clinic ECG laboratory between Dec 31, 1993, and July 21, 2017, with rhythm labels validated by trained personnel under cardiologist supervision. We classified patients with at least one ECG with a rhythm of atrial fibrillation or atrial flutter as positive for atrial fibrillation. We allocated ECGs to the training, internal validation, and testing datasets in a 7:1:2 ratio. We calculated the area under the curve (AUC) of the receiver operatoring characteristic curve for the internal validation dataset to select a probability threshold, which we applied to the testing dataset. We evaluated model performance on the testing dataset by calculating the AUC and the accuracy, sensitivity, specificity, and F1 score with two-sided 95% CIs. FINDINGS: We included 180 922 patients with 649 931 normal sinus rhythm ECGs for analysis: 454 789 ECGs recorded from 126 526 patients in the training dataset, 64 340 ECGs from 18 116 patients in the internal validation dataset, and 130 802 ECGs from 36 280 patients in the testing dataset. 3051 (8.4%) patients in the testing dataset had verified atrial fibrillation before the normal sinus rhythm ECG tested by the model. A single AI-enabled ECG identified atrial fibrillation with an AUC of 0.87 (95% CI 0.86-0.88), sensitivity of 79.0% (77.5-80.4), specificity of 79.5% (79.0-79.9), F1 score of 39.2% (38.1-40.3), and overall accuracy of 79.4% (79.0-79.9). Including all ECGs acquired during the first month of each patient's window of interest (ie, the study start date or 31 days before the first recorded atrial fibrillation ECG) increased the AUC to 0.90 (0.90-0.91), sensitivity to 82.3% (80.9-83.6), specificity to 83.4% (83.0-83.8), F1 score to 45.4% (44.2-46.5), and overall accuracy to 83.3% (83.0-83.7). INTERPRETATION: An AI-enabled ECG acquired during normal sinus rhythm permits identification at point of care of individuals with atrial fibrillation. FUNDING: None.","An artificial intelligence-enabled ECG algorithm for the identification of patients with atrial fibrillation during sinus rhythm: a retrospective analysis of outcome prediction. BACKGROUND: Atrial fibrillation is frequently asymptomatic and thus underdetected but is associated with stroke, heart failure, and death. Existing screening methods require prolonged monitoring and are limited by cost and low yield. We aimed to develop a rapid, inexpensive, point-of-care means of identifying patients with atrial fibrillation using machine learning. METHODS: We developed an artificial intelligence (AI)-enabled electrocardiograph (ECG) using a convolutional neural network to detect the electrocardiographic signature of atrial fibrillation present during normal sinus rhythm using standard 10-second, 12-lead ECGs. We included all patients aged 18 years or older with at least one digital, normal sinus rhythm, standard 10-second, 12-lead ECG acquired in the supine position at the Mayo Clinic ECG laboratory between Dec 31, 1993, and July 21, 2017, with rhythm labels validated by trained personnel under cardiologist supervision. We classified patients with at least one ECG with a rhythm of atrial fibrillation or atrial flutter as positive for atrial fibrillation. We allocated ECGs to the training, internal validation, and testing datasets in a 7:1:2 ratio. We calculated the area under the curve (AUC) of the receiver operatoring characteristic curve for the internal validation dataset to select a probability threshold, which we applied to the testing dataset. We evaluated model performance on the testing dataset by calculating the AUC and the accuracy, sensitivity, specificity, and F1 score with two-sided 95% CIs. FINDINGS: We included 180 922 patients with 649 931 normal sinus rhythm ECGs for analysis: 454 789 ECGs recorded from 126 526 patients in the training dataset, 64 340 ECGs from 18 116 patients in the internal validation dataset, and 130 802 ECGs from 36 280 patients in the testing dataset. 3051 (8.4%) patients in the testing dataset had verified atrial fibrillation before the normal sinus rhythm ECG tested by the model. A single AI-enabled ECG identified atrial fibrillation with an AUC of 0.87 (95% CI 0.86-0.88), sensitivity of 79.0% (77.5-80.4), specificity of 79.5% (79.0-79.9), F1 score of 39.2% (38.1-40.3), and overall accuracy of 79.4% (79.0-79.9). Including all ECGs acquired during the first month of each patient's window of interest (ie, the study start date or 31 days before the first recorded atrial fibrillation ECG) increased the AUC to 0.90 (0.90-0.91), sensitivity to 82.3% (80.9-83.6), specificity to 83.4% (83.0-83.8), F1 score to 45.4% (44.2-46.5), and overall accuracy to 83.3% (83.0-83.7). INTERPRETATION: An AI-enabled ECG acquired during normal sinus rhythm permits identification at point of care of individuals with atrial fibrillation. FUNDING: None."
1,Deep Learning for Chest Radiograph Diagnosis in the Emergency Department,"BackgroundThe performance of a deep learning (DL) algorithm should be validated in actual clinical situations, before its clinical implementation.PurposeTo evaluate the performance of a DL algorithm for identifying chest radiographs with clinically relevant abnormalities in the emergency department (ED) setting.Materials and MethodsThis single-center retrospective study included consecutive patients who visited the ED and underwent initial chest radiography between January 1 and March 31, 2017. Chest radiographs were analyzed with a commercially available DL algorithm. The performance of the algorithm was evaluated by determining the area under the receiver operating characteristic curve (AUC), sensitivity, and specificity at predefined operating cutoffs (high-sensitivity and high-specificity cutoffs). The sensitivities and specificities of the algorithm were compared with those of the on-call radiology residents who interpreted the chest radiographs in the actual practice by using McNemar tests. If there were discordant findings between the algorithm and resident, the residents reinterpreted the chest radiographs by using the algorithm's output.ResultsA total of 1135 patients (mean age, 53 years +/- 18; 582 men) were evaluated. In the identification of abnormal chest radiographs, the algorithm showed an AUC of 0.95 (95% confidence interval [CI]: 0.93, 0.96), a sensitivity of 88.7% (227 of 256 radiographs; 95% CI: 84.1%, 92.3%), and a specificity of 69.6% (612 of 879 radiographs; 95% CI: 66.5%, 72.7%) at the high-sensitivity cutoff and a sensitivity of 81.6% (209 of 256 radiographs; 95% CI: 76.3%, 86.2%) and specificity of 90.3% (794 of 879 radiographs; 95% CI: 88.2%, 92.2%) at the high-specificity cutoff. Radiology residents showed lower sensitivity (65.6% [168 of 256 radiographs; 95% CI: 59.5%, 71.4%], P < .001) and higher specificity (98.1% [862 of 879 radiographs; 95% CI: 96.9%, 98.9%], P < .001) compared with the algorithm. After reinterpretation of chest radiographs with use of the algorithm's outputs, the sensitivity of the residents improved (73.4% [188 of 256 radiographs; 95% CI: 68.0%, 78.8%], P = .003), whereas specificity was reduced (94.3% [829 of 879 radiographs; 95% CI: 92.8%, 95.8%], P < .001).ConclusionA deep learning algorithm used with emergency department chest radiographs showed diagnostic performance for identifying clinically relevant abnormalities and helped improve the sensitivity of radiology residents' evaluation.Published under a CC BY 4.0 license.Online supplemental material is available for this article.See also the editorial by Munera and Infante in this issue.","Deep Learning for Chest Radiograph Diagnosis in the Emergency Department. BackgroundThe performance of a deep learning (DL) algorithm should be validated in actual clinical situations, before its clinical implementation.PurposeTo evaluate the performance of a DL algorithm for identifying chest radiographs with clinically relevant abnormalities in the emergency department (ED) setting.Materials and MethodsThis single-center retrospective study included consecutive patients who visited the ED and underwent initial chest radiography between January 1 and March 31, 2017. Chest radiographs were analyzed with a commercially available DL algorithm. The performance of the algorithm was evaluated by determining the area under the receiver operating characteristic curve (AUC), sensitivity, and specificity at predefined operating cutoffs (high-sensitivity and high-specificity cutoffs). The sensitivities and specificities of the algorithm were compared with those of the on-call radiology residents who interpreted the chest radiographs in the actual practice by using McNemar tests. If there were discordant findings between the algorithm and resident, the residents reinterpreted the chest radiographs by using the algorithm's output.ResultsA total of 1135 patients (mean age, 53 years +/- 18; 582 men) were evaluated. In the identification of abnormal chest radiographs, the algorithm showed an AUC of 0.95 (95% confidence interval [CI]: 0.93, 0.96), a sensitivity of 88.7% (227 of 256 radiographs; 95% CI: 84.1%, 92.3%), and a specificity of 69.6% (612 of 879 radiographs; 95% CI: 66.5%, 72.7%) at the high-sensitivity cutoff and a sensitivity of 81.6% (209 of 256 radiographs; 95% CI: 76.3%, 86.2%) and specificity of 90.3% (794 of 879 radiographs; 95% CI: 88.2%, 92.2%) at the high-specificity cutoff. Radiology residents showed lower sensitivity (65.6% [168 of 256 radiographs; 95% CI: 59.5%, 71.4%], P < .001) and higher specificity (98.1% [862 of 879 radiographs; 95% CI: 96.9%, 98.9%], P < .001) compared with the algorithm. After reinterpretation of chest radiographs with use of the algorithm's outputs, the sensitivity of the residents improved (73.4% [188 of 256 radiographs; 95% CI: 68.0%, 78.8%], P = .003), whereas specificity was reduced (94.3% [829 of 879 radiographs; 95% CI: 92.8%, 95.8%], P < .001).ConclusionA deep learning algorithm used with emergency department chest radiographs showed diagnostic performance for identifying clinically relevant abnormalities and helped improve the sensitivity of radiology residents' evaluation.Published under a CC BY 4.0 license.Online supplemental material is available for this article.See also the editorial by Munera and Infante in this issue."
1,Augmented Bladder Tumor Detection Using Deep Learning,"Adequate tumor detection is critical in complete transurethral resection of bladder tumor (TURBT) to reduce cancer recurrence, but up to 20% of bladder tumors are missed by standard white light cystoscopy. Deep learning augmented cystoscopy may improve tumor localization, intraoperative navigation, and surgical resection of bladder cancer. We aimed to develop a deep learning algorithm for augmented cystoscopic detection of bladder cancer. Patients undergoing cystoscopy/TURBT were recruited and white light videos were recorded. Video frames containing histologically confirmed papillary urothelial carcinoma were selected and manually annotated. We constructed CystoNet, an image analysis platform based on convolutional neural networks, for automated bladder tumor detection using a development dataset of 95 patients for algorithm training and five patients for testing. Diagnostic performance of CystoNet was validated prospectively in an additional 54 patients. In the validation dataset, per-frame sensitivity and specificity were 90.9% (95% confidence interval [CI], 90.3-91.6%) and 98.6% (95% CI, 98.5-98.8%), respectively. Per-tumor sensitivity was 90.9% (95% CI, 90.3-91.6%). CystoNet detected 39 of 41 papillary and three of three flat bladder cancers. With high sensitivity and specificity, CystoNet may improve the diagnostic yield of cystoscopy and efficacy of TURBT. PATIENT SUMMARY: Conventional cystoscopy has recognized shortcomings in bladder cancer detection, with implications for recurrence. Cystoscopy augmented with artificial intelligence may improve cancer detection and resection.","Augmented Bladder Tumor Detection Using Deep Learning. Adequate tumor detection is critical in complete transurethral resection of bladder tumor (TURBT) to reduce cancer recurrence, but up to 20% of bladder tumors are missed by standard white light cystoscopy. Deep learning augmented cystoscopy may improve tumor localization, intraoperative navigation, and surgical resection of bladder cancer. We aimed to develop a deep learning algorithm for augmented cystoscopic detection of bladder cancer. Patients undergoing cystoscopy/TURBT were recruited and white light videos were recorded. Video frames containing histologically confirmed papillary urothelial carcinoma were selected and manually annotated. We constructed CystoNet, an image analysis platform based on convolutional neural networks, for automated bladder tumor detection using a development dataset of 95 patients for algorithm training and five patients for testing. Diagnostic performance of CystoNet was validated prospectively in an additional 54 patients. In the validation dataset, per-frame sensitivity and specificity were 90.9% (95% confidence interval [CI], 90.3-91.6%) and 98.6% (95% CI, 98.5-98.8%), respectively. Per-tumor sensitivity was 90.9% (95% CI, 90.3-91.6%). CystoNet detected 39 of 41 papillary and three of three flat bladder cancers. With high sensitivity and specificity, CystoNet may improve the diagnostic yield of cystoscopy and efficacy of TURBT. PATIENT SUMMARY: Conventional cystoscopy has recognized shortcomings in bladder cancer detection, with implications for recurrence. Cystoscopy augmented with artificial intelligence may improve cancer detection and resection."
1,Comparison of methods for early-readmission prediction in a high-dimensional heterogeneous covariates and time-to-event outcome framework,"BACKGROUND: Choosing the most performing method in terms of outcome prediction or variables selection is a recurring problem in prognosis studies, leading to many publications on methods comparison. But some aspects have received little attention. First, most comparison studies treat prediction performance and variable selection aspects separately. Second, methods are either compared within a binary outcome setting (where we want to predict whether the readmission will occur within an arbitrarily chosen delay or not) or within a survival analysis setting (where the outcomes are directly the censored times), but not both. In this paper, we propose a comparison methodology to weight up those different settings both in terms of prediction and variables selection, while incorporating advanced machine learning strategies. METHODS: Using a high-dimensional case study on a sickle-cell disease (SCD) cohort, we compare 8 statistical methods. In the binary outcome setting, we consider logistic regression (LR), support vector machine (SVM), random forest (RF), gradient boosting (GB) and neural network (NN); while on the survival analysis setting, we consider the Cox Proportional Hazards (PH), the CURE and the C-mix models. We also propose a method using Gaussian Processes to extract meaningfull structured covariates from longitudinal data. RESULTS: Among all assessed statistical methods, the survival analysis ones obtain the best results. In particular the C-mix model yields the better performances in both the two considered settings (AUC =0.94 in the binary outcome setting), as well as interesting interpretation aspects. There is some consistency in selected covariates across methods within a setting, but not much across the two settings. CONCLUSIONS: It appears that learning withing the survival analysis setting first (so using all the temporal information), and then going back to a binary prediction using the survival estimates gives significantly better prediction performances than the ones obtained by models trained ""directly"" within the binary outcome setting.","Comparison of methods for early-readmission prediction in a high-dimensional heterogeneous covariates and time-to-event outcome framework. BACKGROUND: Choosing the most performing method in terms of outcome prediction or variables selection is a recurring problem in prognosis studies, leading to many publications on methods comparison. But some aspects have received little attention. First, most comparison studies treat prediction performance and variable selection aspects separately. Second, methods are either compared within a binary outcome setting (where we want to predict whether the readmission will occur within an arbitrarily chosen delay or not) or within a survival analysis setting (where the outcomes are directly the censored times), but not both. In this paper, we propose a comparison methodology to weight up those different settings both in terms of prediction and variables selection, while incorporating advanced machine learning strategies. METHODS: Using a high-dimensional case study on a sickle-cell disease (SCD) cohort, we compare 8 statistical methods. In the binary outcome setting, we consider logistic regression (LR), support vector machine (SVM), random forest (RF), gradient boosting (GB) and neural network (NN); while on the survival analysis setting, we consider the Cox Proportional Hazards (PH), the CURE and the C-mix models. We also propose a method using Gaussian Processes to extract meaningfull structured covariates from longitudinal data. RESULTS: Among all assessed statistical methods, the survival analysis ones obtain the best results. In particular the C-mix model yields the better performances in both the two considered settings (AUC =0.94 in the binary outcome setting), as well as interesting interpretation aspects. There is some consistency in selected covariates across methods within a setting, but not much across the two settings. CONCLUSIONS: It appears that learning withing the survival analysis setting first (so using all the temporal information), and then going back to a binary prediction using the survival estimates gives significantly better prediction performances than the ones obtained by models trained ""directly"" within the binary outcome setting."
1,ThalPred: a web-based prediction tool for discriminating thalassemia trait and iron deficiency anemia,"BACKGROUND: The hypochromic microcytic anemia (HMA) commonly found in Thailand are iron deficiency anemia (IDA) and thalassemia trait (TT). Accurate discrimination between IDA and TT is an important issue and better methods are urgently needed. Although considerable RBC formulas and indices with various optimal cut-off values have been developed, distinguishing between IDA and TT is still a challenging problem due to the diversity of various anemic populations. To address this problem, it is desirable to develop an improved and automated prediction model for discriminating IDA from TT. METHODS: We retrospectively collected laboratory data of HMA found in Thai adults. Five machine learnings, including k-nearest neighbor (k-NN), decision tree, random forest (RF), artificial neural network (ANN) and support vector machine (SVM), were applied to construct a discriminant model. Performance was assessed and compared with thirteen existing discriminant formulas and indices. RESULTS: The data of 186 patients (146 patients with TT and 40 with IDA) were enrolled. The interpretable rules derived from the RF model were proposed to demonstrate the combination of RBC indices for discriminating IDA from TT. A web-based tool 'ThalPred' was implemented using an SVM model based on seven RBC parameters. ThalPred achieved prediction results with an external accuracy, MCC and AUC of 95.59, 0.87 and 0.98, respectively. CONCLUSION: ThalPred and an interpretable rule were provided for distinguishing IDA from TT. For the convenience of health care team experimental scientists, a web-based tool has been established at http://codes.bio/thalpred/ by which users can easily get their desired screening test result without the need to go through the underlying mathematical and computational details.","ThalPred: a web-based prediction tool for discriminating thalassemia trait and iron deficiency anemia. BACKGROUND: The hypochromic microcytic anemia (HMA) commonly found in Thailand are iron deficiency anemia (IDA) and thalassemia trait (TT). Accurate discrimination between IDA and TT is an important issue and better methods are urgently needed. Although considerable RBC formulas and indices with various optimal cut-off values have been developed, distinguishing between IDA and TT is still a challenging problem due to the diversity of various anemic populations. To address this problem, it is desirable to develop an improved and automated prediction model for discriminating IDA from TT. METHODS: We retrospectively collected laboratory data of HMA found in Thai adults. Five machine learnings, including k-nearest neighbor (k-NN), decision tree, random forest (RF), artificial neural network (ANN) and support vector machine (SVM), were applied to construct a discriminant model. Performance was assessed and compared with thirteen existing discriminant formulas and indices. RESULTS: The data of 186 patients (146 patients with TT and 40 with IDA) were enrolled. The interpretable rules derived from the RF model were proposed to demonstrate the combination of RBC indices for discriminating IDA from TT. A web-based tool 'ThalPred' was implemented using an SVM model based on seven RBC parameters. ThalPred achieved prediction results with an external accuracy, MCC and AUC of 95.59, 0.87 and 0.98, respectively. CONCLUSION: ThalPred and an interpretable rule were provided for distinguishing IDA from TT. For the convenience of health care team experimental scientists, a web-based tool has been established at http://codes.bio/thalpred/ by which users can easily get their desired screening test result without the need to go through the underlying mathematical and computational details."
1,Biometric handwriting analysis to support Parkinson's Disease assessment and grading,"BACKGROUND: Handwriting represents one of the major symptom in Parkinson's Disease (PD) patients. The computer-aided analysis of the handwriting allows for the identification of promising patterns that might be useful in PD detection and rating. In this study, we propose an innovative set of features extracted by geometrical, dynamical and muscle activation signals acquired during handwriting tasks, and evaluate the contribution of such features in detecting and rating PD by means of artificial neural networks. METHODS: Eleven healthy subjects and twenty-one PD patients were enrolled in this study. Each involved subject was asked to write three different patterns on a graphic tablet while wearing the Myo Armband used to collect the muscle activation signals of the main forearm muscles. We have then extracted several features related to the written pattern, the movement of the pen and the pressure exerted with the pen and the muscle activations. The computed features have been used to classify healthy subjects versus PD patients and to discriminate mild PD patients from moderate PD patients by using an artificial neural network (ANN). RESULTS: After the training and evaluation of different ANN topologies, the obtained results showed that the proposed features have high relevance in PD detection and rating. In particular, we found that our approach both detect and rate (mild and moderate PD) with a classification accuracy higher than 90%. CONCLUSIONS: In this paper we have investigated the representativeness of a set of proposed features related to handwriting tasks in PD detection and rating. In particular, we used an ANN to classify healthy subjects and PD patients (PD detection), and to classify mild and moderate PD patients (PD rating). The implemented and tested methods showed promising results proven by the high level of accuracy, sensitivity and specificity. Such results suggest the usability of the proposed setup in clinical settings to support the medical decision about Parkinson's Disease.","Biometric handwriting analysis to support Parkinson's Disease assessment and grading. BACKGROUND: Handwriting represents one of the major symptom in Parkinson's Disease (PD) patients. The computer-aided analysis of the handwriting allows for the identification of promising patterns that might be useful in PD detection and rating. In this study, we propose an innovative set of features extracted by geometrical, dynamical and muscle activation signals acquired during handwriting tasks, and evaluate the contribution of such features in detecting and rating PD by means of artificial neural networks. METHODS: Eleven healthy subjects and twenty-one PD patients were enrolled in this study. Each involved subject was asked to write three different patterns on a graphic tablet while wearing the Myo Armband used to collect the muscle activation signals of the main forearm muscles. We have then extracted several features related to the written pattern, the movement of the pen and the pressure exerted with the pen and the muscle activations. The computed features have been used to classify healthy subjects versus PD patients and to discriminate mild PD patients from moderate PD patients by using an artificial neural network (ANN). RESULTS: After the training and evaluation of different ANN topologies, the obtained results showed that the proposed features have high relevance in PD detection and rating. In particular, we found that our approach both detect and rate (mild and moderate PD) with a classification accuracy higher than 90%. CONCLUSIONS: In this paper we have investigated the representativeness of a set of proposed features related to handwriting tasks in PD detection and rating. In particular, we used an ANN to classify healthy subjects and PD patients (PD detection), and to classify mild and moderate PD patients (PD rating). The implemented and tested methods showed promising results proven by the high level of accuracy, sensitivity and specificity. Such results suggest the usability of the proposed setup in clinical settings to support the medical decision about Parkinson's Disease."
1,Classification of Cancer at Prostate MRI: Deep Learning versus Clinical PI-RADS Assessment,,
1,A space-variant visual pathway model for data efficient deep learning,"We present an investigation into adopting a model of the retino-cortical mapping, found in biological visual systems, to improve the efficiency of image analysis using Deep Convolutional Neural Nets (DCNNs) in the context of robot vision and egocentric perception systems. This work has now enabled DCNNs to process input images approaching one million pixels in size, in real time, using only consumer grade graphics processor (GPU) hardware in a single pass of the DCNN.","A space-variant visual pathway model for data efficient deep learning. We present an investigation into adopting a model of the retino-cortical mapping, found in biological visual systems, to improve the efficiency of image analysis using Deep Convolutional Neural Nets (DCNNs) in the context of robot vision and egocentric perception systems. This work has now enabled DCNNs to process input images approaching one million pixels in size, in real time, using only consumer grade graphics processor (GPU) hardware in a single pass of the DCNN."
1,Automatically identifying social isolation from clinical narratives for patients with prostate Cancer,"BACKGROUND: Social isolation is an important social determinant that impacts health outcomes and mortality among patients. The National Academy of Medicine recently recommended that social isolation be documented in electronic health records (EHR). However, social isolation usually is not recorded or obtained as coded data but rather collected from patient self-report or documented in clinical narratives. This study explores the feasibility and effectiveness of natural language processing (NLP) strategy for identifying patients who are socially isolated from clinical narratives. METHOD: We used data from the Medical University of South Carolina (MUSC) Research Data Warehouse. Patients 18â€‰years-of-age or older who were diagnosed with prostate cancer between January 1, 2014 and May 31, 2017 were eligible for this study. NLP pipelines identifying social isolation were developed via extraction of notes on progress, history and physical, consult, emergency department provider, telephone encounter, discharge summary, plan of care, and radiation oncology. Of 4195 eligible prostate cancer patients, we randomly sampled 3138 patients (75%) as a training dataset. The remaining 1057 patients (25%) were used as a test dataset to evaluate NLP algorithm performance. Standard performance measures for the NLP algorithm, including precision, recall, and F-measure, were assessed by expert manual review using the test dataset. RESULTS: A total of 55,516 clinical notes from 3138 patients were included to develop the lexicon and NLP pipelines for social isolation. Of those, 35 unique patients (1.2%) had social isolation mention(s) in 217 notes. Among 24 terms relevant to social isolation, the most prevalent were ""lack of social support,"" ""lonely,"" ""social isolation,"" ""no friends,"" and ""loneliness"". Among 1057 patients in the test dataset, 17 patients (1.6%) were identified as having social isolation mention(s) in 40 clinical notes. Manual review identified four false positive mentions of social isolation and one false negatives in 154 notes from randomly selected 52 controls. The NLP pipeline demonstrated 90% precision, 97% recall, and 93% F-measure. The major reasons for a false positive included the ambiguities of the experiencer of social isolation, negation, and alternate meaning of words. CONCLUSIONS: Our NLP algorithms demonstrate a highly accurate approach to identify social isolation.","Automatically identifying social isolation from clinical narratives for patients with prostate Cancer. BACKGROUND: Social isolation is an important social determinant that impacts health outcomes and mortality among patients. The National Academy of Medicine recently recommended that social isolation be documented in electronic health records (EHR). However, social isolation usually is not recorded or obtained as coded data but rather collected from patient self-report or documented in clinical narratives. This study explores the feasibility and effectiveness of natural language processing (NLP) strategy for identifying patients who are socially isolated from clinical narratives. METHOD: We used data from the Medical University of South Carolina (MUSC) Research Data Warehouse. Patients 18â€‰years-of-age or older who were diagnosed with prostate cancer between January 1, 2014 and May 31, 2017 were eligible for this study. NLP pipelines identifying social isolation were developed via extraction of notes on progress, history and physical, consult, emergency department provider, telephone encounter, discharge summary, plan of care, and radiation oncology. Of 4195 eligible prostate cancer patients, we randomly sampled 3138 patients (75%) as a training dataset. The remaining 1057 patients (25%) were used as a test dataset to evaluate NLP algorithm performance. Standard performance measures for the NLP algorithm, including precision, recall, and F-measure, were assessed by expert manual review using the test dataset. RESULTS: A total of 55,516 clinical notes from 3138 patients were included to develop the lexicon and NLP pipelines for social isolation. Of those, 35 unique patients (1.2%) had social isolation mention(s) in 217 notes. Among 24 terms relevant to social isolation, the most prevalent were ""lack of social support,"" ""lonely,"" ""social isolation,"" ""no friends,"" and ""loneliness"". Among 1057 patients in the test dataset, 17 patients (1.6%) were identified as having social isolation mention(s) in 40 clinical notes. Manual review identified four false positive mentions of social isolation and one false negatives in 154 notes from randomly selected 52 controls. The NLP pipeline demonstrated 90% precision, 97% recall, and 93% F-measure. The major reasons for a false positive included the ambiguities of the experiencer of social isolation, negation, and alternate meaning of words. CONCLUSIONS: Our NLP algorithms demonstrate a highly accurate approach to identify social isolation."
1,Atrial fibrillation classification based on convolutional neural networks,"BACKGROUND: The global age-adjusted mortality rate related to atrial fibrillation (AF) registered a rapid growth in the last four decades, i.e., from 0.8 to 1.6 and 0.9 to 1.7 per 100,000 for men and women during 1990-2010, respectively. In this context, this study uses convolutional neural networks for classifying (diagnosing) AF, employing electrocardiogram data in a general hospital. METHODS: Data came from Anam Hospital in Seoul, Korea, with 20,000 unique patients (10,000 normal sinus rhythm and 10,000 AF). 30 convolutional neural networks were applied and compared for the diagnosis of the normal sinus rhythm vs. AF condition: 6 Alex networks with 5 convolutional layers, 3 fully connected layers and the number of kernels changing from 3 to 256; and 24 residual networks with the number of residuals blocks (or kernels) varying from 8 to 2 (or 64 to 2). RESULTS: In terms of the accuracy, the best Alex network was one with 24 initial kernels (i.e., kernels in the first layer), 5,268,818 parameters and the training time of 89â€‰s (0.997), while the best residual network was one with 6 residual blocks, 32 initial kernels, 248,418 parameters and the training time of 253â€‰s (0.999). In general, the performance of the residual network improved as the number of its residual blocks (its depth) increased. CONCLUSION: For AF diagnosis, the residual network might be a good model with higher accuracy and fewer parameters than its Alex-network counterparts.","Atrial fibrillation classification based on convolutional neural networks. BACKGROUND: The global age-adjusted mortality rate related to atrial fibrillation (AF) registered a rapid growth in the last four decades, i.e., from 0.8 to 1.6 and 0.9 to 1.7 per 100,000 for men and women during 1990-2010, respectively. In this context, this study uses convolutional neural networks for classifying (diagnosing) AF, employing electrocardiogram data in a general hospital. METHODS: Data came from Anam Hospital in Seoul, Korea, with 20,000 unique patients (10,000 normal sinus rhythm and 10,000 AF). 30 convolutional neural networks were applied and compared for the diagnosis of the normal sinus rhythm vs. AF condition: 6 Alex networks with 5 convolutional layers, 3 fully connected layers and the number of kernels changing from 3 to 256; and 24 residual networks with the number of residuals blocks (or kernels) varying from 8 to 2 (or 64 to 2). RESULTS: In terms of the accuracy, the best Alex network was one with 24 initial kernels (i.e., kernels in the first layer), 5,268,818 parameters and the training time of 89â€‰s (0.997), while the best residual network was one with 6 residual blocks, 32 initial kernels, 248,418 parameters and the training time of 253â€‰s (0.999). In general, the performance of the residual network improved as the number of its residual blocks (its depth) increased. CONCLUSION: For AF diagnosis, the residual network might be a good model with higher accuracy and fewer parameters than its Alex-network counterparts."
1,Radiomics model to predict early progression of nonmetastatic nasopharyngeal carcinoma after intensity modulation radiation therapy: A multicenter study,"Purpose: To examine the prognostic value of a machine learning model trained with pretreatment MRI radiomic features in the assessment of patients with nonmetastatic nasopharyngeal carcinoma (NPC) who are at risk for 3-year disease progression after intensitymodulated radiation therapy and to explain the radiomics features in the model. Materials and Methods: A total of 277 patients with nonmetastatic NPC admitted between March 2008 and December 2014 at two imaging centers were retrospectively reviewed. Patients were allocated to a discovery or validation cohort based on where they underwent MRI (discovery cohort, n = 217; validation cohort, n = 60). A total of 525 radiomics features extracted from contrast materialâ€“ enhanced T1- or T2-weighted MRI studies and five clinical features were subjected to radiomic machine learning modeling to predict 3-year disease progression. Feature selection was performed by analyzing robustness to resampling, reproducibility between observers, and redundancy. Features for the final model were selected with Kaplan-Meier analysis and the log-rank test. A support vector machine was used as the classifier for the model. To interpret the pattern learned from the model, Shapley additive explanations (SHAP) was applied. Results: The final model yielded an area under the receiver operating characteristic curve of 0.80 in both the discovery (95% bootstrap confidence interval: 0.80, 0.81) and independent validation (95% bootstrap confidence interval: 0.73, 0.89) cohorts. Analysis with SHAP revealed that tumor shape sphericity, first-order mean absolute deviation, T stage, and overall stage were important factors in 3-year disease progression. Conclusion: These results add to the growing evidence of the role of radiomics in the assessment of NPC. By using explanatory techniques, such as SHAP, the complex interaction of features learned by the model may be understood.","Radiomics model to predict early progression of nonmetastatic nasopharyngeal carcinoma after intensity modulation radiation therapy: A multicenter study. Purpose: To examine the prognostic value of a machine learning model trained with pretreatment MRI radiomic features in the assessment of patients with nonmetastatic nasopharyngeal carcinoma (NPC) who are at risk for 3-year disease progression after intensitymodulated radiation therapy and to explain the radiomics features in the model. Materials and Methods: A total of 277 patients with nonmetastatic NPC admitted between March 2008 and December 2014 at two imaging centers were retrospectively reviewed. Patients were allocated to a discovery or validation cohort based on where they underwent MRI (discovery cohort, n = 217; validation cohort, n = 60). A total of 525 radiomics features extracted from contrast materialâ€“ enhanced T1- or T2-weighted MRI studies and five clinical features were subjected to radiomic machine learning modeling to predict 3-year disease progression. Feature selection was performed by analyzing robustness to resampling, reproducibility between observers, and redundancy. Features for the final model were selected with Kaplan-Meier analysis and the log-rank test. A support vector machine was used as the classifier for the model. To interpret the pattern learned from the model, Shapley additive explanations (SHAP) was applied. Results: The final model yielded an area under the receiver operating characteristic curve of 0.80 in both the discovery (95% bootstrap confidence interval: 0.80, 0.81) and independent validation (95% bootstrap confidence interval: 0.73, 0.89) cohorts. Analysis with SHAP revealed that tumor shape sphericity, first-order mean absolute deviation, T stage, and overall stage were important factors in 3-year disease progression. Conclusion: These results add to the growing evidence of the role of radiomics in the assessment of NPC. By using explanatory techniques, such as SHAP, the complex interaction of features learned by the model may be understood."
1,Automated organ-level classification of free-text pathology reports to support a radiology follow-up tracking engine,"Purpose: To evaluate the performance of machine learning algorithms on organ-level classification of semistructured pathology reports, to incorporate surgical pathology monitoring into an automated imaging recommendation follow-up engine. Materials and Methods: This retrospective study included 2013 pathology reports from patients who underwent abdominal imaging at a large tertiary care center between 2012 and 2018. The reports were labeled by two annotators as relevant to four abdominal organs: Liver, kidneys, pancreas and/or adrenal glands, or none. Automated classification methods were compared: Simple string matching, random forests, extreme gradient boosting, support vector machines, and two neural network architecturesâ€”convolutional neural networks and long short-term memory networks. Three methods from the literature were used to provide interpretability and qualitative validation of the learned network features. Results: The neural networks performed well on the four-organ classification task (F1 score: 96.3% for convolutional neural network and 96.7% for long short-term memory vs 89.9% for support vector machines, 93.9% for extreme gradient boosting, 82.8% for random forests, and 75.2% for simple string matching). Multiple methods were used to visualize the decision-making process of the network, verifying that the networks used similar heuristics to a human annotator. The neural networks were able to classify, with a high degree of accuracy, pathology reports written in unseen formats, suggesting the networks had learned a generalizable encoding of the salient features. Conclusion: Neural network-based approaches achieve high performance on organ-level pathology report classification, suggesting that it is feasible to use them within automated tracking systems.","Automated organ-level classification of free-text pathology reports to support a radiology follow-up tracking engine. Purpose: To evaluate the performance of machine learning algorithms on organ-level classification of semistructured pathology reports, to incorporate surgical pathology monitoring into an automated imaging recommendation follow-up engine. Materials and Methods: This retrospective study included 2013 pathology reports from patients who underwent abdominal imaging at a large tertiary care center between 2012 and 2018. The reports were labeled by two annotators as relevant to four abdominal organs: Liver, kidneys, pancreas and/or adrenal glands, or none. Automated classification methods were compared: Simple string matching, random forests, extreme gradient boosting, support vector machines, and two neural network architecturesâ€”convolutional neural networks and long short-term memory networks. Three methods from the literature were used to provide interpretability and qualitative validation of the learned network features. Results: The neural networks performed well on the four-organ classification task (F1 score: 96.3% for convolutional neural network and 96.7% for long short-term memory vs 89.9% for support vector machines, 93.9% for extreme gradient boosting, 82.8% for random forests, and 75.2% for simple string matching). Multiple methods were used to visualize the decision-making process of the network, verifying that the networks used similar heuristics to a human annotator. The neural networks were able to classify, with a high degree of accuracy, pathology reports written in unseen formats, suggesting the networks had learned a generalizable encoding of the salient features. Conclusion: Neural network-based approaches achieve high performance on organ-level pathology report classification, suggesting that it is feasible to use them within automated tracking systems."
1,Use of natural language processing to improve predictive models for imaging utilization in children presenting to the emergency department,"OBJECTIVE: To examine the association between the medical imaging utilization and information related to patients' socioeconomic, demographic and clinical factors during the patients' ED visits; and to develop predictive models using these associated factors including natural language elements to predict the medical imaging utilization at pediatric ED. METHODS: Pediatric patients' data from the 2012-2016 United States National Hospital Ambulatory Medical Care Survey was included to build the models to predict the use of imaging in children presenting to the ED. Multivariable logistic regression models were built with structured variables such as temperature, heart rate, age, and unstructured variables such as reason for visit, free text nursing notes and combined data available at triage. NLP techniques were used to extract information from the unstructured data. RESULTS: Of the 27,665 pediatric ED visits included in the study, 8394 (30.3%) received medical imaging in the ED, including 6922 (25.0%) who had an X-ray and 1367 (4.9%) who had a computed tomography (CT) scan. In the predictive model including only structured variables, the c-statistic was 0.71 (95% CI: 0.70-0.71) for any imaging use, 0.69 (95% CI: 0.68-0.70) for X-ray, and 0.77 (95% CI: 0.76-0.78) for CT. Models including only unstructured information had c-statistics of 0.81 (95% CI: 0.81-0.82) for any imaging use, 0.82 (95% CI: 0.82-0.83) for X-ray, and 0.85 (95% CI: 0.83-0.86) for CT scans. When both structured variables and free text variables were included, the c-statistics reached 0.82 (95% CI: 0.82-0.83) for any imaging use, 0.83 (95% CI: 0.83-0.84) for X-ray, and 0.87 (95% CI: 0.86-0.88) for CT. CONCLUSIONS: Both CT and X-rays are commonly used in the pediatric ED with one third of the visits receiving at least one. Patients' socioeconomic, demographic and clinical factors presented at ED triage period were associated with the medical imaging utilization. Predictive models combining structured and unstructured variables available at triage performed better than models using structured or unstructured variables alone, suggesting the potential for use of NLP in determining resource utilization.","Use of natural language processing to improve predictive models for imaging utilization in children presenting to the emergency department. OBJECTIVE: To examine the association between the medical imaging utilization and information related to patients' socioeconomic, demographic and clinical factors during the patients' ED visits; and to develop predictive models using these associated factors including natural language elements to predict the medical imaging utilization at pediatric ED. METHODS: Pediatric patients' data from the 2012-2016 United States National Hospital Ambulatory Medical Care Survey was included to build the models to predict the use of imaging in children presenting to the ED. Multivariable logistic regression models were built with structured variables such as temperature, heart rate, age, and unstructured variables such as reason for visit, free text nursing notes and combined data available at triage. NLP techniques were used to extract information from the unstructured data. RESULTS: Of the 27,665 pediatric ED visits included in the study, 8394 (30.3%) received medical imaging in the ED, including 6922 (25.0%) who had an X-ray and 1367 (4.9%) who had a computed tomography (CT) scan. In the predictive model including only structured variables, the c-statistic was 0.71 (95% CI: 0.70-0.71) for any imaging use, 0.69 (95% CI: 0.68-0.70) for X-ray, and 0.77 (95% CI: 0.76-0.78) for CT. Models including only unstructured information had c-statistics of 0.81 (95% CI: 0.81-0.82) for any imaging use, 0.82 (95% CI: 0.82-0.83) for X-ray, and 0.85 (95% CI: 0.83-0.86) for CT scans. When both structured variables and free text variables were included, the c-statistics reached 0.82 (95% CI: 0.82-0.83) for any imaging use, 0.83 (95% CI: 0.83-0.84) for X-ray, and 0.87 (95% CI: 0.86-0.88) for CT. CONCLUSIONS: Both CT and X-rays are commonly used in the pediatric ED with one third of the visits receiving at least one. Patients' socioeconomic, demographic and clinical factors presented at ED triage period were associated with the medical imaging utilization. Predictive models combining structured and unstructured variables available at triage performed better than models using structured or unstructured variables alone, suggesting the potential for use of NLP in determining resource utilization."
1,Disease quantification on PET/CT images without explicit object delineation,"PURPOSE: The derivation of quantitative information from images in a clinically practical way continues to face a major hurdle because of image segmentation challenges. This paper presents a novel approach, called automatic anatomy recognition-disease quantification (AAR-DQ), for disease quantification (DQ) on positron emission tomography/computed tomography (PET/CT) images. This approach explores how to decouple DQ methods from explicit dependence on object (e.g., organ) delineation through the use of only object recognition results from our recently developed automatic anatomy recognition (AAR) method to quantify disease burden. METHOD: The AAR-DQ process starts off with the AAR approach for modeling anatomy and automatically recognizing objects on low-dose CT images of PET/CT acquisitions. It incorporates novel aspects of model building that relate to finding an optimal disease map for each organ. The parameters of the disease map are estimated from a set of training image data sets including normal subjects and patients with metastatic cancer. The result of recognition for an object on a patient image is the location of a fuzzy model for the object which is optimally adjusted for the image. The model is used as a fuzzy mask on the PET image for estimating a fuzzy disease map for the specific patient and subsequently for quantifying disease based on this map. This process handles blur arising in PET images from partial volume effect entirely through accurate fuzzy mapping to account for heterogeneity and gradation of disease content at the voxel level without explicitly performing correction for the partial volume effect. Disease quantification is performed from the fuzzy disease map in terms of total lesion glycolysis (TLG) and standardized uptake value (SUV) statistics. We also demonstrate that the method of disease quantification is applicable even when the ""object"" of interest is recognized manually with a simple and quick action such as interactively specifying a 3D box ROI. Depending on the degree of automaticity for object and lesion recognition on PET/CT, DQ can be performed at the object level either semi-automatically (DQ-MO) or automatically (DQ-AO), or at the lesion level either semi-automatically (DQ-ML) or automatically. RESULTS: We utilized 67 data sets in total: 16 normal data sets used for model building, and 20 phantom data sets plus 31 patient data sets (with various types of metastatic cancer) used for testing the three methods DQ-AO, DQ-MO, and DQ-ML. The parameters of the disease map were estimated using the leave-one-out strategy. The organs of focus were left and right lungs and liver, and the disease quantities measured were TLG, SUVMean, and SUVMax. On phantom data sets, overall error for the three parameters were approximately 6%, 3%, and 0%, respectively, with TLG error varying from 2% for large ""lesions"" (37mm diameter) to 37% for small ""lesions"" (10mm diameter). On patient data sets, for non-conspicuous lesions, those overall errors were approximately 19%, 14% and 0%; for conspicuous lesions, these overall errors were approximately 9%, 7%, 0%, respectively, with errors in estimation being generally smaller for liver than for lungs, although without statistical significance. CONCLUSIONS: Accurate disease quantification on PET/CT images without performing explicit delineation of lesions is feasible following object recognition. Method DQ-MO generally yields more accurate results than DQ-AO although the difference is statistically not significant. Compared to current methods from the literature, almost all of which focus only on lesion-level DQ and not organ-level DQ, our results were comparable for large lesions and were superior for smaller lesions, with less demand on training data and computational resources. DQ-AO and even DQ-MO seem to have the potential for quantifying disease burden body-wide routinely via the AAR-DQ approach.","Disease quantification on PET/CT images without explicit object delineation. PURPOSE: The derivation of quantitative information from images in a clinically practical way continues to face a major hurdle because of image segmentation challenges. This paper presents a novel approach, called automatic anatomy recognition-disease quantification (AAR-DQ), for disease quantification (DQ) on positron emission tomography/computed tomography (PET/CT) images. This approach explores how to decouple DQ methods from explicit dependence on object (e.g., organ) delineation through the use of only object recognition results from our recently developed automatic anatomy recognition (AAR) method to quantify disease burden. METHOD: The AAR-DQ process starts off with the AAR approach for modeling anatomy and automatically recognizing objects on low-dose CT images of PET/CT acquisitions. It incorporates novel aspects of model building that relate to finding an optimal disease map for each organ. The parameters of the disease map are estimated from a set of training image data sets including normal subjects and patients with metastatic cancer. The result of recognition for an object on a patient image is the location of a fuzzy model for the object which is optimally adjusted for the image. The model is used as a fuzzy mask on the PET image for estimating a fuzzy disease map for the specific patient and subsequently for quantifying disease based on this map. This process handles blur arising in PET images from partial volume effect entirely through accurate fuzzy mapping to account for heterogeneity and gradation of disease content at the voxel level without explicitly performing correction for the partial volume effect. Disease quantification is performed from the fuzzy disease map in terms of total lesion glycolysis (TLG) and standardized uptake value (SUV) statistics. We also demonstrate that the method of disease quantification is applicable even when the ""object"" of interest is recognized manually with a simple and quick action such as interactively specifying a 3D box ROI. Depending on the degree of automaticity for object and lesion recognition on PET/CT, DQ can be performed at the object level either semi-automatically (DQ-MO) or automatically (DQ-AO), or at the lesion level either semi-automatically (DQ-ML) or automatically. RESULTS: We utilized 67 data sets in total: 16 normal data sets used for model building, and 20 phantom data sets plus 31 patient data sets (with various types of metastatic cancer) used for testing the three methods DQ-AO, DQ-MO, and DQ-ML. The parameters of the disease map were estimated using the leave-one-out strategy. The organs of focus were left and right lungs and liver, and the disease quantities measured were TLG, SUVMean, and SUVMax. On phantom data sets, overall error for the three parameters were approximately 6%, 3%, and 0%, respectively, with TLG error varying from 2% for large ""lesions"" (37mm diameter) to 37% for small ""lesions"" (10mm diameter). On patient data sets, for non-conspicuous lesions, those overall errors were approximately 19%, 14% and 0%; for conspicuous lesions, these overall errors were approximately 9%, 7%, 0%, respectively, with errors in estimation being generally smaller for liver than for lungs, although without statistical significance. CONCLUSIONS: Accurate disease quantification on PET/CT images without performing explicit delineation of lesions is feasible following object recognition. Method DQ-MO generally yields more accurate results than DQ-AO although the difference is statistically not significant. Compared to current methods from the literature, almost all of which focus only on lesion-level DQ and not organ-level DQ, our results were comparable for large lesions and were superior for smaller lesions, with less demand on training data and computational resources. DQ-AO and even DQ-MO seem to have the potential for quantifying disease burden body-wide routinely via the AAR-DQ approach."
1,Deep Learning for Automated Contouring of Primary Tumor Volumes by MRI for Nasopharyngeal Carcinoma,,
1,Assessment of Deep Natural Language Processing in Ascertaining Oncologic Outcomes From Radiology Reports,"Importance: A rapid learning health care system for oncology will require scalable methods for extracting clinical end points from electronic health records (EHRs). Outside of clinical trials, end points such as cancer progression and response are not routinely encoded into structured data. Objective: To determine whether deep natural language processing can extract relevant cancer outcomes from radiologic reports, a ubiquitous but unstructured EHR data source. Design, Setting, and Participants: A retrospective cohort study evaluated 1112 patients who underwent tumor genotyping for a diagnosis of lung cancer and participated in the Dana-Farber Cancer Institute PROFILE study from June 26, 2013, to July 2, 2018. Exposures: Patients were divided into curation and reserve sets. Human abstractors applied a structured framework to radiologic reports for the curation set to ascertain the presence of cancer and changes in cancer status over time (ie, worsening/progressing vs improving/responding). Deep learning models were then trained to capture these outcomes from report text and subsequently evaluated in a 10% held-out test subset of curation patients. Cox proportional hazards regression models compared human and machine curations of disease-free survival, progression-free survival, and time to improvement/response in the curation set, and measured associations between report classification and overall survival in the curation and reserve sets. Main Outcomes and Measures: The primary outcome was area under the receiver operating characteristic curve (AUC) for deep learning models; secondary outcomes were time to improvement/response, disease-free survival, progression-free survival, and overall survival. Results: A total of 2406 patients were included (mean [SD] age, 66.5 [10.8] years; 1428 female [59.7%]; 2170 [90.2%] white). Radiologic reports (n = 14230) were manually reviewed for 1112 patients in the curation set. In the test subset (n = 109), deep learning models identified the presence of cancer, improvement/response, and worsening/progression with accurate discrimination (AUC >0.90). Machine and human curation yielded similar measurements of disease-free survival (hazard ratio [HR] for machine vs human curation, 1.18; 95% CI, 0.71-1.95); progression-free survival (HR, 1.11; 95% CI, 0.71-1.71); and time to improvement/response (HR, 1.03; 95% CI, 0.65-1.64). Among 15000 additional reports for 1294 reserve set patients, algorithm-detected cancer worsening/progression was associated with decreased overall survival (HR for mortality, 4.04; 95% CI, 2.78-5.85), and improvement/response was associated with increased overall survival (HR, 0.41; 95% CI, 0.22-0.77). Conclusions and Relevance: Deep natural language processing appears to speed curation of relevant cancer outcomes and facilitate rapid learning from EHR data.","Assessment of Deep Natural Language Processing in Ascertaining Oncologic Outcomes From Radiology Reports. Importance: A rapid learning health care system for oncology will require scalable methods for extracting clinical end points from electronic health records (EHRs). Outside of clinical trials, end points such as cancer progression and response are not routinely encoded into structured data. Objective: To determine whether deep natural language processing can extract relevant cancer outcomes from radiologic reports, a ubiquitous but unstructured EHR data source. Design, Setting, and Participants: A retrospective cohort study evaluated 1112 patients who underwent tumor genotyping for a diagnosis of lung cancer and participated in the Dana-Farber Cancer Institute PROFILE study from June 26, 2013, to July 2, 2018. Exposures: Patients were divided into curation and reserve sets. Human abstractors applied a structured framework to radiologic reports for the curation set to ascertain the presence of cancer and changes in cancer status over time (ie, worsening/progressing vs improving/responding). Deep learning models were then trained to capture these outcomes from report text and subsequently evaluated in a 10% held-out test subset of curation patients. Cox proportional hazards regression models compared human and machine curations of disease-free survival, progression-free survival, and time to improvement/response in the curation set, and measured associations between report classification and overall survival in the curation and reserve sets. Main Outcomes and Measures: The primary outcome was area under the receiver operating characteristic curve (AUC) for deep learning models; secondary outcomes were time to improvement/response, disease-free survival, progression-free survival, and overall survival. Results: A total of 2406 patients were included (mean [SD] age, 66.5 [10.8] years; 1428 female [59.7%]; 2170 [90.2%] white). Radiologic reports (n = 14230) were manually reviewed for 1112 patients in the curation set. In the test subset (n = 109), deep learning models identified the presence of cancer, improvement/response, and worsening/progression with accurate discrimination (AUC >0.90). Machine and human curation yielded similar measurements of disease-free survival (hazard ratio [HR] for machine vs human curation, 1.18; 95% CI, 0.71-1.95); progression-free survival (HR, 1.11; 95% CI, 0.71-1.71); and time to improvement/response (HR, 1.03; 95% CI, 0.65-1.64). Among 15000 additional reports for 1294 reserve set patients, algorithm-detected cancer worsening/progression was associated with decreased overall survival (HR for mortality, 4.04; 95% CI, 2.78-5.85), and improvement/response was associated with increased overall survival (HR, 0.41; 95% CI, 0.22-0.77). Conclusions and Relevance: Deep natural language processing appears to speed curation of relevant cancer outcomes and facilitate rapid learning from EHR data."
1,Medical image classification using synergic deep learning,"The classification of medical images is an essential task in computer-aided diagnosis, medical image retrieval and mining. Although deep learning has shown proven advantages over traditional methods that rely on the handcrafted features, it remains challenging due to the significant intra-class variation and inter-class similarity caused by the diversity of imaging modalities and clinical pathologies. In this paper, we propose a synergic deep learning (SDL) model to address this issue by using multiple deep convolutional neural networks (DCNNs) simultaneously and enabling them to mutually learn from each other. Each pair of DCNNs has their learned image representation concatenated as the input of a synergic network, which has a fully connected structure that predicts whether the pair of input images belong to the same class. Thus, if one DCNN makes a correct classification, a mistake made by the other DCNN leads to a synergic error that serves as an extra force to update the model. This model can be trained end-to-end under the supervision of classification errors from DCNNs and synergic errors from each pair of DCNNs. Our experimental results on the ImageCLEF-2015, ImageCLEF-2016, ISIC-2016, and ISIC-2017 datasets indicate that the proposed SDL model achieves the state-of-the-art performance in these medical image classification tasks.","Medical image classification using synergic deep learning. The classification of medical images is an essential task in computer-aided diagnosis, medical image retrieval and mining. Although deep learning has shown proven advantages over traditional methods that rely on the handcrafted features, it remains challenging due to the significant intra-class variation and inter-class similarity caused by the diversity of imaging modalities and clinical pathologies. In this paper, we propose a synergic deep learning (SDL) model to address this issue by using multiple deep convolutional neural networks (DCNNs) simultaneously and enabling them to mutually learn from each other. Each pair of DCNNs has their learned image representation concatenated as the input of a synergic network, which has a fully connected structure that predicts whether the pair of input images belong to the same class. Thus, if one DCNN makes a correct classification, a mistake made by the other DCNN leads to a synergic error that serves as an extra force to update the model. This model can be trained end-to-end under the supervision of classification errors from DCNNs and synergic errors from each pair of DCNNs. Our experimental results on the ImageCLEF-2015, ImageCLEF-2016, ISIC-2016, and ISIC-2017 datasets indicate that the proposed SDL model achieves the state-of-the-art performance in these medical image classification tasks."
1,Identification of Vertebral Fractures by Convolutional Neural Networks to Predict Nonvertebral and Hip Fractures: A Registry-based Cohort Study of Dual X-ray Absorptiometry,"Background Detection of vertebral fractures (VFs) aids in management of osteoporosis and targeting of fracture prevention therapies. Purpose To determine whether convolutional neural networks (CNNs) can be trained to identify VFs at VF assessment (VFA) performed with dual-energy x-ray absorptiometry and if VFs identified by CNNs confer a similar prognosis compared with the expert reader reference standard. Materials and Methods In this retrospective study, 12 742 routine clinical VFA images obtained from February 2010 to December 2017 and reported as VF present or absent were used for CNN training and testing. All reporting physicians were diagnostic imaging specialists with at least 10 years of experience. Randomly selected training and validation sets were used to produce a CNN ensemble that calculates VF probability. A test set (30%; 3822 images) was used to assess CNN agreement with the human expert reader reference standard and CNN prediction of incident non-VFs. Statistical analyses included area under the receiver operating characteristic curve, two-tailed Student t tests, prevalence- and bias-adjusted kappa value, Kaplan-Meier curves, and Cox proportional hazard models. Results This study included 12 742 patients (mean age, 76 years +/- 7; 12 013 women). The CNN ensemble demonstrated an area under the receiver operating characteristic curve of 0.94 (95% confidence interval [CI]: 0.93, 0.95) for VF detection that corresponded to sensitivity of 87.4% (534 of 611), specificity of 88.4% (2838 of 3211), and prevalence- and bias-adjusted kappa value of 0.77. On the basis of incident fracture data available for 2813 patients (mean follow up, 3.7 years), hazard ratios adjusted for baseline fracture probability were 1.7 (95% CI: 1.3, 2.2) for CNN versus 1.8 (95% CI: 1.3, 2.3) for expert reader-detected VFs for incident non-VF and 2.3 (95% CI: 1.5, 3.5) versus 2.4 (95% CI: 1.5, 3.7) for incident hip fracture. Conclusion Convolutional neural networks can identify vertebral fractures on vertebral fracture assessment images with high accuracy, and these convolutional neural network-identified vertebral fractures predict clinical fracture outcomes. (c) RSNA, 2019 Online supplemental material is available for this article.","Identification of Vertebral Fractures by Convolutional Neural Networks to Predict Nonvertebral and Hip Fractures: A Registry-based Cohort Study of Dual X-ray Absorptiometry. Background Detection of vertebral fractures (VFs) aids in management of osteoporosis and targeting of fracture prevention therapies. Purpose To determine whether convolutional neural networks (CNNs) can be trained to identify VFs at VF assessment (VFA) performed with dual-energy x-ray absorptiometry and if VFs identified by CNNs confer a similar prognosis compared with the expert reader reference standard. Materials and Methods In this retrospective study, 12 742 routine clinical VFA images obtained from February 2010 to December 2017 and reported as VF present or absent were used for CNN training and testing. All reporting physicians were diagnostic imaging specialists with at least 10 years of experience. Randomly selected training and validation sets were used to produce a CNN ensemble that calculates VF probability. A test set (30%; 3822 images) was used to assess CNN agreement with the human expert reader reference standard and CNN prediction of incident non-VFs. Statistical analyses included area under the receiver operating characteristic curve, two-tailed Student t tests, prevalence- and bias-adjusted kappa value, Kaplan-Meier curves, and Cox proportional hazard models. Results This study included 12 742 patients (mean age, 76 years +/- 7; 12 013 women). The CNN ensemble demonstrated an area under the receiver operating characteristic curve of 0.94 (95% confidence interval [CI]: 0.93, 0.95) for VF detection that corresponded to sensitivity of 87.4% (534 of 611), specificity of 88.4% (2838 of 3211), and prevalence- and bias-adjusted kappa value of 0.77. On the basis of incident fracture data available for 2813 patients (mean follow up, 3.7 years), hazard ratios adjusted for baseline fracture probability were 1.7 (95% CI: 1.3, 2.2) for CNN versus 1.8 (95% CI: 1.3, 2.3) for expert reader-detected VFs for incident non-VF and 2.3 (95% CI: 1.5, 3.5) versus 2.4 (95% CI: 1.5, 3.7) for incident hip fracture. Conclusion Convolutional neural networks can identify vertebral fractures on vertebral fracture assessment images with high accuracy, and these convolutional neural network-identified vertebral fractures predict clinical fracture outcomes. (c) RSNA, 2019 Online supplemental material is available for this article."
1,Combination of peri- and intratumoral radiomic features on baseline CT scans predicts response to chemotherapy in lung adenocarcinoma,"Purpose: To identify the role of radiomics texture features both within and outside the nodule in predicting (a) time to progression (TTP) and overall survival (OS) as well as (b) response to chemotherapy in patients with nonâ€“small cell lung cancer (NSCLC). Materials and Methods: Data in a total of 125 patients who had been treated with pemetrexed-based platinum doublet chemotherapy at Cleveland Clinic were retrospectively analyzed. The patients were divided randomly into two sets with the constraint that there were an equal number of responders and nonresponders in the training set. The training set comprised 53 patients with NSCLC, and the validation set comprised 72 patients. A machine learning classifier trained with radiomic texture features extracted from intra- and peritumoral regions of nonâ€“contrast-enhanced CT images was used to predict response to chemotherapy. The radiomic risk-score signature was generated by using least absolute shrinkage and selection operator with the Cox regression model; association of the radiomic signature with TTP and OS was also evaluated. Results: A combination of radiomic features in conjunction with a quadratic discriminant analysis classifier yielded a mean maximum area under the receiver operating characteristic curve (AUC) of 0.82 Â± 0.09 (standard deviation) in the training set and a corresponding AUC of 0.77 in the independent testing set. The radiomics signature was also significantly associated with TTP (hazard ratio [HR], 2.8; 95% confidence interval [CI]: 1.95, 4.00; P <.0001) and OS (HR, 2.35; 95% CI: 1.41, 3.94; P =.0011). Additionally, decision curve analysis demonstrated that in terms of clinical usefulness, the radiomics signature had a higher overall net benefit in prediction of high-risk patients to receive treatment than the clinicopathologic measurements. Conclusion: This study suggests that radiomic texture features extracted from within and around the nodule on baseline CT scans are (a) predictive of response to chemotherapy and (b) associated with TTP and OS for patients with NSCLC.","Combination of peri- and intratumoral radiomic features on baseline CT scans predicts response to chemotherapy in lung adenocarcinoma. Purpose: To identify the role of radiomics texture features both within and outside the nodule in predicting (a) time to progression (TTP) and overall survival (OS) as well as (b) response to chemotherapy in patients with nonâ€“small cell lung cancer (NSCLC). Materials and Methods: Data in a total of 125 patients who had been treated with pemetrexed-based platinum doublet chemotherapy at Cleveland Clinic were retrospectively analyzed. The patients were divided randomly into two sets with the constraint that there were an equal number of responders and nonresponders in the training set. The training set comprised 53 patients with NSCLC, and the validation set comprised 72 patients. A machine learning classifier trained with radiomic texture features extracted from intra- and peritumoral regions of nonâ€“contrast-enhanced CT images was used to predict response to chemotherapy. The radiomic risk-score signature was generated by using least absolute shrinkage and selection operator with the Cox regression model; association of the radiomic signature with TTP and OS was also evaluated. Results: A combination of radiomic features in conjunction with a quadratic discriminant analysis classifier yielded a mean maximum area under the receiver operating characteristic curve (AUC) of 0.82 Â± 0.09 (standard deviation) in the training set and a corresponding AUC of 0.77 in the independent testing set. The radiomics signature was also significantly associated with TTP (hazard ratio [HR], 2.8; 95% confidence interval [CI]: 1.95, 4.00; P <.0001) and OS (HR, 2.35; 95% CI: 1.41, 3.94; P =.0011). Additionally, decision curve analysis demonstrated that in terms of clinical usefulness, the radiomics signature had a higher overall net benefit in prediction of high-risk patients to receive treatment than the clinicopathologic measurements. Conclusion: This study suggests that radiomic texture features extracted from within and around the nodule on baseline CT scans are (a) predictive of response to chemotherapy and (b) associated with TTP and OS for patients with NSCLC."
1,Multiview Cluster Analysis Identifies Variable Corticosteroid Response Phenotypes in Severe Asthma,,
1,Machine Learning to Predict the Likelihood of Acute Myocardial Infarction,"BACKGROUND: Variations in cardiac troponin concentrations by age, sex and time between samples in patients with suspected myocardial infarction are not currently accounted for in diagnostic approaches. We aimed to combine these variables through machine learning to improve the assessment of risk for individual patients. METHODS: A machine learning algorithm (myocardial-ischemic-injury-index [MI(3)]) incorporating age, sex, and paired high-sensitivity cardiac troponin I concentrations, was trained on 3,013 patients and tested on 7,998 patients with suspected myocardial infarction. MI(3) uses gradient boosting to compute a value (0-100) reflecting an individual's likelihood of a diagnosis of type 1 myocardial infarction and estimates the sensitivity, negative predictive value (NPV), specificity and positive predictive value (PPV) for that individual. Assessment was by calibration and area under the receiver-operating-characteristic curve (AUC). Secondary analysis evaluated example MI(3) thresholds from the training set that identified patients as low-risk (99% sensitivity) and high-risk (75% PPV), and performance at these thresholds was compared in the test set to the 99th percentile and European Society of Cardiology (ESC) rule-out pathways. RESULTS: Myocardial infarction occurred in 404 (13.4%) patients in the training set and 849 (10.6%) patients in the test set. MI(3) was well calibrated with a very high AUC of 0.963 [0.956-0.971] in the test set and similar performance in early and late presenters. Example MI(3) thresholds identifying low-risk and high-risk patients in the training set were 1.6 and 49.7 respectively. In the test set, MI(3) values were <1.6 in 69.5% with a NPV of 99.7% (99.5%-99.8%) and sensitivity of 97.8% (96.7-98.7%), and were >/=49.7 in 10.6% with a PPV of 71.8% (68.9-75.0%) and specificity of 96.7% (96.3-97.1%). Using these thresholds, MI(3) performed better than the ESC 0/3-hour pathway (sensitivity 82.5% [74.5-88.8%], specificity 92.2% [90.7-93.5%]) and the 99th percentile at any time-point (sensitivity 89.6% [87.4-91.6%]), specificity 89.3% [88.6-90.0%]). CONCLUSIONS: Using machine learning, MI(3) provides an individualized and objective assessment of the likelihood of myocardial infarction, which can be used to identify low-risk and high-risk patients who may benefit from earlier clinical decisions. CLINICAL TRIAL REGISTRATION: Unique Identifier: Australian New Zealand Clinical Trials Registry: ACTRN12616001441404. URL: https://www.anzctr.org.au.","Machine Learning to Predict the Likelihood of Acute Myocardial Infarction. BACKGROUND: Variations in cardiac troponin concentrations by age, sex and time between samples in patients with suspected myocardial infarction are not currently accounted for in diagnostic approaches. We aimed to combine these variables through machine learning to improve the assessment of risk for individual patients. METHODS: A machine learning algorithm (myocardial-ischemic-injury-index [MI(3)]) incorporating age, sex, and paired high-sensitivity cardiac troponin I concentrations, was trained on 3,013 patients and tested on 7,998 patients with suspected myocardial infarction. MI(3) uses gradient boosting to compute a value (0-100) reflecting an individual's likelihood of a diagnosis of type 1 myocardial infarction and estimates the sensitivity, negative predictive value (NPV), specificity and positive predictive value (PPV) for that individual. Assessment was by calibration and area under the receiver-operating-characteristic curve (AUC). Secondary analysis evaluated example MI(3) thresholds from the training set that identified patients as low-risk (99% sensitivity) and high-risk (75% PPV), and performance at these thresholds was compared in the test set to the 99th percentile and European Society of Cardiology (ESC) rule-out pathways. RESULTS: Myocardial infarction occurred in 404 (13.4%) patients in the training set and 849 (10.6%) patients in the test set. MI(3) was well calibrated with a very high AUC of 0.963 [0.956-0.971] in the test set and similar performance in early and late presenters. Example MI(3) thresholds identifying low-risk and high-risk patients in the training set were 1.6 and 49.7 respectively. In the test set, MI(3) values were <1.6 in 69.5% with a NPV of 99.7% (99.5%-99.8%) and sensitivity of 97.8% (96.7-98.7%), and were >/=49.7 in 10.6% with a PPV of 71.8% (68.9-75.0%) and specificity of 96.7% (96.3-97.1%). Using these thresholds, MI(3) performed better than the ESC 0/3-hour pathway (sensitivity 82.5% [74.5-88.8%], specificity 92.2% [90.7-93.5%]) and the 99th percentile at any time-point (sensitivity 89.6% [87.4-91.6%]), specificity 89.3% [88.6-90.0%]). CONCLUSIONS: Using machine learning, MI(3) provides an individualized and objective assessment of the likelihood of myocardial infarction, which can be used to identify low-risk and high-risk patients who may benefit from earlier clinical decisions. CLINICAL TRIAL REGISTRATION: Unique Identifier: Australian New Zealand Clinical Trials Registry: ACTRN12616001441404. URL: https://www.anzctr.org.au."
1,Breast cancer histopathology image classification through assembling multiple compact CNNs,"BACKGROUND: Breast cancer causes hundreds of thousands of deaths each year worldwide. The early stage diagnosis and treatment can significantly reduce the mortality rate. However, the traditional manual diagnosis needs intense workload, and diagnostic errors are prone to happen with the prolonged work of pathologists. Automatic histopathology image recognition plays a key role in speeding up diagnosis and improving the quality of diagnosis. METHODS: In this work, we propose a breast cancer histopathology image classification by assembling multiple compact Convolutional Neural Networks (CNNs). First, a hybrid CNN architecture is designed, which contains a global model branch and a local model branch. By local voting and two-branch information merging, our hybrid model obtains stronger representation ability. Second, by embedding the proposed Squeeze-Excitation-Pruning (SEP) block into our hybrid model, the channel importance can be learned and the redundant channels are thus removed. The proposed channel pruning scheme can decrease the risk of overfitting and produce higher accuracy with the same model size. At last, with different data partition and composition, we build multiple models and assemble them together to further enhance the model generalization ability. RESULTS: Experimental results show that in public BreaKHis dataset, our proposed hybrid model achieves comparable performance with the state-of-the-art. By adopting the multi-model assembling scheme, our method outperforms the state-of-the-art in both patient level and image level accuracy for BACH dataset. CONCLUSIONS: We propose a novel compact breast cancer histopathology image classification scheme by assembling multiple compact hybrid CNNs. The proposed scheme achieves promising results for the breast cancer image classification task. Our method can be used in breast cancer auxiliary diagnostic scenario, and it can reduce the workload of pathologists as well as improve the quality of diagnosis.","Breast cancer histopathology image classification through assembling multiple compact CNNs. BACKGROUND: Breast cancer causes hundreds of thousands of deaths each year worldwide. The early stage diagnosis and treatment can significantly reduce the mortality rate. However, the traditional manual diagnosis needs intense workload, and diagnostic errors are prone to happen with the prolonged work of pathologists. Automatic histopathology image recognition plays a key role in speeding up diagnosis and improving the quality of diagnosis. METHODS: In this work, we propose a breast cancer histopathology image classification by assembling multiple compact Convolutional Neural Networks (CNNs). First, a hybrid CNN architecture is designed, which contains a global model branch and a local model branch. By local voting and two-branch information merging, our hybrid model obtains stronger representation ability. Second, by embedding the proposed Squeeze-Excitation-Pruning (SEP) block into our hybrid model, the channel importance can be learned and the redundant channels are thus removed. The proposed channel pruning scheme can decrease the risk of overfitting and produce higher accuracy with the same model size. At last, with different data partition and composition, we build multiple models and assemble them together to further enhance the model generalization ability. RESULTS: Experimental results show that in public BreaKHis dataset, our proposed hybrid model achieves comparable performance with the state-of-the-art. By adopting the multi-model assembling scheme, our method outperforms the state-of-the-art in both patient level and image level accuracy for BACH dataset. CONCLUSIONS: We propose a novel compact breast cancer histopathology image classification scheme by assembling multiple compact hybrid CNNs. The proposed scheme achieves promising results for the breast cancer image classification task. Our method can be used in breast cancer auxiliary diagnostic scenario, and it can reduce the workload of pathologists as well as improve the quality of diagnosis."
1,Automatically Charting Symptoms From Patient-Physician Conversations Using Machine Learning,,
1,Integrating spatial configuration into heatmap regression based CNNs for landmark localization,,
1,A comparison of machine learning techniques for classification of HIV patients with antiretroviral therapy-induced mitochondrial toxicity from those without mitochondrial toxicity,"BACKGROUND: Antiretroviral therapy (ART) has significantly reduced HIV-related morbidity and mortality. However, therapeutic benefit of ART is often limited by delayed drug-associated toxicity. Nucleoside reverse transcriptase inhibitors (NRTIs) are the backbone of ART regimens. NRTIs compete with endogenous deoxyribonucleotide triphosphates (dNTPs) in incorporation into elongating DNA chain resulting in their cytotoxic or antiviral effect. Thus, the efficacy of NRTIs could be affected by direct competition with endogenous dNTPs and/or feedback inhibition of their metabolic enzymes. In this paper, we assessed whether the levels of ribonucleotides (RN) and dNTP pool sizes can be used as biomarkers in distinguishing between HIV-infected patients with ART-induced mitochondrial toxicity and HIV-infected patients without toxicity. METHODS: We used data collected through a case-control study from 50 subjects. Cases were defined as HIV-infected individuals with clinical and/or laboratory evidence of mitochondrial toxicity. Each case was age, gender, and race matched with an HIV-positive without evidence of toxicity. We used a range of machine learning procedures to distinguish between patients with and without toxicity. Using resampling methods like Monte Carlo k-fold cross validation, we compared the accuracy of several machine learning algorithms applied to our data. We used the algorithm with highest classification accuracy rate in evaluating the diagnostic performance of 12 RN and 14 dNTP pool sizes as biomarkers of mitochondrial toxicity. RESULTS: We used eight classification algorithms to assess the diagnostic performance of RN and dNTP pool sizes distinguishing HIV patients with and without NRTI-associated mitochondrial toxicity. The algorithms resulted in cross-validated classification rates of 0.65-0.76 for dNTP and 0.72-0.83 for RN, following reduction of the dimensionality of the input data. The reduction of input variables improved the classification performance of the algorithms, with the most pronounced improvement for RN. Complex tree-based methods worked the best for both the deoxyribose dataset (Random Forest) and the ribose dataset (Classification Tree and AdaBoost), but it is worth noting that simple methods such as Linear Discriminant Analysis and Logistic Regression were very competitive in terms of classification performance. CONCLUSIONS: Our finding of changes in RN and dNTP pools in participants with mitochondrial toxicity validates the importance of dNTP pools in mitochondrial function. Hence, levels of RN and dNTP pools can be used as biomarkers of ART-induced mitochondrial toxicity.","A comparison of machine learning techniques for classification of HIV patients with antiretroviral therapy-induced mitochondrial toxicity from those without mitochondrial toxicity. BACKGROUND: Antiretroviral therapy (ART) has significantly reduced HIV-related morbidity and mortality. However, therapeutic benefit of ART is often limited by delayed drug-associated toxicity. Nucleoside reverse transcriptase inhibitors (NRTIs) are the backbone of ART regimens. NRTIs compete with endogenous deoxyribonucleotide triphosphates (dNTPs) in incorporation into elongating DNA chain resulting in their cytotoxic or antiviral effect. Thus, the efficacy of NRTIs could be affected by direct competition with endogenous dNTPs and/or feedback inhibition of their metabolic enzymes. In this paper, we assessed whether the levels of ribonucleotides (RN) and dNTP pool sizes can be used as biomarkers in distinguishing between HIV-infected patients with ART-induced mitochondrial toxicity and HIV-infected patients without toxicity. METHODS: We used data collected through a case-control study from 50 subjects. Cases were defined as HIV-infected individuals with clinical and/or laboratory evidence of mitochondrial toxicity. Each case was age, gender, and race matched with an HIV-positive without evidence of toxicity. We used a range of machine learning procedures to distinguish between patients with and without toxicity. Using resampling methods like Monte Carlo k-fold cross validation, we compared the accuracy of several machine learning algorithms applied to our data. We used the algorithm with highest classification accuracy rate in evaluating the diagnostic performance of 12 RN and 14 dNTP pool sizes as biomarkers of mitochondrial toxicity. RESULTS: We used eight classification algorithms to assess the diagnostic performance of RN and dNTP pool sizes distinguishing HIV patients with and without NRTI-associated mitochondrial toxicity. The algorithms resulted in cross-validated classification rates of 0.65-0.76 for dNTP and 0.72-0.83 for RN, following reduction of the dimensionality of the input data. The reduction of input variables improved the classification performance of the algorithms, with the most pronounced improvement for RN. Complex tree-based methods worked the best for both the deoxyribose dataset (Random Forest) and the ribose dataset (Classification Tree and AdaBoost), but it is worth noting that simple methods such as Linear Discriminant Analysis and Logistic Regression were very competitive in terms of classification performance. CONCLUSIONS: Our finding of changes in RN and dNTP pools in participants with mitochondrial toxicity validates the importance of dNTP pools in mitochondrial function. Hence, levels of RN and dNTP pools can be used as biomarkers of ART-induced mitochondrial toxicity."
1,Quantifying the effects of data augmentation and stain color normalization in convolutional neural networks for computational pathology,"Stain variation is a phenomenon observed when distinct pathology laboratories stain tissue slides that exhibit similar but not identical color appearance. Due to this color shift between laboratories, convolutional neural networks (CNNs) trained with images from one lab often underperform on unseen images from the other lab. Several techniques have been proposed to reduce the generalization error, mainly grouped into two categories: stain color augmentation and stain color normalization. The former simulates a wide variety of realistic stain variations during training, producing stain-invariant CNNs. The latter aims to match training and test color distributions in order to reduce stain variation. For the first time, we compared some of these techniques and quantified their effect on CNN classification performance using a heterogeneous dataset of hematoxylin and eosin histopathology images from 4 organs and 9 pathology laboratories. Additionally, we propose a novel unsupervised method to perform stain color normalization using a neural network. Based on our experimental results, we provide practical guidelines on how to use stain color augmentation and stain color normalization in future computational pathology applications.","Quantifying the effects of data augmentation and stain color normalization in convolutional neural networks for computational pathology. Stain variation is a phenomenon observed when distinct pathology laboratories stain tissue slides that exhibit similar but not identical color appearance. Due to this color shift between laboratories, convolutional neural networks (CNNs) trained with images from one lab often underperform on unseen images from the other lab. Several techniques have been proposed to reduce the generalization error, mainly grouped into two categories: stain color augmentation and stain color normalization. The former simulates a wide variety of realistic stain variations during training, producing stain-invariant CNNs. The latter aims to match training and test color distributions in order to reduce stain variation. For the first time, we compared some of these techniques and quantified their effect on CNN classification performance using a heterogeneous dataset of hematoxylin and eosin histopathology images from 4 organs and 9 pathology laboratories. Additionally, we propose a novel unsupervised method to perform stain color normalization using a neural network. Based on our experimental results, we provide practical guidelines on how to use stain color augmentation and stain color normalization in future computational pathology applications."
1,A Quantitative Severity Scale for Retinopathy of Prematurity Using Deep Learning to Monitor Disease Regression After Treatment,"Importance: Retinopathy of prematurity (ROP) is a leading cause of childhood blindness worldwide, but treatment failure and disease recurrence are important causes of adverse outcomes in patients with treatment-requiring ROP (TR-ROP). Objectives: To apply an automated ROP vascular severity score obtained using a deep learning algorithm and to assess its utility for objectively monitoring ROP regression after treatment. Design, Setting, and Participants: This retrospective cohort study used data from the Imaging and Informatics in ROP consortium, which comprises 9 tertiary referral centers in North America that screen high volumes of at-risk infants for ROP. Images of 5255 clinical eye examinations from 871 infants performed between July 2011 and December 2016 were assessed for eligibility in the present study. The disease course was assessed with time across the numerous examinations for patients with TR-ROP. Infants born prematurely meeting screening criteria for ROP who developed TR-ROP and who had images captured within 4 weeks before and after treatment as well as at the time of treatment were included. Main Outcomes and Measures: The primary outcome was mean (SD) ROP vascular severity score before, at time of, and after treatment. A deep learning classifier was used to assign a continuous ROP vascular severity score, which ranged from 1 (normal) to 9 (most severe), at each examination. A secondary outcome was the difference in ROP vascular severity score among eyes treated with laser or the vascular endothelial growth factor antagonist bevacizumab. Differences between groups for both outcomes were assessed using unpaired 2-tailed t tests with Bonferroni correction. Results: Of 5255 examined eyes, 91 developed TR-ROP, of which 46 eyes met the inclusion criteria based on the available images. The mean (SD) birth weight of those patients was 653 (185) g, with a mean (SD) gestational age of 24.9 (1.3) weeks. The mean (SD) ROP vascular severity scores significantly increased 2 weeks prior to treatment (4.19 [1.75]), peaked at treatment (7.43 [1.89]), and decreased for at least 2 weeks after treatment (4.00 [1.88]) (all P < .001). Eyes requiring retreatment with laser had higher ROP vascular severity scores at the time of initial treatment compared with eyes receiving a single treatment (P < .001). Conclusions and Relevance: This quantitative ROP vascular severity score appears to consistently reflect clinical disease progression and posttreatment regression in eyes with TR-ROP. These study results may have implications for the monitoring of patients with ROP for treatment failure and disease recurrence and for determining the appropriate level of disease severity for primary treatment in eyes with aggressive disease.","A Quantitative Severity Scale for Retinopathy of Prematurity Using Deep Learning to Monitor Disease Regression After Treatment. Importance: Retinopathy of prematurity (ROP) is a leading cause of childhood blindness worldwide, but treatment failure and disease recurrence are important causes of adverse outcomes in patients with treatment-requiring ROP (TR-ROP). Objectives: To apply an automated ROP vascular severity score obtained using a deep learning algorithm and to assess its utility for objectively monitoring ROP regression after treatment. Design, Setting, and Participants: This retrospective cohort study used data from the Imaging and Informatics in ROP consortium, which comprises 9 tertiary referral centers in North America that screen high volumes of at-risk infants for ROP. Images of 5255 clinical eye examinations from 871 infants performed between July 2011 and December 2016 were assessed for eligibility in the present study. The disease course was assessed with time across the numerous examinations for patients with TR-ROP. Infants born prematurely meeting screening criteria for ROP who developed TR-ROP and who had images captured within 4 weeks before and after treatment as well as at the time of treatment were included. Main Outcomes and Measures: The primary outcome was mean (SD) ROP vascular severity score before, at time of, and after treatment. A deep learning classifier was used to assign a continuous ROP vascular severity score, which ranged from 1 (normal) to 9 (most severe), at each examination. A secondary outcome was the difference in ROP vascular severity score among eyes treated with laser or the vascular endothelial growth factor antagonist bevacizumab. Differences between groups for both outcomes were assessed using unpaired 2-tailed t tests with Bonferroni correction. Results: Of 5255 examined eyes, 91 developed TR-ROP, of which 46 eyes met the inclusion criteria based on the available images. The mean (SD) birth weight of those patients was 653 (185) g, with a mean (SD) gestational age of 24.9 (1.3) weeks. The mean (SD) ROP vascular severity scores significantly increased 2 weeks prior to treatment (4.19 [1.75]), peaked at treatment (7.43 [1.89]), and decreased for at least 2 weeks after treatment (4.00 [1.88]) (all P < .001). Eyes requiring retreatment with laser had higher ROP vascular severity scores at the time of initial treatment compared with eyes receiving a single treatment (P < .001). Conclusions and Relevance: This quantitative ROP vascular severity score appears to consistently reflect clinical disease progression and posttreatment regression in eyes with TR-ROP. These study results may have implications for the monitoring of patients with ROP for treatment failure and disease recurrence and for determining the appropriate level of disease severity for primary treatment in eyes with aggressive disease."
1,Adversarial training with cycle consistency for unsupervised super-resolution in endomicroscopy,"In recent years, endomicroscopy has become increasingly used for diagnostic purposes and interventional guidance. It can provide intraoperative aids for real-time tissue characterization and can help to perform visual investigations aimed for example to discover epithelial cancers. Due to physical constraints on the acquisition process, endomicroscopy images, still today have a low number of informative pixels which hampers their quality. Post-processing techniques, such as Super-Resolution (SR), are a potential solution to increase the quality of these images. SR techniques are often supervised, requiring aligned pairs of low-resolution (LR) and high-resolution (HR) images patches to train a model. However, in our domain, the lack of HR images hinders the collection of such pairs and makes supervised training unsuitable. For this reason, we propose an unsupervised SR framework based on an adversarial deep neural network with a physically-inspired cycle consistency, designed to impose some acquisition properties on the super-resolved images. Our framework can exploit HR images, regardless of the domain where they are coming from, to transfer the quality of the HR images to the initial LR images. This property can be particularly useful in all situations where pairs of LR/HR are not available during the training. Our quantitative analysis, validated using a database of 238 endomicroscopy video sequences from 143 patients, shows the ability of the pipeline to produce convincing super-resolved images. A Mean Opinion Score (MOS) study also confirms this quantitative image quality assessment.","Adversarial training with cycle consistency for unsupervised super-resolution in endomicroscopy. In recent years, endomicroscopy has become increasingly used for diagnostic purposes and interventional guidance. It can provide intraoperative aids for real-time tissue characterization and can help to perform visual investigations aimed for example to discover epithelial cancers. Due to physical constraints on the acquisition process, endomicroscopy images, still today have a low number of informative pixels which hampers their quality. Post-processing techniques, such as Super-Resolution (SR), are a potential solution to increase the quality of these images. SR techniques are often supervised, requiring aligned pairs of low-resolution (LR) and high-resolution (HR) images patches to train a model. However, in our domain, the lack of HR images hinders the collection of such pairs and makes supervised training unsuitable. For this reason, we propose an unsupervised SR framework based on an adversarial deep neural network with a physically-inspired cycle consistency, designed to impose some acquisition properties on the super-resolved images. Our framework can exploit HR images, regardless of the domain where they are coming from, to transfer the quality of the HR images to the initial LR images. This property can be particularly useful in all situations where pairs of LR/HR are not available during the training. Our quantitative analysis, validated using a database of 238 endomicroscopy video sequences from 143 patients, shows the ability of the pipeline to produce convincing super-resolved images. A Mean Opinion Score (MOS) study also confirms this quantitative image quality assessment."
1,Identifying peer experts in online health forums,"BACKGROUND: Online health forums have become increasingly popular over the past several years. They provide members with a platform to network with peers and share information, experiential advice, and support. Among the members of health forums, we define ""peer experts"" as a set of lay users who have gained expertise on the particular health topic through personal experience, and who demonstrate credibility in responding to questions from other members. This paper aims to motivate the need to identify peer experts in health forums and study their characteristics. METHODS: We analyze profiles and activity of members of a popular online health forum and characterize the interaction behavior of peer experts. We study the temporal patterns of comments posted by lay users and peer experts to uncover how peer expertise is developed. We further train a supervised classifier to identify peer experts based on their activity level, textual features, and temporal progression of posts. RESULT: A support vector machine classifier with radial basis function kernel was found to be the most suitable model among those studied. Features capturing the key semantic word classes and higher mean user activity were found to be most significant features. CONCLUSION: We define a new class of members of health forums called peer experts, and present preliminary, yet promising, approaches to distinguish peer experts from novice users. Identifying such peer expertise could potentially help improve the perceived reliability and trustworthiness of information in community health forums.","Identifying peer experts in online health forums. BACKGROUND: Online health forums have become increasingly popular over the past several years. They provide members with a platform to network with peers and share information, experiential advice, and support. Among the members of health forums, we define ""peer experts"" as a set of lay users who have gained expertise on the particular health topic through personal experience, and who demonstrate credibility in responding to questions from other members. This paper aims to motivate the need to identify peer experts in health forums and study their characteristics. METHODS: We analyze profiles and activity of members of a popular online health forum and characterize the interaction behavior of peer experts. We study the temporal patterns of comments posted by lay users and peer experts to uncover how peer expertise is developed. We further train a supervised classifier to identify peer experts based on their activity level, textual features, and temporal progression of posts. RESULT: A support vector machine classifier with radial basis function kernel was found to be the most suitable model among those studied. Features capturing the key semantic word classes and higher mean user activity were found to be most significant features. CONCLUSION: We define a new class of members of health forums called peer experts, and present preliminary, yet promising, approaches to distinguish peer experts from novice users. Identifying such peer expertise could potentially help improve the perceived reliability and trustworthiness of information in community health forums."
1,Multimodal hyper-connectivity of functional networks using functionally-weighted LASSO for MCI classification,"Recent works have shown that hyper-networks derived from blood-oxygen-level-dependent (BOLD) fMRI, where an edge (called hyper-edge) can be connected to more than two nodes, are effective biomarkers for MCI classification. Although BOLD fMRI is a high temporal resolution fMRI approach to assess alterations in brain networks, it cannot pinpoint to a single correlation of neuronal activity since BOLD signals are composite. In contrast, arterial spin labeling (ASL) is a lower temporal resolution fMRI technique for measuring cerebral blood flow (CBF) that can provide quantitative, direct brain network physiology measurements. This paper proposes a novel sparse regression algorithm for inference of the integrated hyper-connectivity networks from BOLD fMRI and ASL fMRI. Specifically, a least absolution shrinkage and selection operator (LASSO) algorithm, which is constrained by the functional connectivity derived from ASL fMRI, is employed to estimate hyper-connectivity for characterizing BOLD-fMRI-based functional interaction among multiple regions. An ASL-derived functional connectivity is constructed by using an Ultra-GroupLASSO-UOLS algorithm, where the combination of ultra-least squares (ULS) criterion with a group LASSO (GroupLASSO) algorithm is applied to detect the topology of ASL-based functional connectivity networks, and then an ultra-orthogonal least squares (UOLS) algorithm is used to estimate the connectivity strength. By combining the complementary characterization conveyed by rs-fMRI and ASL fMRI, our multimodal hyper-networks demonstrated much better discriminative characteristics than either the conventional pairwise connectivity networks or the unimodal hyper-connectivity networks. Experimental results on publicly available ADNI dataset demonstrate that the proposed method outperforms the existing single modality based sparse functional connectivity inference methods.","Multimodal hyper-connectivity of functional networks using functionally-weighted LASSO for MCI classification. Recent works have shown that hyper-networks derived from blood-oxygen-level-dependent (BOLD) fMRI, where an edge (called hyper-edge) can be connected to more than two nodes, are effective biomarkers for MCI classification. Although BOLD fMRI is a high temporal resolution fMRI approach to assess alterations in brain networks, it cannot pinpoint to a single correlation of neuronal activity since BOLD signals are composite. In contrast, arterial spin labeling (ASL) is a lower temporal resolution fMRI technique for measuring cerebral blood flow (CBF) that can provide quantitative, direct brain network physiology measurements. This paper proposes a novel sparse regression algorithm for inference of the integrated hyper-connectivity networks from BOLD fMRI and ASL fMRI. Specifically, a least absolution shrinkage and selection operator (LASSO) algorithm, which is constrained by the functional connectivity derived from ASL fMRI, is employed to estimate hyper-connectivity for characterizing BOLD-fMRI-based functional interaction among multiple regions. An ASL-derived functional connectivity is constructed by using an Ultra-GroupLASSO-UOLS algorithm, where the combination of ultra-least squares (ULS) criterion with a group LASSO (GroupLASSO) algorithm is applied to detect the topology of ASL-based functional connectivity networks, and then an ultra-orthogonal least squares (UOLS) algorithm is used to estimate the connectivity strength. By combining the complementary characterization conveyed by rs-fMRI and ASL fMRI, our multimodal hyper-networks demonstrated much better discriminative characteristics than either the conventional pairwise connectivity networks or the unimodal hyper-connectivity networks. Experimental results on publicly available ADNI dataset demonstrate that the proposed method outperforms the existing single modality based sparse functional connectivity inference methods."
1,Data-driven discovery and validation of circulating blood-based biomarkers associated with prevalent atrial fibrillation,,
1,Relation path feature embedding based convolutional neural network method for drug discovery,"BACKGROUND: Drug development is an expensive and time-consuming process. Literature-based discovery has played a critical role in drug development and may be a supplementary method to help scientists speed up the discovery of drugs. METHODS: Here, we propose a relation path features embedding based convolutional neural network model with attention mechanism for drug discovery from literature, which we denote as PACNN. First, we use predications from biomedical abstracts to construct a biomedical knowledge graph, and then apply a path ranking algorithm to extract drug-disease relation path features on the biomedical knowledge graph. After that, we use these drug-disease relation features to train a convolutional neural network model which combined with the attention mechanism. Finally, we employ the trained models to mine drugs for treating diseases. RESULTS: The experiment shows that the proposed model achieved promising results, comparing to several random walk algorithms. CONCLUSIONS: In this paper, we propose a relation path features embedding based convolutional neural network with attention mechanism for discovering potential drugs from literature. Our method could be an auxiliary method for drug discovery, which can speed up the discovery of new drugs for the incurable diseases.","Relation path feature embedding based convolutional neural network method for drug discovery. BACKGROUND: Drug development is an expensive and time-consuming process. Literature-based discovery has played a critical role in drug development and may be a supplementary method to help scientists speed up the discovery of drugs. METHODS: Here, we propose a relation path features embedding based convolutional neural network model with attention mechanism for drug discovery from literature, which we denote as PACNN. First, we use predications from biomedical abstracts to construct a biomedical knowledge graph, and then apply a path ranking algorithm to extract drug-disease relation path features on the biomedical knowledge graph. After that, we use these drug-disease relation features to train a convolutional neural network model which combined with the attention mechanism. Finally, we employ the trained models to mine drugs for treating diseases. RESULTS: The experiment shows that the proposed model achieved promising results, comparing to several random walk algorithms. CONCLUSIONS: In this paper, we propose a relation path features embedding based convolutional neural network with attention mechanism for discovering potential drugs from literature. Our method could be an auxiliary method for drug discovery, which can speed up the discovery of new drugs for the incurable diseases."
1,Screening for cardiac contractile dysfunction using an artificial intelligence-enabled electrocardiogram,"Asymptomatic left ventricular dysfunction (ALVD) is present in 3-6% of the general population, is associated with reduced quality of life and longevity, and is treatable when found(1-4). An inexpensive, noninvasive screening tool for ALVD in the doctor's office is not available. We tested the hypothesis that application of artificial intelligence (AI) to the electrocardiogram (ECG), a routine method of measuring the heart's electrical activity, could identify ALVD. Using paired 12-lead ECG and echocardiogram data, including the left ventricular ejection fraction (a measure of contractile function), from 44,959 patients at the Mayo Clinic, we trained a convolutional neural network to identify patients with ventricular dysfunction, defined as ejection fraction </=35%, using the ECG data alone. When tested on an independent set of 52,870 patients, the network model yielded values for the area under the curve, sensitivity, specificity, and accuracy of 0.93, 86.3%, 85.7%, and 85.7%, respectively. In patients without ventricular dysfunction, those with a positive AI screen were at 4 times the risk (hazard ratio, 4.1; 95% confidence interval, 3.3 to 5.0) of developing future ventricular dysfunction compared with those with a negative screen. Application of AI to the ECG-a ubiquitous, low-cost test-permits the ECG to serve as a powerful screening tool in asymptomatic individuals to identify ALVD.","Screening for cardiac contractile dysfunction using an artificial intelligence-enabled electrocardiogram. Asymptomatic left ventricular dysfunction (ALVD) is present in 3-6% of the general population, is associated with reduced quality of life and longevity, and is treatable when found(1-4). An inexpensive, noninvasive screening tool for ALVD in the doctor's office is not available. We tested the hypothesis that application of artificial intelligence (AI) to the electrocardiogram (ECG), a routine method of measuring the heart's electrical activity, could identify ALVD. Using paired 12-lead ECG and echocardiogram data, including the left ventricular ejection fraction (a measure of contractile function), from 44,959 patients at the Mayo Clinic, we trained a convolutional neural network to identify patients with ventricular dysfunction, defined as ejection fraction </=35%, using the ECG data alone. When tested on an independent set of 52,870 patients, the network model yielded values for the area under the curve, sensitivity, specificity, and accuracy of 0.93, 86.3%, 85.7%, and 85.7%, respectively. In patients without ventricular dysfunction, those with a positive AI screen were at 4 times the risk (hazard ratio, 4.1; 95% confidence interval, 3.3 to 5.0) of developing future ventricular dysfunction compared with those with a negative screen. Application of AI to the ECG-a ubiquitous, low-cost test-permits the ECG to serve as a powerful screening tool in asymptomatic individuals to identify ALVD."
